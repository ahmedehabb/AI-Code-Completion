{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4686168995864e759e186d7fd918e760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee7b9cecbc6f40088ea5f2367d335a45",
              "IPY_MODEL_12bf162d434845e9ac4232c4574c0018",
              "IPY_MODEL_af54eb0306254a2b85a253c6810e1d69"
            ],
            "layout": "IPY_MODEL_9e544e16614f4d9ba0d70e98948ec925"
          }
        },
        "ee7b9cecbc6f40088ea5f2367d335a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7bcb65fc0d54533a3a48974d61338e3",
            "placeholder": "​",
            "style": "IPY_MODEL_826d8188ff884735abd2f98764ba110d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "12bf162d434845e9ac4232c4574c0018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e77e6b20c14be1907f066476a6c134",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_726fb2007f064bf7a52762b192ceb02b",
            "value": 2
          }
        },
        "af54eb0306254a2b85a253c6810e1d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c841d17ccc4567810669e78e1dca88",
            "placeholder": "​",
            "style": "IPY_MODEL_deb9ab1daa544a79a28dfb40d8c901f6",
            "value": " 2/2 [00:00&lt;00:00,  7.09it/s]"
          }
        },
        "9e544e16614f4d9ba0d70e98948ec925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7bcb65fc0d54533a3a48974d61338e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "826d8188ff884735abd2f98764ba110d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31e77e6b20c14be1907f066476a6c134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "726fb2007f064bf7a52762b192ceb02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47c841d17ccc4567810669e78e1dca88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb9ab1daa544a79a28dfb40d8c901f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60f5cfc48c394ef08f044dad03a50227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aea51a7f6f340cb88657ca29be2ddfc",
              "IPY_MODEL_4af619a83b3144dd866cda2571774b70",
              "IPY_MODEL_58a4749b7a3b4f6ba113ae962bad42f3"
            ],
            "layout": "IPY_MODEL_743125700e0c4050a9ea3586b52622af"
          }
        },
        "2aea51a7f6f340cb88657ca29be2ddfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a54b8c92f45e488cb2831efa54e90fdf",
            "placeholder": "​",
            "style": "IPY_MODEL_535121458b84497db8dc1d891b16298b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4af619a83b3144dd866cda2571774b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ad4f9868326492a996fa431ca7431ad",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6a34f7457a84b0897eba81ff48212d7",
            "value": 25
          }
        },
        "58a4749b7a3b4f6ba113ae962bad42f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac234e1b33054c42b6949c0769c34ff0",
            "placeholder": "​",
            "style": "IPY_MODEL_fbfd7e1a8a1b4baf911431d12adc7f32",
            "value": " 25.0/25.0 [00:00&lt;00:00, 470B/s]"
          }
        },
        "743125700e0c4050a9ea3586b52622af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a54b8c92f45e488cb2831efa54e90fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "535121458b84497db8dc1d891b16298b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ad4f9868326492a996fa431ca7431ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6a34f7457a84b0897eba81ff48212d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac234e1b33054c42b6949c0769c34ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbfd7e1a8a1b4baf911431d12adc7f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d1f23a6d53a49f38e0f95db00216eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d97fdc62c2cc4354bf41ed82619bb3fb",
              "IPY_MODEL_f3f696e1e3c24362b6574c1a8f2d2159",
              "IPY_MODEL_698de0988cf14796a835285818b2bab6"
            ],
            "layout": "IPY_MODEL_f1f248fd9b2346f6b327e0534e6804ce"
          }
        },
        "d97fdc62c2cc4354bf41ed82619bb3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11216b0f00e74a23974a08388d7480c7",
            "placeholder": "​",
            "style": "IPY_MODEL_6fc8f2bf5d8f443eb675d067d060b78e",
            "value": "vocab.json: 100%"
          }
        },
        "f3f696e1e3c24362b6574c1a8f2d2159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b37f1e6f0541569e643ebe94ac2e5c",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b490ae809c345a8824efb80d302fdc8",
            "value": 898822
          }
        },
        "698de0988cf14796a835285818b2bab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58ecee6ee53448fb9ee883389dca4f43",
            "placeholder": "​",
            "style": "IPY_MODEL_6a53dfe892994e1f85e2090457fb4615",
            "value": " 899k/899k [00:00&lt;00:00, 10.4MB/s]"
          }
        },
        "f1f248fd9b2346f6b327e0534e6804ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11216b0f00e74a23974a08388d7480c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc8f2bf5d8f443eb675d067d060b78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1b37f1e6f0541569e643ebe94ac2e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b490ae809c345a8824efb80d302fdc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58ecee6ee53448fb9ee883389dca4f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a53dfe892994e1f85e2090457fb4615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e37b6baede6b43e4a27478f433b7eefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b52182bebeb4cda8cd02d2e0a93ce22",
              "IPY_MODEL_5c9f141c68d744889eb1c046950a2b0f",
              "IPY_MODEL_4a1c4543996041b589931683eae8fb03"
            ],
            "layout": "IPY_MODEL_dd609d2371d9446b8c3fe443e82bdae2"
          }
        },
        "5b52182bebeb4cda8cd02d2e0a93ce22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1af0b387f09c4044bcb40ad2f070110a",
            "placeholder": "​",
            "style": "IPY_MODEL_da1a5d6c7f574b53ad15d8769738e7b6",
            "value": "merges.txt: 100%"
          }
        },
        "5c9f141c68d744889eb1c046950a2b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c371e2de859427a95a1911bf62694cb",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ce544ba80f34a96ab6247e8a41796ba",
            "value": 456318
          }
        },
        "4a1c4543996041b589931683eae8fb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8c9502a796542919e1a9014e2d5e66f",
            "placeholder": "​",
            "style": "IPY_MODEL_955090510f8d4867a9c0f4176c5f2942",
            "value": " 456k/456k [00:00&lt;00:00, 2.73MB/s]"
          }
        },
        "dd609d2371d9446b8c3fe443e82bdae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af0b387f09c4044bcb40ad2f070110a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da1a5d6c7f574b53ad15d8769738e7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c371e2de859427a95a1911bf62694cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce544ba80f34a96ab6247e8a41796ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8c9502a796542919e1a9014e2d5e66f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "955090510f8d4867a9c0f4176c5f2942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0658ee95e01f4bf18f1cf3ed112b573d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e4cf4dc9e72471c9811c13d455ea72e",
              "IPY_MODEL_76614e1f1ca340c8961f91435a78f89a",
              "IPY_MODEL_133ad04cb5be405a8e2ba91dd72a5ed3"
            ],
            "layout": "IPY_MODEL_97d1e4da203e4126aa92bfc592778481"
          }
        },
        "6e4cf4dc9e72471c9811c13d455ea72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4737fb9adbc7423c80457eecaa57b0e1",
            "placeholder": "​",
            "style": "IPY_MODEL_fb663774f1904a039cc08c86a5ea7d41",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "76614e1f1ca340c8961f91435a78f89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908f89e9bc294be6b8a4b4ca166aaba3",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45697a53b6954b70be2d3d025bf21f46",
            "value": 150
          }
        },
        "133ad04cb5be405a8e2ba91dd72a5ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b20f0eb582849df939d9ebac0d6a690",
            "placeholder": "​",
            "style": "IPY_MODEL_2c23838042ef415fb3a3be407b62ae9f",
            "value": " 150/150 [00:00&lt;00:00, 3.07kB/s]"
          }
        },
        "97d1e4da203e4126aa92bfc592778481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4737fb9adbc7423c80457eecaa57b0e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb663774f1904a039cc08c86a5ea7d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "908f89e9bc294be6b8a4b4ca166aaba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45697a53b6954b70be2d3d025bf21f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b20f0eb582849df939d9ebac0d6a690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c23838042ef415fb3a3be407b62ae9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f403ff6b11224fba8742b7b56bfc773d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa4c82caef34451bbf4da17f136b4b10",
              "IPY_MODEL_593d7b8a6a624152be4ccf3ad6710cbc",
              "IPY_MODEL_75e300073f5e4863a95adeb9b6cdb110"
            ],
            "layout": "IPY_MODEL_4402d2c23e51417ea514fb3c86bda37e"
          }
        },
        "aa4c82caef34451bbf4da17f136b4b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f06327626aa4e489b341f22a4b68388",
            "placeholder": "​",
            "style": "IPY_MODEL_0f8a2065422a42c994f08d6b2048b8e4",
            "value": "config.json: 100%"
          }
        },
        "593d7b8a6a624152be4ccf3ad6710cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d398430b9d9d4f1280698e48ffddfb6d",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1af3118131e642a78bb15b725a143cfa",
            "value": 498
          }
        },
        "75e300073f5e4863a95adeb9b6cdb110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a4e30ba608416aa8ffbf1c4caabf62",
            "placeholder": "​",
            "style": "IPY_MODEL_e0e03b7d812a436fb91eb7bd011f8fe7",
            "value": " 498/498 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "4402d2c23e51417ea514fb3c86bda37e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f06327626aa4e489b341f22a4b68388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8a2065422a42c994f08d6b2048b8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d398430b9d9d4f1280698e48ffddfb6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af3118131e642a78bb15b725a143cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79a4e30ba608416aa8ffbf1c4caabf62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e03b7d812a436fb91eb7bd011f8fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "906467d1c39f461280538119b483421f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_feb26b7a610549b0bc4bcb2f099cff8c",
              "IPY_MODEL_7f98a63e8e8e47aea197c33ccaf35baa",
              "IPY_MODEL_547cfd14790e4ea4a15686e9a3817a25"
            ],
            "layout": "IPY_MODEL_9af383f0f322494c9a031958a7a99061"
          }
        },
        "feb26b7a610549b0bc4bcb2f099cff8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b976c11a8b7549c892a5a6ad727ccdb7",
            "placeholder": "​",
            "style": "IPY_MODEL_8c5b40b0264a4e44b508ff247a8c8401",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "7f98a63e8e8e47aea197c33ccaf35baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eb7c603a03a4641a5a9cf267a8025ae",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f723371adadb44b48fab7c3a3edd36fa",
            "value": 498627950
          }
        },
        "547cfd14790e4ea4a15686e9a3817a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec4c78e4fdb4b4c8657cf40bf633682",
            "placeholder": "​",
            "style": "IPY_MODEL_495b64151656433b8fd2e9470b67e057",
            "value": " 499M/499M [00:02&lt;00:00, 219MB/s]"
          }
        },
        "9af383f0f322494c9a031958a7a99061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b976c11a8b7549c892a5a6ad727ccdb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5b40b0264a4e44b508ff247a8c8401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eb7c603a03a4641a5a9cf267a8025ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f723371adadb44b48fab7c3a3edd36fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dec4c78e4fdb4b4c8657cf40bf633682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "495b64151656433b8fd2e9470b67e057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myzaa7Tsj2Wa",
        "outputId": "6aa91a65-f376-4f68-d405-c156320d7084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Project-Pattern-Recognition-main.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcflACrHkSIj",
        "outputId": "af36b1af-9e7c-4752-85c3-f06de9eadf84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Project-Pattern-Recognition-main.zip\n",
            "replace __MACOSX/._Project-Pattern-Recognition-main? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def get_all_py_files(directory):\n",
        "    # Using glob to recursively find all Python files\n",
        "    py_files = glob.glob(os.path.join(directory, '**', '*.py'), recursive=True)\n",
        "    py_files = [file for file in py_files if not file.endswith(\"__init__.py\")]\n",
        "    return py_files\n",
        "\n",
        "# Example usage\n",
        "directory = './Project-Pattern-Recognition-main'  # Replace this with the path of your directory\n",
        "py_files = get_all_py_files(directory)\n",
        "\n",
        "# Print out the list of .py files found\n",
        "for file in py_files:\n",
        "    print(file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEtqBD_Sj5f6",
        "outputId": "06f92551-2319-40b5-e770-6b52d344544d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./Project-Pattern-Recognition-main/data_insertion.py\n",
            "./Project-Pattern-Recognition-main/imports.py\n",
            "./Project-Pattern-Recognition-main/Final.py\n",
            "./Project-Pattern-Recognition-main/feature_selection/feature_selection.py\n",
            "./Project-Pattern-Recognition-main/illumination_preprocessing/illumination_preprocessing.py\n",
            "./Project-Pattern-Recognition-main/dataloader/dataloader.py\n",
            "./Project-Pattern-Recognition-main/feature_extraction/feature_extraction.py\n",
            "./Project-Pattern-Recognition-main/preprocessing/clustering_segmentation.py\n",
            "./Project-Pattern-Recognition-main/preprocessing/region_segmentation.py\n",
            "./Project-Pattern-Recognition-main/preprocessing/preproccessing.py\n",
            "./Project-Pattern-Recognition-main/preprocessing/edge_detection.py\n",
            "./Project-Pattern-Recognition-main/preprocessing/image_aligner.py\n",
            "./Project-Pattern-Recognition-main/preprocessing/threshold_segmentation.py\n",
            "./Project-Pattern-Recognition-main/preprocessing/image_restoration.py\n",
            "./Project-Pattern-Recognition-main/model_selection/model_selection.py\n",
            "./Project-Pattern-Recognition-main/performance_analysis/performance_analysis.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def read_file(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return f.readlines()\n",
        "\n",
        "\n",
        "def split_code_by_lines_only(code_lines, num_splits=30):\n",
        "    examples = []\n",
        "    for _ in range(num_splits):\n",
        "        # Pick a random line to simulate the cursor position (prefix)\n",
        "        line_idx = random.randint(1, len(code_lines) - 2)\n",
        "\n",
        "        # Split code for prefix: All code before the cursor line\n",
        "        prefix = ''.join(code_lines[:line_idx])\n",
        "\n",
        "        # Ensure the suffix line is after line_idx\n",
        "        if line_idx < len(code_lines) - 1:\n",
        "            suffix_line_idx = random.randint(line_idx + 1, len(code_lines) - 1)\n",
        "        else:\n",
        "            suffix_line_idx = len(code_lines) - 1  # Fallback if near the end\n",
        "\n",
        "        # Suffix: All code after the suffix line\n",
        "        suffix = ''.join(code_lines[suffix_line_idx:])\n",
        "\n",
        "        # Middle: All lines between the prefix and the suffix\n",
        "        middle = ''.join(code_lines[line_idx:suffix_line_idx])\n",
        "\n",
        "        examples.append((prefix, middle, suffix))\n",
        "\n",
        "    return examples\n",
        "\n",
        "def split_code(code_lines, num_splits=30):\n",
        "    examples = []\n",
        "    for _ in range(num_splits):\n",
        "        # Pick a random line to simulate the cursor position\n",
        "        line_idx = random.randint(1, len(code_lines) - 2)\n",
        "        line = code_lines[line_idx]\n",
        "\n",
        "        # Randomly select a point within that line to split\n",
        "        if len(line) > 1:\n",
        "            cursor_pos = random.randint(0, len(line) - 1)\n",
        "        else:\n",
        "            cursor_pos = 0\n",
        "\n",
        "        # Split code at the cursor position (for prefix)\n",
        "        prefix = ''.join(code_lines[:line_idx]) + line[:cursor_pos]\n",
        "\n",
        "        # Ensure the suffix line is after line_idx\n",
        "        if line_idx < len(code_lines) - 1:\n",
        "            suffix_line_idx = random.randint(line_idx + 1, len(code_lines) - 1)\n",
        "        else:\n",
        "            suffix_line_idx = len(code_lines) - 1  # Fallback in case the cursor is near the end\n",
        "\n",
        "        suffix_line = code_lines[suffix_line_idx]\n",
        "\n",
        "        # Randomly select a point within that line to split\n",
        "        if len(suffix_line) > 1:\n",
        "            suffix_cursor_pos = random.randint(0, len(suffix_line) - 1)\n",
        "        else:\n",
        "            suffix_cursor_pos = 0\n",
        "\n",
        "        # The suffix starts from the selected line and continues onward\n",
        "        suffix = suffix_line[suffix_cursor_pos:] + ''.join(code_lines[suffix_line_idx + 1:])\n",
        "\n",
        "        # The middle is the code between the cursor and the start of the suffix\n",
        "        middle = line[cursor_pos:] + ''.join(code_lines[line_idx + 1:suffix_line_idx]) + suffix_line[:suffix_cursor_pos]\n",
        "\n",
        "        examples.append((prefix, middle, suffix))\n",
        "\n",
        "    return examples\n",
        "\n",
        "def create_dataset(py_files, num_examples_per_file=1):\n",
        "    examples = []\n",
        "    for file in py_files:\n",
        "        code_lines = read_file(file)\n",
        "        # examples.extend(split_code(code_lines, num_splits=num_examples_per_file))\n",
        "        examples.extend(split_code_by_lines_only(code_lines, num_splits=num_examples_per_file))\n",
        "\n",
        "    return examples\n",
        "\n",
        "dataset = create_dataset(py_files, num_examples_per_file=3)"
      ],
      "metadata": {
        "id": "KxDRy4iKj6Vo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset is a list of tuples [(prefix, middle, suffix), ...]\n",
        "for i, example in enumerate(dataset):\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(\"Prefix: \\n\", example[0])\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    print(\"Middle (missing): \\n\", example[1])\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    print(\"Suffix: \\n\", example[2])\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6A8-QOrj8B1",
        "outputId": "5331ba74-f33e-4967-ece2-32146e9e25e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "Prefix: \n",
            " import os\n",
            "import gdown\n",
            "\n",
            "url = 'https://drive.google.com/uc?id=1JLxhdIddq6_vKlHml7jT48VaeXoJjvpR'\n",
            "output_filename = 'data.zip'\n",
            "\n",
            "# Get current working directory\n",
            "cwd = os.getcwd()\n",
            "\n",
            "# Concatenate current working directory and output filename\n",
            "output_path = os.path.join(cwd, output_filename)\n",
            "\n",
            "# Download file from Google Drive to output path\n",
            "gdown.download(url, output_path, quiet=False)\n",
            "\n",
            "import zipfile\n",
            "\n",
            "with zipfile.ZipFile(output_filename, 'r') as zip_ref:\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "     zip_ref.extractall('./data')\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " \n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 2:\n",
            "Prefix: \n",
            " import os\n",
            "import gdown\n",
            "\n",
            "url = 'https://drive.google.com/uc?id=1JLxhdIddq6_vKlHml7jT48VaeXoJjvpR'\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " output_filename = 'data.zip'\n",
            "\n",
            "# Get current working directory\n",
            "cwd = os.getcwd()\n",
            "\n",
            "# Concatenate current working directory and output filename\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " output_path = os.path.join(cwd, output_filename)\n",
            "\n",
            "# Download file from Google Drive to output path\n",
            "gdown.download(url, output_path, quiet=False)\n",
            "\n",
            "import zipfile\n",
            "\n",
            "with zipfile.ZipFile(output_filename, 'r') as zip_ref:\n",
            "    zip_ref.extractall('./data')\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 3:\n",
            "Prefix: \n",
            " import os\n",
            "import gdown\n",
            "\n",
            "url = 'https://drive.google.com/uc?id=1JLxhdIddq6_vKlHml7jT48VaeXoJjvpR'\n",
            "output_filename = 'data.zip'\n",
            "\n",
            "# Get current working directory\n",
            "cwd = os.getcwd()\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "# Concatenate current working directory and output filename\n",
            "output_path = os.path.join(cwd, output_filename)\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " # Download file from Google Drive to output path\n",
            "gdown.download(url, output_path, quiet=False)\n",
            "\n",
            "import zipfile\n",
            "\n",
            "with zipfile.ZipFile(output_filename, 'r') as zip_ref:\n",
            "    zip_ref.extractall('./data')\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 4:\n",
            "Prefix: \n",
            " from tensorflow.keras.models import load_model\n",
            "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense\n",
            "from keras.utils import to_categorical\n",
            "from keras import regularizers\n",
            "\n",
            "from sklearn.decomposition import PCA\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.neighbors import KNeighborsClassifier\n",
            "from sklearn.svm import SVC\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "from sklearn.metrics import accuracy_score\n",
            "from sklearn.ensemble import AdaBoostClassifier\n",
            "from sklearn.cluster import KMeans\n",
            "\n",
            "from skimage.filters import sobel, prewitt, roberts, laplace , median, gaussian, threshold_otsu, rank, threshold_local\n",
            "from skimage.feature import canny\n",
            "from skimage.restoration import denoise_nl_means, wiener\n",
            "from skimage.morphology import disk , square\n",
            "from skimage.draw import rectangle\n",
            "from skimage import exposure, filters\n",
            "from skimage.segmentation import felzenszwalb, slic, quickshift\n",
            "from skimage.segmentation import slic\n",
            "from skimage.segmentation import mark_boundaries\n",
            "from skimage.util import img_as_float\n",
            "from skimage.transform import resize\n",
            "from skimage.measure import regionprops\n",
            "from skimage.color import label2rgb\n",
            "from skimage.morphology import closing, disk, skeletonize\n",
            "from skimage.util import invert\n",
            "from skimage.segmentation import clear_border\n",
            "from skimage.feature import hog, local_binary_pattern\n",
            "from skimage.color import rgb2gray\n",
            "from skimage.feature import daisy\n",
            "\n",
            "from scipy.fftpack import fft\n",
            "from scipy.signal import convolve2d\n",
            "from scipy.ndimage import convolve\n",
            "from scipy import ndimage as ndi\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "from pathlib import Path\n",
            "from PIL import Image, ImageOps\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " from pyefd import elliptic_fourier_descriptors\n",
            "# from multiprocessing import Pool\n",
            "from colorama import Fore, Back, Style\n",
            "from skfuzzy.cluster import cmeans\n",
            "\n",
            "import pickle\n",
            "import time\n",
            "import cv2\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "import os\n",
            "import tqdm\n",
            "import hmmlearn.hmm as hmm\n",
            "import datetime\n",
            "import colorama\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 5:\n",
            "Prefix: \n",
            " from tensorflow.keras.models import load_model\n",
            "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense\n",
            "from keras.utils import to_categorical\n",
            "from keras import regularizers\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "from sklearn.decomposition import PCA\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.neighbors import KNeighborsClassifier\n",
            "from sklearn.svm import SVC\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "from sklearn.metrics import accuracy_score\n",
            "from sklearn.ensemble import AdaBoostClassifier\n",
            "from sklearn.cluster import KMeans\n",
            "\n",
            "from skimage.filters import sobel, prewitt, roberts, laplace , median, gaussian, threshold_otsu, rank, threshold_local\n",
            "from skimage.feature import canny\n",
            "from skimage.restoration import denoise_nl_means, wiener\n",
            "from skimage.morphology import disk , square\n",
            "from skimage.draw import rectangle\n",
            "from skimage import exposure, filters\n",
            "from skimage.segmentation import felzenszwalb, slic, quickshift\n",
            "from skimage.segmentation import slic\n",
            "from skimage.segmentation import mark_boundaries\n",
            "from skimage.util import img_as_float\n",
            "from skimage.transform import resize\n",
            "from skimage.measure import regionprops\n",
            "from skimage.color import label2rgb\n",
            "from skimage.morphology import closing, disk, skeletonize\n",
            "from skimage.util import invert\n",
            "from skimage.segmentation import clear_border\n",
            "from skimage.feature import hog, local_binary_pattern\n",
            "from skimage.color import rgb2gray\n",
            "from skimage.feature import daisy\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " \n",
            "from scipy.fftpack import fft\n",
            "from scipy.signal import convolve2d\n",
            "from scipy.ndimage import convolve\n",
            "from scipy import ndimage as ndi\n",
            "\n",
            "from pathlib import Path\n",
            "from PIL import Image, ImageOps\n",
            "from pyefd import elliptic_fourier_descriptors\n",
            "# from multiprocessing import Pool\n",
            "from colorama import Fore, Back, Style\n",
            "from skfuzzy.cluster import cmeans\n",
            "\n",
            "import pickle\n",
            "import time\n",
            "import cv2\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "import os\n",
            "import tqdm\n",
            "import hmmlearn.hmm as hmm\n",
            "import datetime\n",
            "import colorama\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 6:\n",
            "Prefix: \n",
            " from tensorflow.keras.models import load_model\n",
            "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense\n",
            "from keras.utils import to_categorical\n",
            "from keras import regularizers\n",
            "\n",
            "from sklearn.decomposition import PCA\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.neighbors import KNeighborsClassifier\n",
            "from sklearn.svm import SVC\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "from sklearn.metrics import accuracy_score\n",
            "from sklearn.ensemble import AdaBoostClassifier\n",
            "from sklearn.cluster import KMeans\n",
            "\n",
            "from skimage.filters import sobel, prewitt, roberts, laplace , median, gaussian, threshold_otsu, rank, threshold_local\n",
            "from skimage.feature import canny\n",
            "from skimage.restoration import denoise_nl_means, wiener\n",
            "from skimage.morphology import disk , square\n",
            "from skimage.draw import rectangle\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " from skimage import exposure, filters\n",
            "from skimage.segmentation import felzenszwalb, slic, quickshift\n",
            "from skimage.segmentation import slic\n",
            "from skimage.segmentation import mark_boundaries\n",
            "from skimage.util import img_as_float\n",
            "from skimage.transform import resize\n",
            "from skimage.measure import regionprops\n",
            "from skimage.color import label2rgb\n",
            "from skimage.morphology import closing, disk, skeletonize\n",
            "from skimage.util import invert\n",
            "from skimage.segmentation import clear_border\n",
            "from skimage.feature import hog, local_binary_pattern\n",
            "from skimage.color import rgb2gray\n",
            "from skimage.feature import daisy\n",
            "\n",
            "from scipy.fftpack import fft\n",
            "from scipy.signal import convolve2d\n",
            "from scipy.ndimage import convolve\n",
            "from scipy import ndimage as ndi\n",
            "\n",
            "from pathlib import Path\n",
            "from PIL import Image, ImageOps\n",
            "from pyefd import elliptic_fourier_descriptors\n",
            "# from multiprocessing import Pool\n",
            "from colorama import Fore, Back, Style\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " from skfuzzy.cluster import cmeans\n",
            "\n",
            "import pickle\n",
            "import time\n",
            "import cv2\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "import os\n",
            "import tqdm\n",
            "import hmmlearn.hmm as hmm\n",
            "import datetime\n",
            "import colorama\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 7:\n",
            "Prefix: \n",
            " # Required Files in the same directory:\n",
            "# 1. model.h5\n",
            "# 2. pca.pkl\n",
            "# 3. extracted_features_train_mean.npy\n",
            "# 4. extracted_features_train_std.npy\n",
            "\n",
            "from dataloader.dataloader import DataLoader\n",
            "from feature_extraction.feature_extraction import FeatureExtractor\n",
            "from feature_selection.feature_selection import FeatureSelector\n",
            "from model_selection.model_selection import ModelSelection\n",
            "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
            "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
            "from preprocessing.image_aligner import ImageAligner\n",
            "\n",
            "from imports import *\n",
            "\n",
            "data_loader = DataLoader(Path('./test'))\n",
            "illumination_processing = IlluminationPreprocessing()\n",
            "feature_extractor = FeatureExtractor()\n",
            "feature_selector = FeatureSelector()\n",
            "image_aligner = ImageAligner()\n",
            "\n",
            "model = load_model(\"model.h5\")\n",
            "pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "extracted_features_train_mean = np.load(\"extracted_features_train_mean.npy\")\n",
            "extracted_features_train_std = np.load(\"extracted_features_train_std.npy\")\n",
            "\n",
            "path = Path('./test')\n",
            "\n",
            "if os.path.exists(\"results.txt\"):\n",
            "    os.remove(\"results.txt\")\n",
            "if os.path.exists(\"time.txt\"):\n",
            "    os.remove(\"time.txt\")\n",
            "\n",
            "results_file = open(\"results.txt\", \"w\")\n",
            "time_file = open(\"time.txt\", \"w\")\n",
            "\n",
            "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
            "\n",
            "# Sort the list of files in increasing order\n",
            "files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
            "\n",
            "# Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
            "for i, filename in enumerate(files):\n",
            "    img = cv2.imread(os.path.join(path, filename))\n",
            "    img = np.array(img)\n",
            "    \n",
            "    # Get current time\n",
            "    start = time.perf_counter()\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "     \n",
            "    # Resize the image\n",
            "    img = data_loader.custom_resize_img(img)\n",
            "    \n",
            "    # Illumination Preprocessing\n",
            "    illuminated_test, _ = illumination_processing.process_image(img)\n",
            "\n",
            "    # Image Alignment\n",
            "    aligned_test = image_aligner.align_image([illuminated_test])[0]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " \n",
            "    # Feature extraction and selection\n",
            "    daisy_features_test = feature_extractor.extract_daisy_features([aligned_test])[0]\n",
            "\n",
            "    pca_daisy_features_test = feature_selector.test_pca(daisy_features_test,pca)\n",
            "    \n",
            "    pca_daisy_features_test = (pca_daisy_features_test - extracted_features_train_mean) /extracted_features_train_std\n",
            "\n",
            "    # Model loading and prediction\n",
            "    model_prediction = model.predict(pca_daisy_features_test)\n",
            "\n",
            "    # Only in case of ANN\n",
            "    model_prediction = model_prediction.argmax(axis=1)\n",
            "    \n",
            "    # stop timer\n",
            "    end = time.perf_counter()\n",
            "    \n",
            "    total_time_seconds = round(end - start, 3)\n",
            "\n",
            "    # write the prediction in results file\n",
            "    results_file.write(f\"{int(model_prediction[0])}\\n\")\n",
            "    \n",
            "    # write the time in times file\n",
            "    time_file.write(f\"{total_time_seconds}\\n\")\n",
            "\n",
            "results_file.close()\n",
            "time_file.close()\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 8:\n",
            "Prefix: \n",
            " # Required Files in the same directory:\n",
            "# 1. model.h5\n",
            "# 2. pca.pkl\n",
            "# 3. extracted_features_train_mean.npy\n",
            "# 4. extracted_features_train_std.npy\n",
            "\n",
            "from dataloader.dataloader import DataLoader\n",
            "from feature_extraction.feature_extraction import FeatureExtractor\n",
            "from feature_selection.feature_selection import FeatureSelector\n",
            "from model_selection.model_selection import ModelSelection\n",
            "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
            "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
            "from preprocessing.image_aligner import ImageAligner\n",
            "\n",
            "from imports import *\n",
            "\n",
            "data_loader = DataLoader(Path('./test'))\n",
            "illumination_processing = IlluminationPreprocessing()\n",
            "feature_extractor = FeatureExtractor()\n",
            "feature_selector = FeatureSelector()\n",
            "image_aligner = ImageAligner()\n",
            "\n",
            "model = load_model(\"model.h5\")\n",
            "pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "extracted_features_train_mean = np.load(\"extracted_features_train_mean.npy\")\n",
            "extracted_features_train_std = np.load(\"extracted_features_train_std.npy\")\n",
            "\n",
            "path = Path('./test')\n",
            "\n",
            "if os.path.exists(\"results.txt\"):\n",
            "    os.remove(\"results.txt\")\n",
            "if os.path.exists(\"time.txt\"):\n",
            "    os.remove(\"time.txt\")\n",
            "\n",
            "results_file = open(\"results.txt\", \"w\")\n",
            "time_file = open(\"time.txt\", \"w\")\n",
            "\n",
            "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
            "\n",
            "# Sort the list of files in increasing order\n",
            "files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
            "\n",
            "# Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
            "for i, filename in enumerate(files):\n",
            "    img = cv2.imread(os.path.join(path, filename))\n",
            "    img = np.array(img)\n",
            "    \n",
            "    # Get current time\n",
            "    start = time.perf_counter()\n",
            "    \n",
            "    # Resize the image\n",
            "    img = data_loader.custom_resize_img(img)\n",
            "    \n",
            "    # Illumination Preprocessing\n",
            "    illuminated_test, _ = illumination_processing.process_image(img)\n",
            "\n",
            "    # Image Alignment\n",
            "    aligned_test = image_aligner.align_image([illuminated_test])[0]\n",
            "\n",
            "    # Feature extraction and selection\n",
            "    daisy_features_test = feature_extractor.extract_daisy_features([aligned_test])[0]\n",
            "\n",
            "    pca_daisy_features_test = feature_selector.test_pca(daisy_features_test,pca)\n",
            "    \n",
            "    pca_daisy_features_test = (pca_daisy_features_test - extracted_features_train_mean) /extracted_features_train_std\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "     # Model loading and prediction\n",
            "    model_prediction = model.predict(pca_daisy_features_test)\n",
            "\n",
            "    # Only in case of ANN\n",
            "    model_prediction = model_prediction.argmax(axis=1)\n",
            "    \n",
            "    # stop timer\n",
            "    end = time.perf_counter()\n",
            "    \n",
            "    total_time_seconds = round(end - start, 3)\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "     # write the prediction in results file\n",
            "    results_file.write(f\"{int(model_prediction[0])}\\n\")\n",
            "    \n",
            "    # write the time in times file\n",
            "    time_file.write(f\"{total_time_seconds}\\n\")\n",
            "\n",
            "results_file.close()\n",
            "time_file.close()\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 9:\n",
            "Prefix: \n",
            " # Required Files in the same directory:\n",
            "# 1. model.h5\n",
            "# 2. pca.pkl\n",
            "# 3. extracted_features_train_mean.npy\n",
            "# 4. extracted_features_train_std.npy\n",
            "\n",
            "from dataloader.dataloader import DataLoader\n",
            "from feature_extraction.feature_extraction import FeatureExtractor\n",
            "from feature_selection.feature_selection import FeatureSelector\n",
            "from model_selection.model_selection import ModelSelection\n",
            "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
            "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
            "from preprocessing.image_aligner import ImageAligner\n",
            "\n",
            "from imports import *\n",
            "\n",
            "data_loader = DataLoader(Path('./test'))\n",
            "illumination_processing = IlluminationPreprocessing()\n",
            "feature_extractor = FeatureExtractor()\n",
            "feature_selector = FeatureSelector()\n",
            "image_aligner = ImageAligner()\n",
            "\n",
            "model = load_model(\"model.h5\")\n",
            "pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "extracted_features_train_mean = np.load(\"extracted_features_train_mean.npy\")\n",
            "extracted_features_train_std = np.load(\"extracted_features_train_std.npy\")\n",
            "\n",
            "path = Path('./test')\n",
            "\n",
            "if os.path.exists(\"results.txt\"):\n",
            "    os.remove(\"results.txt\")\n",
            "if os.path.exists(\"time.txt\"):\n",
            "    os.remove(\"time.txt\")\n",
            "\n",
            "results_file = open(\"results.txt\", \"w\")\n",
            "time_file = open(\"time.txt\", \"w\")\n",
            "\n",
            "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
            "\n",
            "# Sort the list of files in increasing order\n",
            "files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
            "\n",
            "# Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
            "for i, filename in enumerate(files):\n",
            "    img = cv2.imread(os.path.join(path, filename))\n",
            "    img = np.array(img)\n",
            "    \n",
            "    # Get current time\n",
            "    start = time.perf_counter()\n",
            "    \n",
            "    # Resize the image\n",
            "    img = data_loader.custom_resize_img(img)\n",
            "    \n",
            "    # Illumination Preprocessing\n",
            "    illuminated_test, _ = illumination_processing.process_image(img)\n",
            "\n",
            "    # Image Alignment\n",
            "    aligned_test = image_aligner.align_image([illuminated_test])[0]\n",
            "\n",
            "    # Feature extraction and selection\n",
            "    daisy_features_test = feature_extractor.extract_daisy_features([aligned_test])[0]\n",
            "\n",
            "    pca_daisy_features_test = feature_selector.test_pca(daisy_features_test,pca)\n",
            "    \n",
            "    pca_daisy_features_test = (pca_daisy_features_test - extracted_features_train_mean) /extracted_features_train_std\n",
            "\n",
            "    # Model loading and prediction\n",
            "    model_prediction = model.predict(pca_daisy_features_test)\n",
            "\n",
            "    # Only in case of ANN\n",
            "    model_prediction = model_prediction.argmax(axis=1)\n",
            "    \n",
            "    # stop timer\n",
            "    end = time.perf_counter()\n",
            "    \n",
            "    total_time_seconds = round(end - start, 3)\n",
            "\n",
            "    # write the prediction in results file\n",
            "    results_file.write(f\"{int(model_prediction[0])}\\n\")\n",
            "    \n",
            "    # write the time in times file\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "     time_file.write(f\"{total_time_seconds}\\n\")\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " results_file.close()\n",
            "time_file.close()\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 10:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class FeatureSelector:\n",
            "    def __init__(self) -> None:\n",
            "        pass\n",
            "\n",
            "    def extract_pca_features(self, images, load=False, num_pca_components=0.95):\n",
            "        \"\"\"\n",
            "        The extract_pca_features function takes as input a NumPy array of images and an optional parameter num_components that specifies the number of principal components to use as features (default is 20).\n",
            "        For each image, the function flattens the image into a 1D vector and appends it to a list of image vectors.\n",
            "        It then converts the list of image vectors to a NumPy array and performs PCA using scikit-learn's PCA function.\n",
            "        Finally, the function extracts the first num_components principal components and returns them as the PCA features.\n",
            "        \"\"\"\n",
            "        image_vectors = []\n",
            "        for image in images:\n",
            "            image_vectors.append(image.flatten())\n",
            "        image_vectors = np.array(image_vectors)\n",
            "        \n",
            "        if load:\n",
            "            pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "            pca_features = pca.transform(image_vectors)\n",
            "            return pca_features\n",
            "        else:\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "             print(\"Creating new PCA model...\")\n",
            "            pca = PCA(n_components = num_pca_components, svd_solver = 'full')\n",
            "            pca.fit(image_vectors)\n",
            "\n",
            "            pca_features = pca.transform(image_vectors)\n",
            "\n",
            "            pca_features = np.array(pca_features)\n",
            "            \n",
            "            pickle.dump(pca, open(\"pca.pkl\", \"wb\"))\n",
            "            \n",
            "            return pca_features\n",
            "        \n",
            "    def test_pca(self,img, pca):\n",
            "        image_vector = img.flatten()\n",
            "        pca_features = pca.transform(np.array([image_vector]))\n",
            "        return pca_features\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         \n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 11:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class FeatureSelector:\n",
            "    def __init__(self) -> None:\n",
            "        pass\n",
            "\n",
            "    def extract_pca_features(self, images, load=False, num_pca_components=0.95):\n",
            "        \"\"\"\n",
            "        The extract_pca_features function takes as input a NumPy array of images and an optional parameter num_components that specifies the number of principal components to use as features (default is 20).\n",
            "        For each image, the function flattens the image into a 1D vector and appends it to a list of image vectors.\n",
            "        It then converts the list of image vectors to a NumPy array and performs PCA using scikit-learn's PCA function.\n",
            "        Finally, the function extracts the first num_components principal components and returns them as the PCA features.\n",
            "        \"\"\"\n",
            "        image_vectors = []\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         for image in images:\n",
            "            image_vectors.append(image.flatten())\n",
            "        image_vectors = np.array(image_vectors)\n",
            "        \n",
            "        if load:\n",
            "            pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "            pca_features = pca.transform(image_vectors)\n",
            "            return pca_features\n",
            "        else:\n",
            "            print(\"Creating new PCA model...\")\n",
            "            pca = PCA(n_components = num_pca_components, svd_solver = 'full')\n",
            "            pca.fit(image_vectors)\n",
            "\n",
            "            pca_features = pca.transform(image_vectors)\n",
            "\n",
            "            pca_features = np.array(pca_features)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "             \n",
            "            pickle.dump(pca, open(\"pca.pkl\", \"wb\"))\n",
            "            \n",
            "            return pca_features\n",
            "        \n",
            "    def test_pca(self,img, pca):\n",
            "        image_vector = img.flatten()\n",
            "        pca_features = pca.transform(np.array([image_vector]))\n",
            "        return pca_features\n",
            "        \n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 12:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "\n",
            "class FeatureSelector:\n",
            "    def __init__(self) -> None:\n",
            "        pass\n",
            "\n",
            "    def extract_pca_features(self, images, load=False, num_pca_components=0.95):\n",
            "        \"\"\"\n",
            "        The extract_pca_features function takes as input a NumPy array of images and an optional parameter num_components that specifies the number of principal components to use as features (default is 20).\n",
            "        For each image, the function flattens the image into a 1D vector and appends it to a list of image vectors.\n",
            "        It then converts the list of image vectors to a NumPy array and performs PCA using scikit-learn's PCA function.\n",
            "        Finally, the function extracts the first num_components principal components and returns them as the PCA features.\n",
            "        \"\"\"\n",
            "        image_vectors = []\n",
            "        for image in images:\n",
            "            image_vectors.append(image.flatten())\n",
            "        image_vectors = np.array(image_vectors)\n",
            "        \n",
            "        if load:\n",
            "            pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "            pca_features = pca.transform(image_vectors)\n",
            "            return pca_features\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         else:\n",
            "            print(\"Creating new PCA model...\")\n",
            "            pca = PCA(n_components = num_pca_components, svd_solver = 'full')\n",
            "            pca.fit(image_vectors)\n",
            "\n",
            "            pca_features = pca.transform(image_vectors)\n",
            "\n",
            "            pca_features = np.array(pca_features)\n",
            "            \n",
            "            pickle.dump(pca, open(\"pca.pkl\", \"wb\"))\n",
            "            \n",
            "            return pca_features\n",
            "        \n",
            "    def test_pca(self,img, pca):\n",
            "        image_vector = img.flatten()\n",
            "        pca_features = pca.transform(np.array([image_vector]))\n",
            "        return pca_features\n",
            "        \n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 13:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class IlluminationPreprocessing:\n",
            "  def __init__(self):\n",
            "    pass\n",
            "  \n",
            "  def retinex(self, image, sigma=100):\n",
            "      image = np.copy(image)\n",
            "      # Convert image to float32\n",
            "      image = image.astype(np.float32)\n",
            "\n",
            "      # Compute logarithmic luminance\n",
            "      log_luminance = np.log(image.mean(axis=2))\n",
            "\n",
            "      # Compute multiscale decomposition using a Gaussian pyramid\n",
            "      pyramid = []\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "       pyramid.append(log_luminance)\n",
            "      for i in range(1, 3):\n",
            "          pyramid.append(cv2.pyrDown(pyramid[i - 1]))\n",
            "\n",
            "      # Compute local contrast for each scale\n",
            "      contrast = []\n",
            "      for i in range(3):\n",
            "          laplacian = cv2.Laplacian(pyramid[i], cv2.CV_32F, ksize=3)\n",
            "          contrast.append(np.exp(np.abs(cv2.resize(laplacian, log_luminance.shape[::-1])) / sigma))\n",
            "\n",
            "      # Compute reflectance by multiplying local contrast across scales\n",
            "      reflectance = np.ones_like(log_luminance)\n",
            "      for i in range(3):\n",
            "          reflectance *= cv2.resize(contrast[i], log_luminance.shape[::-1])\n",
            "\n",
            "      # Compute illumination by dividing logarithmic luminance by reflectance\n",
            "      illumination = np.exp(log_luminance) / reflectance\n",
            "\n",
            "      # Rescale illumination to have the same range as the input image\n",
            "      illumination = cv2.normalize(illumination, None, 0, 255, cv2.NORM_MINMAX)\n",
            "\n",
            "      # Convert illumination back to uint8 and merge with original image\n",
            "      illumination = illumination.astype(np.uint8)\n",
            "      result = cv2.merge([image[:,:,0] - illumination, image[:,:,1] - illumination, image[:,:,2] - illumination])\n",
            "\n",
            "      # Invert pixel values to range of [0, 255]\n",
            "      result = (255 - result).clip(0, 255).astype(np.uint8)\n",
            "      return result\n",
            "\n",
            "\n",
            "  def process_image(self, img):\n",
            "      op = self.retinex(img)\n",
            "      op = cv2.cvtColor(op, cv2.COLOR_RGB2HSV)\n",
            "      saturation_channel = op[:, :, 1]\n",
            "\n",
            "      # Calculate actual threshold value\n",
            "      _, actual_threshold = cv2.threshold(saturation_channel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
            "      # plt.imshow(saturation_channel, cmap=\"gray\")\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "       # plt.show()\n",
            "      kernel = np.ones((5, 5), np.uint8)\n",
            "      # Perform morphological operations to remove small noise and fill gaps in the binary image\n",
            "      mask = cv2.morphologyEx(actual_threshold, cv2.MORPH_OPEN, kernel)\n",
            "      mask = ndi.binary_fill_holes(mask).astype(np.uint8)\n",
            "      # plt.imshow(mask, cmap=\"gray\")\n",
            "      # plt.show()\n",
            "      # Apply binary mask to grayscale image\n",
            "      saturation_channel_masked = cv2.multiply(saturation_channel, mask)\n",
            "      # plt.imshow(saturation_channel_masked, cmap=\"gray\")\n",
            "      # plt.show()\n",
            "      return saturation_channel_masked, mask\n",
            "\n",
            "\n",
            "#   def process_images_multiprocess(self, images):\n",
            "#       with Pool() as p:\n",
            "#           results = p.map(self.process_image, images)\n",
            "#       return np.stack(results, axis=0)\n",
            "\n",
            "  def process_images_loops(self, images):\n",
            "      results = []\n",
            "      for image in images:\n",
            "          results.append(self.process_image(image))\n",
            "      return results\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 14:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class IlluminationPreprocessing:\n",
            "  def __init__(self):\n",
            "    pass\n",
            "  \n",
            "  def retinex(self, image, sigma=100):\n",
            "      image = np.copy(image)\n",
            "      # Convert image to float32\n",
            "      image = image.astype(np.float32)\n",
            "\n",
            "      # Compute logarithmic luminance\n",
            "      log_luminance = np.log(image.mean(axis=2))\n",
            "\n",
            "      # Compute multiscale decomposition using a Gaussian pyramid\n",
            "      pyramid = []\n",
            "      pyramid.append(log_luminance)\n",
            "      for i in range(1, 3):\n",
            "          pyramid.append(cv2.pyrDown(pyramid[i - 1]))\n",
            "\n",
            "      # Compute local contrast for each scale\n",
            "      contrast = []\n",
            "      for i in range(3):\n",
            "          laplacian = cv2.Laplacian(pyramid[i], cv2.CV_32F, ksize=3)\n",
            "          contrast.append(np.exp(np.abs(cv2.resize(laplacian, log_luminance.shape[::-1])) / sigma))\n",
            "\n",
            "      # Compute reflectance by multiplying local contrast across scales\n",
            "      reflectance = np.ones_like(log_luminance)\n",
            "      for i in range(3):\n",
            "          reflectance *= cv2.resize(contrast[i], log_luminance.shape[::-1])\n",
            "\n",
            "      # Compute illumination by dividing logarithmic luminance by reflectance\n",
            "      illumination = np.exp(log_luminance) / reflectance\n",
            "\n",
            "      # Rescale illumination to have the same range as the input image\n",
            "      illumination = cv2.normalize(illumination, None, 0, 255, cv2.NORM_MINMAX)\n",
            "\n",
            "      # Convert illumination back to uint8 and merge with original image\n",
            "      illumination = illumination.astype(np.uint8)\n",
            "      result = cv2.merge([image[:,:,0] - illumination, image[:,:,1] - illumination, image[:,:,2] - illumination])\n",
            "\n",
            "      # Invert pixel values to range of [0, 255]\n",
            "      result = (255 - result).clip(0, 255).astype(np.uint8)\n",
            "      return result\n",
            "\n",
            "\n",
            "  def process_image(self, img):\n",
            "      op = self.retinex(img)\n",
            "      op = cv2.cvtColor(op, cv2.COLOR_RGB2HSV)\n",
            "      saturation_channel = op[:, :, 1]\n",
            "\n",
            "      # Calculate actual threshold value\n",
            "      _, actual_threshold = cv2.threshold(saturation_channel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
            "      # plt.imshow(saturation_channel, cmap=\"gray\")\n",
            "      # plt.show()\n",
            "      kernel = np.ones((5, 5), np.uint8)\n",
            "      # Perform morphological operations to remove small noise and fill gaps in the binary image\n",
            "      mask = cv2.morphologyEx(actual_threshold, cv2.MORPH_OPEN, kernel)\n",
            "      mask = ndi.binary_fill_holes(mask).astype(np.uint8)\n",
            "      # plt.imshow(mask, cmap=\"gray\")\n",
            "      # plt.show()\n",
            "      # Apply binary mask to grayscale image\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "       saturation_channel_masked = cv2.multiply(saturation_channel, mask)\n",
            "      # plt.imshow(saturation_channel_masked, cmap=\"gray\")\n",
            "      # plt.show()\n",
            "      return saturation_channel_masked, mask\n",
            "\n",
            "\n",
            "#   def process_images_multiprocess(self, images):\n",
            "#       with Pool() as p:\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " #           results = p.map(self.process_image, images)\n",
            "#       return np.stack(results, axis=0)\n",
            "\n",
            "  def process_images_loops(self, images):\n",
            "      results = []\n",
            "      for image in images:\n",
            "          results.append(self.process_image(image))\n",
            "      return results\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 15:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class IlluminationPreprocessing:\n",
            "  def __init__(self):\n",
            "    pass\n",
            "  \n",
            "  def retinex(self, image, sigma=100):\n",
            "      image = np.copy(image)\n",
            "      # Convert image to float32\n",
            "      image = image.astype(np.float32)\n",
            "\n",
            "      # Compute logarithmic luminance\n",
            "      log_luminance = np.log(image.mean(axis=2))\n",
            "\n",
            "      # Compute multiscale decomposition using a Gaussian pyramid\n",
            "      pyramid = []\n",
            "      pyramid.append(log_luminance)\n",
            "      for i in range(1, 3):\n",
            "          pyramid.append(cv2.pyrDown(pyramid[i - 1]))\n",
            "\n",
            "      # Compute local contrast for each scale\n",
            "      contrast = []\n",
            "      for i in range(3):\n",
            "          laplacian = cv2.Laplacian(pyramid[i], cv2.CV_32F, ksize=3)\n",
            "          contrast.append(np.exp(np.abs(cv2.resize(laplacian, log_luminance.shape[::-1])) / sigma))\n",
            "\n",
            "      # Compute reflectance by multiplying local contrast across scales\n",
            "      reflectance = np.ones_like(log_luminance)\n",
            "      for i in range(3):\n",
            "          reflectance *= cv2.resize(contrast[i], log_luminance.shape[::-1])\n",
            "\n",
            "      # Compute illumination by dividing logarithmic luminance by reflectance\n",
            "      illumination = np.exp(log_luminance) / reflectance\n",
            "\n",
            "      # Rescale illumination to have the same range as the input image\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "       illumination = cv2.normalize(illumination, None, 0, 255, cv2.NORM_MINMAX)\n",
            "\n",
            "      # Convert illumination back to uint8 and merge with original image\n",
            "      illumination = illumination.astype(np.uint8)\n",
            "      result = cv2.merge([image[:,:,0] - illumination, image[:,:,1] - illumination, image[:,:,2] - illumination])\n",
            "\n",
            "      # Invert pixel values to range of [0, 255]\n",
            "      result = (255 - result).clip(0, 255).astype(np.uint8)\n",
            "      return result\n",
            "\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "   def process_image(self, img):\n",
            "      op = self.retinex(img)\n",
            "      op = cv2.cvtColor(op, cv2.COLOR_RGB2HSV)\n",
            "      saturation_channel = op[:, :, 1]\n",
            "\n",
            "      # Calculate actual threshold value\n",
            "      _, actual_threshold = cv2.threshold(saturation_channel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
            "      # plt.imshow(saturation_channel, cmap=\"gray\")\n",
            "      # plt.show()\n",
            "      kernel = np.ones((5, 5), np.uint8)\n",
            "      # Perform morphological operations to remove small noise and fill gaps in the binary image\n",
            "      mask = cv2.morphologyEx(actual_threshold, cv2.MORPH_OPEN, kernel)\n",
            "      mask = ndi.binary_fill_holes(mask).astype(np.uint8)\n",
            "      # plt.imshow(mask, cmap=\"gray\")\n",
            "      # plt.show()\n",
            "      # Apply binary mask to grayscale image\n",
            "      saturation_channel_masked = cv2.multiply(saturation_channel, mask)\n",
            "      # plt.imshow(saturation_channel_masked, cmap=\"gray\")\n",
            "      # plt.show()\n",
            "      return saturation_channel_masked, mask\n",
            "\n",
            "\n",
            "#   def process_images_multiprocess(self, images):\n",
            "#       with Pool() as p:\n",
            "#           results = p.map(self.process_image, images)\n",
            "#       return np.stack(results, axis=0)\n",
            "\n",
            "  def process_images_loops(self, images):\n",
            "      results = []\n",
            "      for image in images:\n",
            "          results.append(self.process_image(image))\n",
            "      return results\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 16:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "WIDTH = 320\n",
            "HEIGHT = 320\n",
            "\n",
            "\n",
            "class DataLoader:\n",
            "    def __init__(self, path: Path):\n",
            "        self.path = path\n",
            "        self.genders = [\"men\", \"Women\"]\n",
            "        self.desired_size = (WIDTH, HEIGHT)\n",
            "        \n",
            "    def load_data(self, data_augmentation=False):\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         try:\n",
            "            return self.load_saved_data()\n",
            "        except:\n",
            "            return self.start_load_data(data_augmentation)\n",
            "\n",
            "\n",
            "    def start_load_data(self, data_augmentation=False):\n",
            "        images = []\n",
            "        labels = []\n",
            "        x_train = []\n",
            "        y_train = []\n",
            "        x_test = []\n",
            "        y_test = []\n",
            "        x_val = []\n",
            "        y_val = []\n",
            "\n",
            "        for gender in self.genders:\n",
            "            for digit in range(6):\n",
            "                print(f\"current digit: {digit}\")\n",
            "                digit_path = self.path / gender / str(digit)\n",
            "                images = []\n",
            "                labels = []\n",
            "                for img_path in digit_path.glob(\"*.JPG\"):\n",
            "                    try:\n",
            "                        img = Image.open(img_path)\n",
            "                        images.append(np.array(img))\n",
            "                        labels.append(digit)\n",
            "                    except:\n",
            "                        print(\"Image {} is corrupted\".format(img_path))\n",
            "                        continue\n",
            "\n",
            "                images = np.array(images)\n",
            "                \n",
            "                images = self.resize_images(images)\n",
            "\n",
            "                x_train_temp, x_val_temp, y_train_temp, y_val_temp = train_test_split(\n",
            "                    images, labels, test_size=0.2, random_state=42\n",
            "                )\n",
            "                # x_train_temp, x_val_temp, y_train_temp, y_val_temp = train_test_split(\n",
            "                #     x_train_temp, y_train_temp, test_size=0.1 / 0.9, random_state=42\n",
            "                # )\n",
            "                x_train.extend(x_train_temp)\n",
            "                y_train.extend(y_train_temp)\n",
            "                # x_test.extend(x_test_temp)\n",
            "                x_val.extend(x_val_temp)\n",
            "                y_val.extend(y_val_temp)\n",
            "                # y_test.extend(y_test_temp)\n",
            "\n",
            "        x_train = np.array(x_train)\n",
            "        y_train = np.array(y_train)\n",
            "        # x_test = np.array(x_test)\n",
            "        # y_test = np.array(y_test)\n",
            "        x_val = np.array(x_val)\n",
            "        y_val = np.array(y_val)\n",
            "        \n",
            "        # shuffle the training data\n",
            "        indices = np.arange(x_train.shape[0])\n",
            "        np.random.shuffle(indices)\n",
            "        x_train = x_train[indices]\n",
            "        y_train = y_train[indices]\n",
            "\n",
            "        # shuffle the validation data\n",
            "        indices = np.arange(x_val.shape[0])\n",
            "        np.random.shuffle(indices)\n",
            "        x_val = x_val[indices]\n",
            "        y_val = y_val[indices]\n",
            "\n",
            "        if (data_augmentation):\n",
            "            x_train, y_train = self.data_augmentation(x_train, y_train)\n",
            "            y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
            "            \n",
            "        self.save_data(x_train, y_train, x_test, y_test, x_val, y_val)\n",
            "\n",
            "        return x_train, y_train, x_test, y_test, x_val, y_val\n",
            "\n",
            "    def save_data(self, x_train, y_train, x_test, y_test, x_val, y_val):\n",
            "        np.save(\"./data/x_train.npy\", x_train)\n",
            "        np.save(\"./data/y_train.npy\", y_train)\n",
            "        np.save(\"./data/x_test.npy\", x_test)\n",
            "        np.save(\"./data/y_test.npy\", y_test)\n",
            "        np.save(\"./data/x_val.npy\", x_val)\n",
            "        np.save(\"./data/y_val.npy\", y_val)\n",
            "\n",
            "    def load_saved_data(self):\n",
            "        x_train = np.load(\"./data/x_train.npy\")\n",
            "        y_train = np.load(\"./data/y_train.npy\")\n",
            "        x_test = np.load(\"./data/x_test.npy\")\n",
            "        y_test = np.load(\"./data/y_test.npy\")\n",
            "        x_val = np.load(\"./data/x_val.npy\")\n",
            "        y_val = np.load(\"./data/y_val.npy\")\n",
            "    \n",
            "        return x_train, y_train, x_test, y_test, x_val, y_val\n",
            "    \n",
            "    def data_augmentation(self, x_train, y_train):\n",
            "        #--------------------------------------DATA AUGMENTATION-----------------------------------------\n",
            "\n",
            "        # Define image data generator for data augmentation\n",
            "        datagen = ImageDataGenerator(\n",
            "            # rotation_range=40,  # randomly rotate images by up to 40 degrees\n",
            "            width_shift_range=0.3,  # randomly shift images horizontally by up to 30%\n",
            "            height_shift_range=0.3,  # randomly shift images vertically by up to 30%\n",
            "            shear_range=0.2,  # randomly apply shearing transformations\n",
            "            zoom_range=0.3,  # randomly zoom in on images by up to 30%\n",
            "            channel_shift_range=20,  # randomly adjust brightness\n",
            "            brightness_range=[0.5, 1.5],  # randomly adjust brightness\n",
            "            horizontal_flip=True,  # randomly flip images horizontally\n",
            "            vertical_flip=True,  # randomly flip images vertically\n",
            "            fill_mode='nearest'  # fill in any gaps with the nearest pixel value\n",
            "        )\n",
            "\n",
            "        # Fit the data generator to your training data\n",
            "        datagen.fit(x_train)\n",
            "\n",
            "        # Define a function to generate augmented images and labels\n",
            "\n",
            "        # Set batch size for training\n",
            "        batch_size = 300\n",
            "\n",
            "        # Generate augmented images and labels using the function defined above\n",
            "        augmented_data = self.generate_augmented_data(x_train, y_train, batch_size, datagen)\n",
            "        x_augmented, y_augmented = next(augmented_data)\n",
            "\n",
            "        # Concatenate the original training set and the augmented images\n",
            "        x_train = np.concatenate((x_train, x_augmented))\n",
            "\n",
            "        # Concatenate the original labels and the augmented labels\n",
            "        y_train = np.concatenate((y_train, y_augmented))\n",
            "        y_train = np.reshape(y_train,(y_train.shape[0],1))\n",
            "\n",
            "        return x_train, y_train\n",
            "\n",
            "    \n",
            "    \n",
            "    def generate_augmented_data(self, x, y, batch_size, datagen):\n",
            "        gen = datagen.flow(x, y, batch_size=batch_size)\n",
            "        while True:\n",
            "            x_batch, y_batch = gen.next()\n",
            "            yield x_batch, y_batch\n",
            "            \n",
            "    def resize_images(self,images):\n",
            "        images_resized = []\n",
            "        for img in images:\n",
            "            img = self.custom_resize_img(img)\n",
            "            images_resized.append(img)\n",
            "        \n",
            "        images_resized = np.array(images_resized)\n",
            "        return images_resized\n",
            "            \n",
            "            \n",
            "            \n",
            "    def custom_resize_img(self,img):\n",
            "        # Calculate the aspect ratio of the image\n",
            "        img = Image.fromarray(img)\n",
            "        img_width, img_height   = img.size\n",
            "        aspect_ratio = float(img_width) / float(img_height)\n",
            "\n",
            "        # resize the image so that the shortest side is equal to the desired size\n",
            "        if img_width < img_height:\n",
            "            new_width = int(self.desired_size[0] * aspect_ratio)\n",
            "            img = img.resize((new_width, self.desired_size[1]))\n",
            "        else:\n",
            "            new_height = int(self.desired_size[1] / aspect_ratio)\n",
            "            img = img.resize((self.desired_size[0], new_height))\n",
            "\n",
            "        # add padding to the image so that it is the desired size\n",
            "        delta_width = self.desired_size[0] - img.size[0]\n",
            "        delta_height = self.desired_size[1] - img.size[1]\n",
            "        left = int(delta_width / 2)\n",
            "        top = int(delta_height / 2)\n",
            "        right = self.desired_size[0] - img.size[0] - left\n",
            "        bottom = self.desired_size[1] - img.size[1] - top\n",
            "        img = ImageOps.expand(\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "             img, border=(left, top, right, bottom), fill=(255,255,255)\n",
            "        )\n",
            "        img = np.array(img)\n",
            "        return img\n",
            "    \n",
            "    def load_test_data(self):\n",
            "        files = [f for f in os.listdir(self.path) if os.path.isfile(os.path.join(self.path, f))]\n",
            "\n",
            "        # Sort the list of files in increasing order\n",
            "        files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
            "\n",
            "        # Initialize an empty numpy array to store the images\n",
            "        images = np.empty((len(files),), dtype=object)\n",
            "\n",
            "        # Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
            "        for i, filename in enumerate(files):\n",
            "            img = cv2.imread(os.path.join(self.path, filename))\n",
            "            images[i] = img\n",
            "        images = np.array(images)\n",
            "        return images\n",
            "        \n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 17:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "WIDTH = 320\n",
            "HEIGHT = 320\n",
            "\n",
            "\n",
            "class DataLoader:\n",
            "    def __init__(self, path: Path):\n",
            "        self.path = path\n",
            "        self.genders = [\"men\", \"Women\"]\n",
            "        self.desired_size = (WIDTH, HEIGHT)\n",
            "        \n",
            "    def load_data(self, data_augmentation=False):\n",
            "        try:\n",
            "            return self.load_saved_data()\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         except:\n",
            "            return self.start_load_data(data_augmentation)\n",
            "\n",
            "\n",
            "    def start_load_data(self, data_augmentation=False):\n",
            "        images = []\n",
            "        labels = []\n",
            "        x_train = []\n",
            "        y_train = []\n",
            "        x_test = []\n",
            "        y_test = []\n",
            "        x_val = []\n",
            "        y_val = []\n",
            "\n",
            "        for gender in self.genders:\n",
            "            for digit in range(6):\n",
            "                print(f\"current digit: {digit}\")\n",
            "                digit_path = self.path / gender / str(digit)\n",
            "                images = []\n",
            "                labels = []\n",
            "                for img_path in digit_path.glob(\"*.JPG\"):\n",
            "                    try:\n",
            "                        img = Image.open(img_path)\n",
            "                        images.append(np.array(img))\n",
            "                        labels.append(digit)\n",
            "                    except:\n",
            "                        print(\"Image {} is corrupted\".format(img_path))\n",
            "                        continue\n",
            "\n",
            "                images = np.array(images)\n",
            "                \n",
            "                images = self.resize_images(images)\n",
            "\n",
            "                x_train_temp, x_val_temp, y_train_temp, y_val_temp = train_test_split(\n",
            "                    images, labels, test_size=0.2, random_state=42\n",
            "                )\n",
            "                # x_train_temp, x_val_temp, y_train_temp, y_val_temp = train_test_split(\n",
            "                #     x_train_temp, y_train_temp, test_size=0.1 / 0.9, random_state=42\n",
            "                # )\n",
            "                x_train.extend(x_train_temp)\n",
            "                y_train.extend(y_train_temp)\n",
            "                # x_test.extend(x_test_temp)\n",
            "                x_val.extend(x_val_temp)\n",
            "                y_val.extend(y_val_temp)\n",
            "                # y_test.extend(y_test_temp)\n",
            "\n",
            "        x_train = np.array(x_train)\n",
            "        y_train = np.array(y_train)\n",
            "        # x_test = np.array(x_test)\n",
            "        # y_test = np.array(y_test)\n",
            "        x_val = np.array(x_val)\n",
            "        y_val = np.array(y_val)\n",
            "        \n",
            "        # shuffle the training data\n",
            "        indices = np.arange(x_train.shape[0])\n",
            "        np.random.shuffle(indices)\n",
            "        x_train = x_train[indices]\n",
            "        y_train = y_train[indices]\n",
            "\n",
            "        # shuffle the validation data\n",
            "        indices = np.arange(x_val.shape[0])\n",
            "        np.random.shuffle(indices)\n",
            "        x_val = x_val[indices]\n",
            "        y_val = y_val[indices]\n",
            "\n",
            "        if (data_augmentation):\n",
            "            x_train, y_train = self.data_augmentation(x_train, y_train)\n",
            "            y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
            "            \n",
            "        self.save_data(x_train, y_train, x_test, y_test, x_val, y_val)\n",
            "\n",
            "        return x_train, y_train, x_test, y_test, x_val, y_val\n",
            "\n",
            "    def save_data(self, x_train, y_train, x_test, y_test, x_val, y_val):\n",
            "        np.save(\"./data/x_train.npy\", x_train)\n",
            "        np.save(\"./data/y_train.npy\", y_train)\n",
            "        np.save(\"./data/x_test.npy\", x_test)\n",
            "        np.save(\"./data/y_test.npy\", y_test)\n",
            "        np.save(\"./data/x_val.npy\", x_val)\n",
            "        np.save(\"./data/y_val.npy\", y_val)\n",
            "\n",
            "    def load_saved_data(self):\n",
            "        x_train = np.load(\"./data/x_train.npy\")\n",
            "        y_train = np.load(\"./data/y_train.npy\")\n",
            "        x_test = np.load(\"./data/x_test.npy\")\n",
            "        y_test = np.load(\"./data/y_test.npy\")\n",
            "        x_val = np.load(\"./data/x_val.npy\")\n",
            "        y_val = np.load(\"./data/y_val.npy\")\n",
            "    \n",
            "        return x_train, y_train, x_test, y_test, x_val, y_val\n",
            "    \n",
            "    def data_augmentation(self, x_train, y_train):\n",
            "        #--------------------------------------DATA AUGMENTATION-----------------------------------------\n",
            "\n",
            "        # Define image data generator for data augmentation\n",
            "        datagen = ImageDataGenerator(\n",
            "            # rotation_range=40,  # randomly rotate images by up to 40 degrees\n",
            "            width_shift_range=0.3,  # randomly shift images horizontally by up to 30%\n",
            "            height_shift_range=0.3,  # randomly shift images vertically by up to 30%\n",
            "            shear_range=0.2,  # randomly apply shearing transformations\n",
            "            zoom_range=0.3,  # randomly zoom in on images by up to 30%\n",
            "            channel_shift_range=20,  # randomly adjust brightness\n",
            "            brightness_range=[0.5, 1.5],  # randomly adjust brightness\n",
            "            horizontal_flip=True,  # randomly flip images horizontally\n",
            "            vertical_flip=True,  # randomly flip images vertically\n",
            "            fill_mode='nearest'  # fill in any gaps with the nearest pixel value\n",
            "        )\n",
            "\n",
            "        # Fit the data generator to your training data\n",
            "        datagen.fit(x_train)\n",
            "\n",
            "        # Define a function to generate augmented images and labels\n",
            "\n",
            "        # Set batch size for training\n",
            "        batch_size = 300\n",
            "\n",
            "        # Generate augmented images and labels using the function defined above\n",
            "        augmented_data = self.generate_augmented_data(x_train, y_train, batch_size, datagen)\n",
            "        x_augmented, y_augmented = next(augmented_data)\n",
            "\n",
            "        # Concatenate the original training set and the augmented images\n",
            "        x_train = np.concatenate((x_train, x_augmented))\n",
            "\n",
            "        # Concatenate the original labels and the augmented labels\n",
            "        y_train = np.concatenate((y_train, y_augmented))\n",
            "        y_train = np.reshape(y_train,(y_train.shape[0],1))\n",
            "\n",
            "        return x_train, y_train\n",
            "\n",
            "    \n",
            "    \n",
            "    def generate_augmented_data(self, x, y, batch_size, datagen):\n",
            "        gen = datagen.flow(x, y, batch_size=batch_size)\n",
            "        while True:\n",
            "            x_batch, y_batch = gen.next()\n",
            "            yield x_batch, y_batch\n",
            "            \n",
            "    def resize_images(self,images):\n",
            "        images_resized = []\n",
            "        for img in images:\n",
            "            img = self.custom_resize_img(img)\n",
            "            images_resized.append(img)\n",
            "        \n",
            "        images_resized = np.array(images_resized)\n",
            "        return images_resized\n",
            "            \n",
            "            \n",
            "            \n",
            "    def custom_resize_img(self,img):\n",
            "        # Calculate the aspect ratio of the image\n",
            "        img = Image.fromarray(img)\n",
            "        img_width, img_height   = img.size\n",
            "        aspect_ratio = float(img_width) / float(img_height)\n",
            "\n",
            "        # resize the image so that the shortest side is equal to the desired size\n",
            "        if img_width < img_height:\n",
            "            new_width = int(self.desired_size[0] * aspect_ratio)\n",
            "            img = img.resize((new_width, self.desired_size[1]))\n",
            "        else:\n",
            "            new_height = int(self.desired_size[1] / aspect_ratio)\n",
            "            img = img.resize((self.desired_size[0], new_height))\n",
            "\n",
            "        # add padding to the image so that it is the desired size\n",
            "        delta_width = self.desired_size[0] - img.size[0]\n",
            "        delta_height = self.desired_size[1] - img.size[1]\n",
            "        left = int(delta_width / 2)\n",
            "        top = int(delta_height / 2)\n",
            "        right = self.desired_size[0] - img.size[0] - left\n",
            "        bottom = self.desired_size[1] - img.size[1] - top\n",
            "        img = ImageOps.expand(\n",
            "            img, border=(left, top, right, bottom), fill=(255,255,255)\n",
            "        )\n",
            "        img = np.array(img)\n",
            "        return img\n",
            "    \n",
            "    def load_test_data(self):\n",
            "        files = [f for f in os.listdir(self.path) if os.path.isfile(os.path.join(self.path, f))]\n",
            "\n",
            "        # Sort the list of files in increasing order\n",
            "        files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
            "\n",
            "        # Initialize an empty numpy array to store the images\n",
            "        images = np.empty((len(files),), dtype=object)\n",
            "\n",
            "        # Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
            "        for i, filename in enumerate(files):\n",
            "            img = cv2.imread(os.path.join(self.path, filename))\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "             images[i] = img\n",
            "        images = np.array(images)\n",
            "        return images\n",
            "        \n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 18:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "WIDTH = 320\n",
            "HEIGHT = 320\n",
            "\n",
            "\n",
            "class DataLoader:\n",
            "    def __init__(self, path: Path):\n",
            "        self.path = path\n",
            "        self.genders = [\"men\", \"Women\"]\n",
            "        self.desired_size = (WIDTH, HEIGHT)\n",
            "        \n",
            "    def load_data(self, data_augmentation=False):\n",
            "        try:\n",
            "            return self.load_saved_data()\n",
            "        except:\n",
            "            return self.start_load_data(data_augmentation)\n",
            "\n",
            "\n",
            "    def start_load_data(self, data_augmentation=False):\n",
            "        images = []\n",
            "        labels = []\n",
            "        x_train = []\n",
            "        y_train = []\n",
            "        x_test = []\n",
            "        y_test = []\n",
            "        x_val = []\n",
            "        y_val = []\n",
            "\n",
            "        for gender in self.genders:\n",
            "            for digit in range(6):\n",
            "                print(f\"current digit: {digit}\")\n",
            "                digit_path = self.path / gender / str(digit)\n",
            "                images = []\n",
            "                labels = []\n",
            "                for img_path in digit_path.glob(\"*.JPG\"):\n",
            "                    try:\n",
            "                        img = Image.open(img_path)\n",
            "                        images.append(np.array(img))\n",
            "                        labels.append(digit)\n",
            "                    except:\n",
            "                        print(\"Image {} is corrupted\".format(img_path))\n",
            "                        continue\n",
            "\n",
            "                images = np.array(images)\n",
            "                \n",
            "                images = self.resize_images(images)\n",
            "\n",
            "                x_train_temp, x_val_temp, y_train_temp, y_val_temp = train_test_split(\n",
            "                    images, labels, test_size=0.2, random_state=42\n",
            "                )\n",
            "                # x_train_temp, x_val_temp, y_train_temp, y_val_temp = train_test_split(\n",
            "                #     x_train_temp, y_train_temp, test_size=0.1 / 0.9, random_state=42\n",
            "                # )\n",
            "                x_train.extend(x_train_temp)\n",
            "                y_train.extend(y_train_temp)\n",
            "                # x_test.extend(x_test_temp)\n",
            "                x_val.extend(x_val_temp)\n",
            "                y_val.extend(y_val_temp)\n",
            "                # y_test.extend(y_test_temp)\n",
            "\n",
            "        x_train = np.array(x_train)\n",
            "        y_train = np.array(y_train)\n",
            "        # x_test = np.array(x_test)\n",
            "        # y_test = np.array(y_test)\n",
            "        x_val = np.array(x_val)\n",
            "        y_val = np.array(y_val)\n",
            "        \n",
            "        # shuffle the training data\n",
            "        indices = np.arange(x_train.shape[0])\n",
            "        np.random.shuffle(indices)\n",
            "        x_train = x_train[indices]\n",
            "        y_train = y_train[indices]\n",
            "\n",
            "        # shuffle the validation data\n",
            "        indices = np.arange(x_val.shape[0])\n",
            "        np.random.shuffle(indices)\n",
            "        x_val = x_val[indices]\n",
            "        y_val = y_val[indices]\n",
            "\n",
            "        if (data_augmentation):\n",
            "            x_train, y_train = self.data_augmentation(x_train, y_train)\n",
            "            y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
            "            \n",
            "        self.save_data(x_train, y_train, x_test, y_test, x_val, y_val)\n",
            "\n",
            "        return x_train, y_train, x_test, y_test, x_val, y_val\n",
            "\n",
            "    def save_data(self, x_train, y_train, x_test, y_test, x_val, y_val):\n",
            "        np.save(\"./data/x_train.npy\", x_train)\n",
            "        np.save(\"./data/y_train.npy\", y_train)\n",
            "        np.save(\"./data/x_test.npy\", x_test)\n",
            "        np.save(\"./data/y_test.npy\", y_test)\n",
            "        np.save(\"./data/x_val.npy\", x_val)\n",
            "        np.save(\"./data/y_val.npy\", y_val)\n",
            "\n",
            "    def load_saved_data(self):\n",
            "        x_train = np.load(\"./data/x_train.npy\")\n",
            "        y_train = np.load(\"./data/y_train.npy\")\n",
            "        x_test = np.load(\"./data/x_test.npy\")\n",
            "        y_test = np.load(\"./data/y_test.npy\")\n",
            "        x_val = np.load(\"./data/x_val.npy\")\n",
            "        y_val = np.load(\"./data/y_val.npy\")\n",
            "    \n",
            "        return x_train, y_train, x_test, y_test, x_val, y_val\n",
            "    \n",
            "    def data_augmentation(self, x_train, y_train):\n",
            "        #--------------------------------------DATA AUGMENTATION-----------------------------------------\n",
            "\n",
            "        # Define image data generator for data augmentation\n",
            "        datagen = ImageDataGenerator(\n",
            "            # rotation_range=40,  # randomly rotate images by up to 40 degrees\n",
            "            width_shift_range=0.3,  # randomly shift images horizontally by up to 30%\n",
            "            height_shift_range=0.3,  # randomly shift images vertically by up to 30%\n",
            "            shear_range=0.2,  # randomly apply shearing transformations\n",
            "            zoom_range=0.3,  # randomly zoom in on images by up to 30%\n",
            "            channel_shift_range=20,  # randomly adjust brightness\n",
            "            brightness_range=[0.5, 1.5],  # randomly adjust brightness\n",
            "            horizontal_flip=True,  # randomly flip images horizontally\n",
            "            vertical_flip=True,  # randomly flip images vertically\n",
            "            fill_mode='nearest'  # fill in any gaps with the nearest pixel value\n",
            "        )\n",
            "\n",
            "        # Fit the data generator to your training data\n",
            "        datagen.fit(x_train)\n",
            "\n",
            "        # Define a function to generate augmented images and labels\n",
            "\n",
            "        # Set batch size for training\n",
            "        batch_size = 300\n",
            "\n",
            "        # Generate augmented images and labels using the function defined above\n",
            "        augmented_data = self.generate_augmented_data(x_train, y_train, batch_size, datagen)\n",
            "        x_augmented, y_augmented = next(augmented_data)\n",
            "\n",
            "        # Concatenate the original training set and the augmented images\n",
            "        x_train = np.concatenate((x_train, x_augmented))\n",
            "\n",
            "        # Concatenate the original labels and the augmented labels\n",
            "        y_train = np.concatenate((y_train, y_augmented))\n",
            "        y_train = np.reshape(y_train,(y_train.shape[0],1))\n",
            "\n",
            "        return x_train, y_train\n",
            "\n",
            "    \n",
            "    \n",
            "    def generate_augmented_data(self, x, y, batch_size, datagen):\n",
            "        gen = datagen.flow(x, y, batch_size=batch_size)\n",
            "        while True:\n",
            "            x_batch, y_batch = gen.next()\n",
            "            yield x_batch, y_batch\n",
            "            \n",
            "    def resize_images(self,images):\n",
            "        images_resized = []\n",
            "        for img in images:\n",
            "            img = self.custom_resize_img(img)\n",
            "            images_resized.append(img)\n",
            "        \n",
            "        images_resized = np.array(images_resized)\n",
            "        return images_resized\n",
            "            \n",
            "            \n",
            "            \n",
            "    def custom_resize_img(self,img):\n",
            "        # Calculate the aspect ratio of the image\n",
            "        img = Image.fromarray(img)\n",
            "        img_width, img_height   = img.size\n",
            "        aspect_ratio = float(img_width) / float(img_height)\n",
            "\n",
            "        # resize the image so that the shortest side is equal to the desired size\n",
            "        if img_width < img_height:\n",
            "            new_width = int(self.desired_size[0] * aspect_ratio)\n",
            "            img = img.resize((new_width, self.desired_size[1]))\n",
            "        else:\n",
            "            new_height = int(self.desired_size[1] / aspect_ratio)\n",
            "            img = img.resize((self.desired_size[0], new_height))\n",
            "\n",
            "        # add padding to the image so that it is the desired size\n",
            "        delta_width = self.desired_size[0] - img.size[0]\n",
            "        delta_height = self.desired_size[1] - img.size[1]\n",
            "        left = int(delta_width / 2)\n",
            "        top = int(delta_height / 2)\n",
            "        right = self.desired_size[0] - img.size[0] - left\n",
            "        bottom = self.desired_size[1] - img.size[1] - top\n",
            "        img = ImageOps.expand(\n",
            "            img, border=(left, top, right, bottom), fill=(255,255,255)\n",
            "        )\n",
            "        img = np.array(img)\n",
            "        return img\n",
            "    \n",
            "    def load_test_data(self):\n",
            "        files = [f for f in os.listdir(self.path) if os.path.isfile(os.path.join(self.path, f))]\n",
            "\n",
            "        # Sort the list of files in increasing order\n",
            "        files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
            "\n",
            "        # Initialize an empty numpy array to store the images\n",
            "        images = np.empty((len(files),), dtype=object)\n",
            "\n",
            "        # Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
            "        for i, filename in enumerate(files):\n",
            "            img = cv2.imread(os.path.join(self.path, filename))\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "             images[i] = img\n",
            "        images = np.array(images)\n",
            "        return images\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         \n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 19:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "\"\"\"\n",
            "# Example usage:\n",
            "fe = FeatureExtractor()\n",
            "\n",
            "# Load a set of images...\n",
            "images = load_images()\n",
            "\n",
            "# Extract HOG features...\n",
            "hog_features = fe.extract_hog_features(images)\n",
            "\n",
            "# Extract LBP features...\n",
            "lbp_features = fe.extract_lbp_features(images)\n",
            "\n",
            "# Extract SIFT features...\n",
            "sift_features = fe.extract_sift_features(images)\n",
            "\n",
            "# Extract SURF features...\n",
            "surf_features = fe.extract_surf_features(images)\n",
            "\n",
            "# Extract Fourier Descriptor features...\n",
            "fourier_features = fe.extract_fourier_descriptor_features(images)\n",
            "\n",
            "# Extract PCA features...\n",
            "pca_features = fe.extract_pca_features(images)\n",
            "\"\"\"\n",
            "\n",
            "class FeatureExtractor:\n",
            "    def __init__(self):\n",
            "        self.sift_max_length = -1\n",
            "        \n",
            "\n",
            "\n",
            "    def extract_hog_features(self, images, hog_orientations=8, \n",
            "                             hog_pixels_per_cell=(32, 16), \n",
            "                             hog_cells_per_block=(2, 1)):\n",
            "        # Increasing size of hog_pixels_per_cell decreases size of o/p features\n",
            "        # Increasing size of hog_cells_per_block increases size of o/p features\n",
            "        #Array of images\n",
            "        hog_features = []\n",
            "        for i in range(images.shape[0]):\n",
            "            hog_feature = hog(images[i], \n",
            "                            orientations=hog_orientations,\n",
            "                            pixels_per_cell=hog_pixels_per_cell,\n",
            "                            cells_per_block=hog_cells_per_block,\n",
            "                            channel_axis = None)\n",
            "            hog_features.append(hog_feature)\n",
            "\n",
            "        return np.array(hog_features)\n",
            "    \n",
            "    def extract_lbp_features(self, images, lbp_num_points=8, lbp_radius=1):\n",
            "        lbp_features = []\n",
            "        for image in images:\n",
            "            feature = local_binary_pattern(image, lbp_num_points, lbp_radius)\n",
            "            feature = feature.flatten()\n",
            "            lbp_features.append(feature)\n",
            "        return np.array(lbp_features)\n",
            "\n",
            "    def extract_sift_features(self, _images, sift_num_features=128):\n",
            "        # sift = cv2.xfeatures2d.SIFT_create()\n",
            "        images = np.copy(_images)\n",
            "        images = images.astype(np.uint8)\n",
            "        sift = cv2.SIFT_create(nfeatures=sift_num_features, nOctaveLayers=5)\n",
            "        keypoints = []\n",
            "        sift_features = []\n",
            "        \n",
            "        failed_images = []\n",
            "        train_flag = False\n",
            "        if (self.sift_max_length == -1):\n",
            "            train_flag = True\n",
            "        for i in range(images.shape[0]):\n",
            "            # print(images[i].shape)\n",
            "            # plt.imshow(images[i])\n",
            "            # plt.show()\n",
            "            keypoints, s = sift.detectAndCompute(images[i], mask = None)\n",
            "            # print(i, type(s), end = ' ')\n",
            "            if (s is None):\n",
            "                # print('None')\n",
            "                # print('Keypoints: ', keypoints)\n",
            "                failed_images.append(i)\n",
            "                sift_features.append(np.zeros((0,0)))\n",
            "                continue\n",
            "            # print(s.shape)\n",
            "            s = s.flatten()\n",
            "            sift_features.append(s)\n",
            "            if (train_flag and len(s) > self.sift_max_length):\n",
            "                self.sift_max_length = len(s)\n",
            "\n",
            "        # Padding\n",
            "        for i in range(len(sift_features)):\n",
            "            if sift_features[i].shape[0] == 0:\n",
            "                sift_features[i] = np.zeros(self.sift_max_length)\n",
            "            elif sift_features[i].shape[0] < self.sift_max_length:\n",
            "                sift_features[i] = np.pad(sift_features[i], (0, self.sift_max_length - sift_features[i].shape[0]), 'constant')\n",
            "        sift_features = np.array(sift_features)\n",
            "        return sift_features\n",
            "    \n",
            "    def extract_daisy_features(self, images):\n",
            "        descs_features = []\n",
            "        \n",
            "        for image in images:\n",
            "            # descs = daisy(  image, \n",
            "            #                 step=180,\n",
            "            #                 radius=58,\n",
            "            #                 rings=2, \n",
            "            #                 histograms=6,\n",
            "            #                 orientations=8,\n",
            "            #                 visualize=False)\n",
            "\n",
            "            # A smaller value of step would result in a higher density of \n",
            "            # computation and a larger number of descriptors,\n",
            "            # while a larger value of step would result in a lower density of\n",
            "            # computation and a smaller number of descriptors\n",
            "\n",
            "            # radius: This parameter represents the radius (in pixels) of the outermost\n",
            "            # ring of the daisy grid. A larger value of radius would result in a larger area\n",
            "            # of the image being covered by the descriptors, while a smaller value of radius\n",
            "            # would result in a smaller area being covered.\n",
            "\n",
            "            # rings: This parameter represents the number of rings in the daisy grid. \n",
            "            # A larger value of rings would result in a larger number of descriptors being computed, \n",
            "            # while a smaller value of rings would result in a smaller number of descriptors.\n",
            "\n",
            "            # histograms: This parameter represents the number of histograms per ring. \n",
            "            # A larger value of histograms would result in a finer quantization of the gradient orientations, \n",
            "            # while a smaller value of histograms would result in a coarser quantization.\n",
            "\n",
            "            # orientations: This parameter represents the number of orientations per histogram. \n",
            "            # A larger value of orientations would result in a finer quantization of the gradient orientations, \n",
            "            # while a smaller value of orientations would result in a coarser quantization.\n",
            "\n",
            "            # visualize: This parameter specifies whether to return a visualization of the daisy descriptors. \n",
            "            # If set to True, the function would return both the descriptors and a visualization of the daisy \n",
            "            # grid overlaid on the input image.\n",
            "\n",
            "            # For example, you could try increasing the radius and/or rings parameters to \n",
            "            # cover a larger area of the image and capture more local features. \n",
            "            # Alternatively, you could try increasing the histograms and/or orientations parameters \n",
            "            # to capture more detailed information about the gradient orientations. \n",
            "            # However, keep in mind that increasing these parameters would also increase the \n",
            "            # computational cost of the function.\n",
            "\n",
            "            descs = daisy(  image, \n",
            "                            step=180,\n",
            "                            radius=58,\n",
            "                            rings=2, \n",
            "                            histograms=8,\n",
            "                            orientations=16,\n",
            "                            visualize=False)\n",
            "            descs = descs.flatten()\n",
            "            descs_features.append(descs)\n",
            "        descs_features = np.array(descs_features)\n",
            "        return descs_features\n",
            "    \n",
            "    def extract_fourier_descriptor_features(self, images, num_coeffs=20):\n",
            "        \n",
            "        contours = [max(cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0], key=cv2.contourArea)\n",
            "                    for image in images]\n",
            "        contour_complexes = [np.empty(contour.shape[:-1], dtype=complex) for contour in contours]\n",
            "        for i in range(len(contours)):\n",
            "            contour_complexes[i].real, contour_complexes[i].imag = contours[i][:, 0, 0], contours[i][:, 0, 1]\n",
            "        fourier_coeffs = [np.fft.fft(contour_complex)[:num_coeffs] for contour_complex in contour_complexes]\n",
            "        fourier_coeffs = np.array(fourier_coeffs)\n",
            "        return fourier_coeffs\n",
            "    \n",
            "    def extract_orb_features(self, images, features=100):\n",
            "        \n",
            "        descriptors = []\n",
            "        max_length = -1\n",
            "        for i in range(images.shape[0]):\n",
            "            image = images[i]\n",
            "            # Create an ORB object with specified parameters\n",
            "            orb = cv2.ORB_create(nfeatures=features, scaleFactor=1.2, nlevels=8)\n",
            "\n",
            "            # Detect keypoints in the image\n",
            "            keypoints = orb.detect(image, None)\n",
            "\n",
            "            # Compute descriptors for the keypoints\n",
            "            keypoints, descriptor = orb.compute(image, keypoints)\n",
            "            descriptor = descriptor.flatten()\n",
            "\n",
            "            descriptors.append(descriptor)\n",
            "\n",
            "            if len(descriptor) > max_length:\n",
            "                max_length = len(descriptor)\n",
            "\n",
            "        for i in range(len(descriptors)):\n",
            "            if len(descriptors[i]) < max_length:\n",
            "                descriptors[i] = np.pad(descriptors[i], (0, max_length - descriptors[i].shape[0]), 'constant')\n",
            "\n",
            "        # Return the descriptors as a numpy array\n",
            "        return np.array(descriptors)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "    def RI_HOG(self, images, cell_size=(8, 8), block_size=(2, 2), nbins=9, radius=1, neighbors=8):\n",
            "        descriptors = []\n",
            "        for image in images:\n",
            "\n",
            "            # Compute gradient magnitude and orientation\n",
            "            grad_x = cv2.Sobel(image, cv2.CV_32F, 1, 0)\n",
            "            grad_y = cv2.Sobel(image, cv2.CV_32F, 0, 1)\n",
            "            grad_mag, grad_orient = cv2.cartToPolar(grad_x, grad_y, angleInDegrees=True)\n",
            "\n",
            "            # Convert grad_mag to CV_8U type\n",
            "            grad_mag = cv2.convertScaleAbs(grad_mag)\n",
            "\n",
            "            # Compute HOG features\n",
            "            hog = cv2.HOGDescriptor(_winSize=(image.shape[1] // cell_size[1] * cell_size[1], image.shape[0] // cell_size[0] * cell_size[0]),\n",
            "                                    _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),\n",
            "                                    _blockStride=(cell_size[1], cell_size[0]),\n",
            "                                    _cellSize=(cell_size[1], cell_size[0]),\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "                                     _nbins=nbins)\n",
            "            hog_feat = hog.compute(grad_mag, winStride=(cell_size[1], cell_size[0]))\n",
            "\n",
            "            # Compute CLBP features\n",
            "            clbp_feat  = self.extract_lbp_features(np.array([image]), lbp_radius=radius, lbp_num_points=neighbors)[0]\n",
            "            \n",
            "            # Concatenate HOG and CLBP features\n",
            "            features = np.concatenate((hog_feat, clbp_feat))\n",
            "            descriptors.append(features.flatten())\n",
            "\n",
            "        descriptors = np.array(descriptors)\n",
            "        return descriptors\n",
            "\n",
            "    \n",
            "    def extract_hu_moments_features(self, images):\n",
            "        \n",
            "        hu_moments_list = []\n",
            "        for image in images:\n",
            "            \n",
            "            # Find contours in the binary image\n",
            "            contours  = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "\n",
            "            # Select the largest contour\n",
            "            contour = max(contours[0], key=cv2.contourArea)\n",
            "\n",
            "            # Calculate Hu moments\n",
            "            moments = cv2.moments(contour)\n",
            "            hu_moments = cv2.HuMoments(moments)\n",
            "\n",
            "            # Log transform Hu moments to make them scale invariant\n",
            "            hu_moments = -1 * np.sign(hu_moments) * np.log10(np.abs(hu_moments))\n",
            "\n",
            "            # Print Hu moments\n",
            "            hu_moments_list.append(hu_moments.flatten())\n",
            "\n",
            "        res = np.array(hu_moments_list)\n",
            "        return res\n",
            "    \n",
            "    def extract_convex_hull_features(self, images, max_length_train=-1):\n",
            "        features = []\n",
            "        for image in images:\n",
            "            # Find contours in the image\n",
            "            contours,_  = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "\n",
            "            # Find the convex hull of the largest contour\n",
            "            if len(contours) > 0:\n",
            "                largest_contour = max(contours, key=cv2.contourArea)\n",
            "                hull = cv2.convexHull(largest_contour)\n",
            "                if (len(hull.flatten()) > max_length_train):\n",
            "                    max_length_train = len(hull.flatten())\n",
            "                features.append(hull.flatten())\n",
            "            else:\n",
            "                # If there are no contours, append an array of zeros to the feature list\n",
            "                features.append(np.zeros(2))\n",
            "\n",
            "        for i in range(len(features)):\n",
            "            if len(features[i]) < max_length_train:\n",
            "                features[i] = np.pad(features[i], (0, max_length_train - features[i].shape[0]), 'constant')\n",
            "\n",
            "        return np.array(features), max_length_train\n",
            "\n",
            "    def elliptical_fourier_descriptors(self, imgs):\n",
            "\n",
            "        # Define the number of Fourier coefficients to calculate.\n",
            "        n_coeffs = 20\n",
            "\n",
            "        # Define the number of points to sample on each contour.\n",
            "        n_samples = 200\n",
            "\n",
            "        # Define the indices of the Fourier coefficients to keep.\n",
            "        coeffs_to_keep = range(1, 2*n_coeffs + 1)\n",
            "\n",
            "        # Define the output array.\n",
            "        efds = np.zeros((len(imgs), (n_coeffs * 4) - 1))\n",
            "\n",
            "        for i, img in enumerate(imgs):\n",
            "            # Find the contour of the image.\n",
            "            contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
            "\n",
            "            # Sample the contour.\n",
            "            contour = contours[0][:, 0, :]\n",
            "            contour = self.resample_contour(contour, n_samples)\n",
            "\n",
            "            # Calculate the complex Fourier coefficients of the contour.\n",
            "            fourier_coeffs = fft(contour[:, 0] + 1j * contour[:, 1])\n",
            "\n",
            "            # Take the first n_coeffs coefficients.\n",
            "            fourier_coeffs = fourier_coeffs[coeffs_to_keep]\n",
            "            # print(coeffs_to_keep)\n",
            "            # print(fourier_coeffs.shape)\n",
            "            # Calculate the elliptical Fourier descriptors.\n",
            "            a0 = np.real(fourier_coeffs[0]) / n_samples\n",
            "            b_coeffs = -np.imag(fourier_coeffs[1:]) / n_samples\n",
            "            a_coeffs = np.real(fourier_coeffs[1:]) / n_samples\n",
            "            # print(a0.shape, a_coeffs.shape, b_coeffs.shape)\n",
            "            efds_list = [a0]\n",
            "            efds_list.extend(np.ravel(a_coeffs))\n",
            "            efds_list.extend(np.ravel(b_coeffs))\n",
            "            # print(len(efds_list))\n",
            "            efds[i] = np.array(efds_list)\n",
            "\n",
            "        return efds\n",
            "    \n",
            "    def resample_contour(self, contour, n_samples):\n",
            "\n",
            "        # Calculate the arc length of the contour.\n",
            "        arc_length = np.cumsum(np.sqrt(np.sum(np.diff(contour, axis=0) ** 2, axis=1)))\n",
            "        arc_length = np.insert(arc_length, 0, 0) / arc_length[-1]\n",
            "\n",
            "        # Create a uniformly spaced grid of points along the arc length.\n",
            "        t = np.linspace(0, 1, n_samples)\n",
            "\n",
            "        # Interpolate the contour points along the arc length.\n",
            "        x = np.interp(t, arc_length, contour[:, 0])\n",
            "        y = np.interp(t, arc_length, contour[:, 1])\n",
            "\n",
            "        return np.column_stack((x, y))\n",
            "\n",
            "    def extract_efds_features(self, images):\n",
            "        # Load an image and extract a contour\n",
            "        coeffs = []\n",
            "        for image in images:    \n",
            "            binary_image = cv2.adaptiveThreshold(image, maxValue=255, \n",
            "                                                 adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
            "                                                thresholdType=cv2.THRESH_BINARY_INV,\n",
            "                                                    blockSize=11, C=2)\n",
            "            contour,_ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "            \n",
            "            contour = contour[0]\n",
            "            print(contour)\n",
            "            # print(np.all(binary_image == 0))\n",
            "            # plt.imshow(binary_image)\n",
            "            # plt.show()\n",
            "            # Compute the EFDs for the contour\n",
            "            num_coeff = 20\n",
            "            x = contour[:, 0, 0]\n",
            "            y = contour[:, 0, 1]\n",
            "            coeff = elliptic_fourier_descriptors(np.column_stack((x, y)), order=num_coeff, normalize=True)\n",
            "            coeffs.append(coeff.flatten())\n",
            "        return np.array(coeffs)\n",
            "        \n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 20:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "\"\"\"\n",
            "# Example usage:\n",
            "fe = FeatureExtractor()\n",
            "\n",
            "# Load a set of images...\n",
            "images = load_images()\n",
            "\n",
            "# Extract HOG features...\n",
            "hog_features = fe.extract_hog_features(images)\n",
            "\n",
            "# Extract LBP features...\n",
            "lbp_features = fe.extract_lbp_features(images)\n",
            "\n",
            "# Extract SIFT features...\n",
            "sift_features = fe.extract_sift_features(images)\n",
            "\n",
            "# Extract SURF features...\n",
            "surf_features = fe.extract_surf_features(images)\n",
            "\n",
            "# Extract Fourier Descriptor features...\n",
            "fourier_features = fe.extract_fourier_descriptor_features(images)\n",
            "\n",
            "# Extract PCA features...\n",
            "pca_features = fe.extract_pca_features(images)\n",
            "\"\"\"\n",
            "\n",
            "class FeatureExtractor:\n",
            "    def __init__(self):\n",
            "        self.sift_max_length = -1\n",
            "        \n",
            "\n",
            "\n",
            "    def extract_hog_features(self, images, hog_orientations=8, \n",
            "                             hog_pixels_per_cell=(32, 16), \n",
            "                             hog_cells_per_block=(2, 1)):\n",
            "        # Increasing size of hog_pixels_per_cell decreases size of o/p features\n",
            "        # Increasing size of hog_cells_per_block increases size of o/p features\n",
            "        #Array of images\n",
            "        hog_features = []\n",
            "        for i in range(images.shape[0]):\n",
            "            hog_feature = hog(images[i], \n",
            "                            orientations=hog_orientations,\n",
            "                            pixels_per_cell=hog_pixels_per_cell,\n",
            "                            cells_per_block=hog_cells_per_block,\n",
            "                            channel_axis = None)\n",
            "            hog_features.append(hog_feature)\n",
            "\n",
            "        return np.array(hog_features)\n",
            "    \n",
            "    def extract_lbp_features(self, images, lbp_num_points=8, lbp_radius=1):\n",
            "        lbp_features = []\n",
            "        for image in images:\n",
            "            feature = local_binary_pattern(image, lbp_num_points, lbp_radius)\n",
            "            feature = feature.flatten()\n",
            "            lbp_features.append(feature)\n",
            "        return np.array(lbp_features)\n",
            "\n",
            "    def extract_sift_features(self, _images, sift_num_features=128):\n",
            "        # sift = cv2.xfeatures2d.SIFT_create()\n",
            "        images = np.copy(_images)\n",
            "        images = images.astype(np.uint8)\n",
            "        sift = cv2.SIFT_create(nfeatures=sift_num_features, nOctaveLayers=5)\n",
            "        keypoints = []\n",
            "        sift_features = []\n",
            "        \n",
            "        failed_images = []\n",
            "        train_flag = False\n",
            "        if (self.sift_max_length == -1):\n",
            "            train_flag = True\n",
            "        for i in range(images.shape[0]):\n",
            "            # print(images[i].shape)\n",
            "            # plt.imshow(images[i])\n",
            "            # plt.show()\n",
            "            keypoints, s = sift.detectAndCompute(images[i], mask = None)\n",
            "            # print(i, type(s), end = ' ')\n",
            "            if (s is None):\n",
            "                # print('None')\n",
            "                # print('Keypoints: ', keypoints)\n",
            "                failed_images.append(i)\n",
            "                sift_features.append(np.zeros((0,0)))\n",
            "                continue\n",
            "            # print(s.shape)\n",
            "            s = s.flatten()\n",
            "            sift_features.append(s)\n",
            "            if (train_flag and len(s) > self.sift_max_length):\n",
            "                self.sift_max_length = len(s)\n",
            "\n",
            "        # Padding\n",
            "        for i in range(len(sift_features)):\n",
            "            if sift_features[i].shape[0] == 0:\n",
            "                sift_features[i] = np.zeros(self.sift_max_length)\n",
            "            elif sift_features[i].shape[0] < self.sift_max_length:\n",
            "                sift_features[i] = np.pad(sift_features[i], (0, self.sift_max_length - sift_features[i].shape[0]), 'constant')\n",
            "        sift_features = np.array(sift_features)\n",
            "        return sift_features\n",
            "    \n",
            "    def extract_daisy_features(self, images):\n",
            "        descs_features = []\n",
            "        \n",
            "        for image in images:\n",
            "            # descs = daisy(  image, \n",
            "            #                 step=180,\n",
            "            #                 radius=58,\n",
            "            #                 rings=2, \n",
            "            #                 histograms=6,\n",
            "            #                 orientations=8,\n",
            "            #                 visualize=False)\n",
            "\n",
            "            # A smaller value of step would result in a higher density of \n",
            "            # computation and a larger number of descriptors,\n",
            "            # while a larger value of step would result in a lower density of\n",
            "            # computation and a smaller number of descriptors\n",
            "\n",
            "            # radius: This parameter represents the radius (in pixels) of the outermost\n",
            "            # ring of the daisy grid. A larger value of radius would result in a larger area\n",
            "            # of the image being covered by the descriptors, while a smaller value of radius\n",
            "            # would result in a smaller area being covered.\n",
            "\n",
            "            # rings: This parameter represents the number of rings in the daisy grid. \n",
            "            # A larger value of rings would result in a larger number of descriptors being computed, \n",
            "            # while a smaller value of rings would result in a smaller number of descriptors.\n",
            "\n",
            "            # histograms: This parameter represents the number of histograms per ring. \n",
            "            # A larger value of histograms would result in a finer quantization of the gradient orientations, \n",
            "            # while a smaller value of histograms would result in a coarser quantization.\n",
            "\n",
            "            # orientations: This parameter represents the number of orientations per histogram. \n",
            "            # A larger value of orientations would result in a finer quantization of the gradient orientations, \n",
            "            # while a smaller value of orientations would result in a coarser quantization.\n",
            "\n",
            "            # visualize: This parameter specifies whether to return a visualization of the daisy descriptors. \n",
            "            # If set to True, the function would return both the descriptors and a visualization of the daisy \n",
            "            # grid overlaid on the input image.\n",
            "\n",
            "            # For example, you could try increasing the radius and/or rings parameters to \n",
            "            # cover a larger area of the image and capture more local features. \n",
            "            # Alternatively, you could try increasing the histograms and/or orientations parameters \n",
            "            # to capture more detailed information about the gradient orientations. \n",
            "            # However, keep in mind that increasing these parameters would also increase the \n",
            "            # computational cost of the function.\n",
            "\n",
            "            descs = daisy(  image, \n",
            "                            step=180,\n",
            "                            radius=58,\n",
            "                            rings=2, \n",
            "                            histograms=8,\n",
            "                            orientations=16,\n",
            "                            visualize=False)\n",
            "            descs = descs.flatten()\n",
            "            descs_features.append(descs)\n",
            "        descs_features = np.array(descs_features)\n",
            "        return descs_features\n",
            "    \n",
            "    def extract_fourier_descriptor_features(self, images, num_coeffs=20):\n",
            "        \n",
            "        contours = [max(cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0], key=cv2.contourArea)\n",
            "                    for image in images]\n",
            "        contour_complexes = [np.empty(contour.shape[:-1], dtype=complex) for contour in contours]\n",
            "        for i in range(len(contours)):\n",
            "            contour_complexes[i].real, contour_complexes[i].imag = contours[i][:, 0, 0], contours[i][:, 0, 1]\n",
            "        fourier_coeffs = [np.fft.fft(contour_complex)[:num_coeffs] for contour_complex in contour_complexes]\n",
            "        fourier_coeffs = np.array(fourier_coeffs)\n",
            "        return fourier_coeffs\n",
            "    \n",
            "    def extract_orb_features(self, images, features=100):\n",
            "        \n",
            "        descriptors = []\n",
            "        max_length = -1\n",
            "        for i in range(images.shape[0]):\n",
            "            image = images[i]\n",
            "            # Create an ORB object with specified parameters\n",
            "            orb = cv2.ORB_create(nfeatures=features, scaleFactor=1.2, nlevels=8)\n",
            "\n",
            "            # Detect keypoints in the image\n",
            "            keypoints = orb.detect(image, None)\n",
            "\n",
            "            # Compute descriptors for the keypoints\n",
            "            keypoints, descriptor = orb.compute(image, keypoints)\n",
            "            descriptor = descriptor.flatten()\n",
            "\n",
            "            descriptors.append(descriptor)\n",
            "\n",
            "            if len(descriptor) > max_length:\n",
            "                max_length = len(descriptor)\n",
            "\n",
            "        for i in range(len(descriptors)):\n",
            "            if len(descriptors[i]) < max_length:\n",
            "                descriptors[i] = np.pad(descriptors[i], (0, max_length - descriptors[i].shape[0]), 'constant')\n",
            "\n",
            "        # Return the descriptors as a numpy array\n",
            "        return np.array(descriptors)\n",
            "\n",
            "    def RI_HOG(self, images, cell_size=(8, 8), block_size=(2, 2), nbins=9, radius=1, neighbors=8):\n",
            "        descriptors = []\n",
            "        for image in images:\n",
            "\n",
            "            # Compute gradient magnitude and orientation\n",
            "            grad_x = cv2.Sobel(image, cv2.CV_32F, 1, 0)\n",
            "            grad_y = cv2.Sobel(image, cv2.CV_32F, 0, 1)\n",
            "            grad_mag, grad_orient = cv2.cartToPolar(grad_x, grad_y, angleInDegrees=True)\n",
            "\n",
            "            # Convert grad_mag to CV_8U type\n",
            "            grad_mag = cv2.convertScaleAbs(grad_mag)\n",
            "\n",
            "            # Compute HOG features\n",
            "            hog = cv2.HOGDescriptor(_winSize=(image.shape[1] // cell_size[1] * cell_size[1], image.shape[0] // cell_size[0] * cell_size[0]),\n",
            "                                    _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),\n",
            "                                    _blockStride=(cell_size[1], cell_size[0]),\n",
            "                                    _cellSize=(cell_size[1], cell_size[0]),\n",
            "                                    _nbins=nbins)\n",
            "            hog_feat = hog.compute(grad_mag, winStride=(cell_size[1], cell_size[0]))\n",
            "\n",
            "            # Compute CLBP features\n",
            "            clbp_feat  = self.extract_lbp_features(np.array([image]), lbp_radius=radius, lbp_num_points=neighbors)[0]\n",
            "            \n",
            "            # Concatenate HOG and CLBP features\n",
            "            features = np.concatenate((hog_feat, clbp_feat))\n",
            "            descriptors.append(features.flatten())\n",
            "\n",
            "        descriptors = np.array(descriptors)\n",
            "        return descriptors\n",
            "\n",
            "    \n",
            "    def extract_hu_moments_features(self, images):\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         \n",
            "        hu_moments_list = []\n",
            "        for image in images:\n",
            "            \n",
            "            # Find contours in the binary image\n",
            "            contours  = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "\n",
            "            # Select the largest contour\n",
            "            contour = max(contours[0], key=cv2.contourArea)\n",
            "\n",
            "            # Calculate Hu moments\n",
            "            moments = cv2.moments(contour)\n",
            "            hu_moments = cv2.HuMoments(moments)\n",
            "\n",
            "            # Log transform Hu moments to make them scale invariant\n",
            "            hu_moments = -1 * np.sign(hu_moments) * np.log10(np.abs(hu_moments))\n",
            "\n",
            "            # Print Hu moments\n",
            "            hu_moments_list.append(hu_moments.flatten())\n",
            "\n",
            "        res = np.array(hu_moments_list)\n",
            "        return res\n",
            "    \n",
            "    def extract_convex_hull_features(self, images, max_length_train=-1):\n",
            "        features = []\n",
            "        for image in images:\n",
            "            # Find contours in the image\n",
            "            contours,_  = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "\n",
            "            # Find the convex hull of the largest contour\n",
            "            if len(contours) > 0:\n",
            "                largest_contour = max(contours, key=cv2.contourArea)\n",
            "                hull = cv2.convexHull(largest_contour)\n",
            "                if (len(hull.flatten()) > max_length_train):\n",
            "                    max_length_train = len(hull.flatten())\n",
            "                features.append(hull.flatten())\n",
            "            else:\n",
            "                # If there are no contours, append an array of zeros to the feature list\n",
            "                features.append(np.zeros(2))\n",
            "\n",
            "        for i in range(len(features)):\n",
            "            if len(features[i]) < max_length_train:\n",
            "                features[i] = np.pad(features[i], (0, max_length_train - features[i].shape[0]), 'constant')\n",
            "\n",
            "        return np.array(features), max_length_train\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "     def elliptical_fourier_descriptors(self, imgs):\n",
            "\n",
            "        # Define the number of Fourier coefficients to calculate.\n",
            "        n_coeffs = 20\n",
            "\n",
            "        # Define the number of points to sample on each contour.\n",
            "        n_samples = 200\n",
            "\n",
            "        # Define the indices of the Fourier coefficients to keep.\n",
            "        coeffs_to_keep = range(1, 2*n_coeffs + 1)\n",
            "\n",
            "        # Define the output array.\n",
            "        efds = np.zeros((len(imgs), (n_coeffs * 4) - 1))\n",
            "\n",
            "        for i, img in enumerate(imgs):\n",
            "            # Find the contour of the image.\n",
            "            contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
            "\n",
            "            # Sample the contour.\n",
            "            contour = contours[0][:, 0, :]\n",
            "            contour = self.resample_contour(contour, n_samples)\n",
            "\n",
            "            # Calculate the complex Fourier coefficients of the contour.\n",
            "            fourier_coeffs = fft(contour[:, 0] + 1j * contour[:, 1])\n",
            "\n",
            "            # Take the first n_coeffs coefficients.\n",
            "            fourier_coeffs = fourier_coeffs[coeffs_to_keep]\n",
            "            # print(coeffs_to_keep)\n",
            "            # print(fourier_coeffs.shape)\n",
            "            # Calculate the elliptical Fourier descriptors.\n",
            "            a0 = np.real(fourier_coeffs[0]) / n_samples\n",
            "            b_coeffs = -np.imag(fourier_coeffs[1:]) / n_samples\n",
            "            a_coeffs = np.real(fourier_coeffs[1:]) / n_samples\n",
            "            # print(a0.shape, a_coeffs.shape, b_coeffs.shape)\n",
            "            efds_list = [a0]\n",
            "            efds_list.extend(np.ravel(a_coeffs))\n",
            "            efds_list.extend(np.ravel(b_coeffs))\n",
            "            # print(len(efds_list))\n",
            "            efds[i] = np.array(efds_list)\n",
            "\n",
            "        return efds\n",
            "    \n",
            "    def resample_contour(self, contour, n_samples):\n",
            "\n",
            "        # Calculate the arc length of the contour.\n",
            "        arc_length = np.cumsum(np.sqrt(np.sum(np.diff(contour, axis=0) ** 2, axis=1)))\n",
            "        arc_length = np.insert(arc_length, 0, 0) / arc_length[-1]\n",
            "\n",
            "        # Create a uniformly spaced grid of points along the arc length.\n",
            "        t = np.linspace(0, 1, n_samples)\n",
            "\n",
            "        # Interpolate the contour points along the arc length.\n",
            "        x = np.interp(t, arc_length, contour[:, 0])\n",
            "        y = np.interp(t, arc_length, contour[:, 1])\n",
            "\n",
            "        return np.column_stack((x, y))\n",
            "\n",
            "    def extract_efds_features(self, images):\n",
            "        # Load an image and extract a contour\n",
            "        coeffs = []\n",
            "        for image in images:    \n",
            "            binary_image = cv2.adaptiveThreshold(image, maxValue=255, \n",
            "                                                 adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
            "                                                thresholdType=cv2.THRESH_BINARY_INV,\n",
            "                                                    blockSize=11, C=2)\n",
            "            contour,_ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "            \n",
            "            contour = contour[0]\n",
            "            print(contour)\n",
            "            # print(np.all(binary_image == 0))\n",
            "            # plt.imshow(binary_image)\n",
            "            # plt.show()\n",
            "            # Compute the EFDs for the contour\n",
            "            num_coeff = 20\n",
            "            x = contour[:, 0, 0]\n",
            "            y = contour[:, 0, 1]\n",
            "            coeff = elliptic_fourier_descriptors(np.column_stack((x, y)), order=num_coeff, normalize=True)\n",
            "            coeffs.append(coeff.flatten())\n",
            "        return np.array(coeffs)\n",
            "        \n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 21:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "\"\"\"\n",
            "# Example usage:\n",
            "fe = FeatureExtractor()\n",
            "\n",
            "# Load a set of images...\n",
            "images = load_images()\n",
            "\n",
            "# Extract HOG features...\n",
            "hog_features = fe.extract_hog_features(images)\n",
            "\n",
            "# Extract LBP features...\n",
            "lbp_features = fe.extract_lbp_features(images)\n",
            "\n",
            "# Extract SIFT features...\n",
            "sift_features = fe.extract_sift_features(images)\n",
            "\n",
            "# Extract SURF features...\n",
            "surf_features = fe.extract_surf_features(images)\n",
            "\n",
            "# Extract Fourier Descriptor features...\n",
            "fourier_features = fe.extract_fourier_descriptor_features(images)\n",
            "\n",
            "# Extract PCA features...\n",
            "pca_features = fe.extract_pca_features(images)\n",
            "\"\"\"\n",
            "\n",
            "class FeatureExtractor:\n",
            "    def __init__(self):\n",
            "        self.sift_max_length = -1\n",
            "        \n",
            "\n",
            "\n",
            "    def extract_hog_features(self, images, hog_orientations=8, \n",
            "                             hog_pixels_per_cell=(32, 16), \n",
            "                             hog_cells_per_block=(2, 1)):\n",
            "        # Increasing size of hog_pixels_per_cell decreases size of o/p features\n",
            "        # Increasing size of hog_cells_per_block increases size of o/p features\n",
            "        #Array of images\n",
            "        hog_features = []\n",
            "        for i in range(images.shape[0]):\n",
            "            hog_feature = hog(images[i], \n",
            "                            orientations=hog_orientations,\n",
            "                            pixels_per_cell=hog_pixels_per_cell,\n",
            "                            cells_per_block=hog_cells_per_block,\n",
            "                            channel_axis = None)\n",
            "            hog_features.append(hog_feature)\n",
            "\n",
            "        return np.array(hog_features)\n",
            "    \n",
            "    def extract_lbp_features(self, images, lbp_num_points=8, lbp_radius=1):\n",
            "        lbp_features = []\n",
            "        for image in images:\n",
            "            feature = local_binary_pattern(image, lbp_num_points, lbp_radius)\n",
            "            feature = feature.flatten()\n",
            "            lbp_features.append(feature)\n",
            "        return np.array(lbp_features)\n",
            "\n",
            "    def extract_sift_features(self, _images, sift_num_features=128):\n",
            "        # sift = cv2.xfeatures2d.SIFT_create()\n",
            "        images = np.copy(_images)\n",
            "        images = images.astype(np.uint8)\n",
            "        sift = cv2.SIFT_create(nfeatures=sift_num_features, nOctaveLayers=5)\n",
            "        keypoints = []\n",
            "        sift_features = []\n",
            "        \n",
            "        failed_images = []\n",
            "        train_flag = False\n",
            "        if (self.sift_max_length == -1):\n",
            "            train_flag = True\n",
            "        for i in range(images.shape[0]):\n",
            "            # print(images[i].shape)\n",
            "            # plt.imshow(images[i])\n",
            "            # plt.show()\n",
            "            keypoints, s = sift.detectAndCompute(images[i], mask = None)\n",
            "            # print(i, type(s), end = ' ')\n",
            "            if (s is None):\n",
            "                # print('None')\n",
            "                # print('Keypoints: ', keypoints)\n",
            "                failed_images.append(i)\n",
            "                sift_features.append(np.zeros((0,0)))\n",
            "                continue\n",
            "            # print(s.shape)\n",
            "            s = s.flatten()\n",
            "            sift_features.append(s)\n",
            "            if (train_flag and len(s) > self.sift_max_length):\n",
            "                self.sift_max_length = len(s)\n",
            "\n",
            "        # Padding\n",
            "        for i in range(len(sift_features)):\n",
            "            if sift_features[i].shape[0] == 0:\n",
            "                sift_features[i] = np.zeros(self.sift_max_length)\n",
            "            elif sift_features[i].shape[0] < self.sift_max_length:\n",
            "                sift_features[i] = np.pad(sift_features[i], (0, self.sift_max_length - sift_features[i].shape[0]), 'constant')\n",
            "        sift_features = np.array(sift_features)\n",
            "        return sift_features\n",
            "    \n",
            "    def extract_daisy_features(self, images):\n",
            "        descs_features = []\n",
            "        \n",
            "        for image in images:\n",
            "            # descs = daisy(  image, \n",
            "            #                 step=180,\n",
            "            #                 radius=58,\n",
            "            #                 rings=2, \n",
            "            #                 histograms=6,\n",
            "            #                 orientations=8,\n",
            "            #                 visualize=False)\n",
            "\n",
            "            # A smaller value of step would result in a higher density of \n",
            "            # computation and a larger number of descriptors,\n",
            "            # while a larger value of step would result in a lower density of\n",
            "            # computation and a smaller number of descriptors\n",
            "\n",
            "            # radius: This parameter represents the radius (in pixels) of the outermost\n",
            "            # ring of the daisy grid. A larger value of radius would result in a larger area\n",
            "            # of the image being covered by the descriptors, while a smaller value of radius\n",
            "            # would result in a smaller area being covered.\n",
            "\n",
            "            # rings: This parameter represents the number of rings in the daisy grid. \n",
            "            # A larger value of rings would result in a larger number of descriptors being computed, \n",
            "            # while a smaller value of rings would result in a smaller number of descriptors.\n",
            "\n",
            "            # histograms: This parameter represents the number of histograms per ring. \n",
            "            # A larger value of histograms would result in a finer quantization of the gradient orientations, \n",
            "            # while a smaller value of histograms would result in a coarser quantization.\n",
            "\n",
            "            # orientations: This parameter represents the number of orientations per histogram. \n",
            "            # A larger value of orientations would result in a finer quantization of the gradient orientations, \n",
            "            # while a smaller value of orientations would result in a coarser quantization.\n",
            "\n",
            "            # visualize: This parameter specifies whether to return a visualization of the daisy descriptors. \n",
            "            # If set to True, the function would return both the descriptors and a visualization of the daisy \n",
            "            # grid overlaid on the input image.\n",
            "\n",
            "            # For example, you could try increasing the radius and/or rings parameters to \n",
            "            # cover a larger area of the image and capture more local features. \n",
            "            # Alternatively, you could try increasing the histograms and/or orientations parameters \n",
            "            # to capture more detailed information about the gradient orientations. \n",
            "            # However, keep in mind that increasing these parameters would also increase the \n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "             # computational cost of the function.\n",
            "\n",
            "            descs = daisy(  image, \n",
            "                            step=180,\n",
            "                            radius=58,\n",
            "                            rings=2, \n",
            "                            histograms=8,\n",
            "                            orientations=16,\n",
            "                            visualize=False)\n",
            "            descs = descs.flatten()\n",
            "            descs_features.append(descs)\n",
            "        descs_features = np.array(descs_features)\n",
            "        return descs_features\n",
            "    \n",
            "    def extract_fourier_descriptor_features(self, images, num_coeffs=20):\n",
            "        \n",
            "        contours = [max(cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0], key=cv2.contourArea)\n",
            "                    for image in images]\n",
            "        contour_complexes = [np.empty(contour.shape[:-1], dtype=complex) for contour in contours]\n",
            "        for i in range(len(contours)):\n",
            "            contour_complexes[i].real, contour_complexes[i].imag = contours[i][:, 0, 0], contours[i][:, 0, 1]\n",
            "        fourier_coeffs = [np.fft.fft(contour_complex)[:num_coeffs] for contour_complex in contour_complexes]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         fourier_coeffs = np.array(fourier_coeffs)\n",
            "        return fourier_coeffs\n",
            "    \n",
            "    def extract_orb_features(self, images, features=100):\n",
            "        \n",
            "        descriptors = []\n",
            "        max_length = -1\n",
            "        for i in range(images.shape[0]):\n",
            "            image = images[i]\n",
            "            # Create an ORB object with specified parameters\n",
            "            orb = cv2.ORB_create(nfeatures=features, scaleFactor=1.2, nlevels=8)\n",
            "\n",
            "            # Detect keypoints in the image\n",
            "            keypoints = orb.detect(image, None)\n",
            "\n",
            "            # Compute descriptors for the keypoints\n",
            "            keypoints, descriptor = orb.compute(image, keypoints)\n",
            "            descriptor = descriptor.flatten()\n",
            "\n",
            "            descriptors.append(descriptor)\n",
            "\n",
            "            if len(descriptor) > max_length:\n",
            "                max_length = len(descriptor)\n",
            "\n",
            "        for i in range(len(descriptors)):\n",
            "            if len(descriptors[i]) < max_length:\n",
            "                descriptors[i] = np.pad(descriptors[i], (0, max_length - descriptors[i].shape[0]), 'constant')\n",
            "\n",
            "        # Return the descriptors as a numpy array\n",
            "        return np.array(descriptors)\n",
            "\n",
            "    def RI_HOG(self, images, cell_size=(8, 8), block_size=(2, 2), nbins=9, radius=1, neighbors=8):\n",
            "        descriptors = []\n",
            "        for image in images:\n",
            "\n",
            "            # Compute gradient magnitude and orientation\n",
            "            grad_x = cv2.Sobel(image, cv2.CV_32F, 1, 0)\n",
            "            grad_y = cv2.Sobel(image, cv2.CV_32F, 0, 1)\n",
            "            grad_mag, grad_orient = cv2.cartToPolar(grad_x, grad_y, angleInDegrees=True)\n",
            "\n",
            "            # Convert grad_mag to CV_8U type\n",
            "            grad_mag = cv2.convertScaleAbs(grad_mag)\n",
            "\n",
            "            # Compute HOG features\n",
            "            hog = cv2.HOGDescriptor(_winSize=(image.shape[1] // cell_size[1] * cell_size[1], image.shape[0] // cell_size[0] * cell_size[0]),\n",
            "                                    _blockSize=(block_size[1] * cell_size[1], block_size[0] * cell_size[0]),\n",
            "                                    _blockStride=(cell_size[1], cell_size[0]),\n",
            "                                    _cellSize=(cell_size[1], cell_size[0]),\n",
            "                                    _nbins=nbins)\n",
            "            hog_feat = hog.compute(grad_mag, winStride=(cell_size[1], cell_size[0]))\n",
            "\n",
            "            # Compute CLBP features\n",
            "            clbp_feat  = self.extract_lbp_features(np.array([image]), lbp_radius=radius, lbp_num_points=neighbors)[0]\n",
            "            \n",
            "            # Concatenate HOG and CLBP features\n",
            "            features = np.concatenate((hog_feat, clbp_feat))\n",
            "            descriptors.append(features.flatten())\n",
            "\n",
            "        descriptors = np.array(descriptors)\n",
            "        return descriptors\n",
            "\n",
            "    \n",
            "    def extract_hu_moments_features(self, images):\n",
            "        \n",
            "        hu_moments_list = []\n",
            "        for image in images:\n",
            "            \n",
            "            # Find contours in the binary image\n",
            "            contours  = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "\n",
            "            # Select the largest contour\n",
            "            contour = max(contours[0], key=cv2.contourArea)\n",
            "\n",
            "            # Calculate Hu moments\n",
            "            moments = cv2.moments(contour)\n",
            "            hu_moments = cv2.HuMoments(moments)\n",
            "\n",
            "            # Log transform Hu moments to make them scale invariant\n",
            "            hu_moments = -1 * np.sign(hu_moments) * np.log10(np.abs(hu_moments))\n",
            "\n",
            "            # Print Hu moments\n",
            "            hu_moments_list.append(hu_moments.flatten())\n",
            "\n",
            "        res = np.array(hu_moments_list)\n",
            "        return res\n",
            "    \n",
            "    def extract_convex_hull_features(self, images, max_length_train=-1):\n",
            "        features = []\n",
            "        for image in images:\n",
            "            # Find contours in the image\n",
            "            contours,_  = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "\n",
            "            # Find the convex hull of the largest contour\n",
            "            if len(contours) > 0:\n",
            "                largest_contour = max(contours, key=cv2.contourArea)\n",
            "                hull = cv2.convexHull(largest_contour)\n",
            "                if (len(hull.flatten()) > max_length_train):\n",
            "                    max_length_train = len(hull.flatten())\n",
            "                features.append(hull.flatten())\n",
            "            else:\n",
            "                # If there are no contours, append an array of zeros to the feature list\n",
            "                features.append(np.zeros(2))\n",
            "\n",
            "        for i in range(len(features)):\n",
            "            if len(features[i]) < max_length_train:\n",
            "                features[i] = np.pad(features[i], (0, max_length_train - features[i].shape[0]), 'constant')\n",
            "\n",
            "        return np.array(features), max_length_train\n",
            "\n",
            "    def elliptical_fourier_descriptors(self, imgs):\n",
            "\n",
            "        # Define the number of Fourier coefficients to calculate.\n",
            "        n_coeffs = 20\n",
            "\n",
            "        # Define the number of points to sample on each contour.\n",
            "        n_samples = 200\n",
            "\n",
            "        # Define the indices of the Fourier coefficients to keep.\n",
            "        coeffs_to_keep = range(1, 2*n_coeffs + 1)\n",
            "\n",
            "        # Define the output array.\n",
            "        efds = np.zeros((len(imgs), (n_coeffs * 4) - 1))\n",
            "\n",
            "        for i, img in enumerate(imgs):\n",
            "            # Find the contour of the image.\n",
            "            contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
            "\n",
            "            # Sample the contour.\n",
            "            contour = contours[0][:, 0, :]\n",
            "            contour = self.resample_contour(contour, n_samples)\n",
            "\n",
            "            # Calculate the complex Fourier coefficients of the contour.\n",
            "            fourier_coeffs = fft(contour[:, 0] + 1j * contour[:, 1])\n",
            "\n",
            "            # Take the first n_coeffs coefficients.\n",
            "            fourier_coeffs = fourier_coeffs[coeffs_to_keep]\n",
            "            # print(coeffs_to_keep)\n",
            "            # print(fourier_coeffs.shape)\n",
            "            # Calculate the elliptical Fourier descriptors.\n",
            "            a0 = np.real(fourier_coeffs[0]) / n_samples\n",
            "            b_coeffs = -np.imag(fourier_coeffs[1:]) / n_samples\n",
            "            a_coeffs = np.real(fourier_coeffs[1:]) / n_samples\n",
            "            # print(a0.shape, a_coeffs.shape, b_coeffs.shape)\n",
            "            efds_list = [a0]\n",
            "            efds_list.extend(np.ravel(a_coeffs))\n",
            "            efds_list.extend(np.ravel(b_coeffs))\n",
            "            # print(len(efds_list))\n",
            "            efds[i] = np.array(efds_list)\n",
            "\n",
            "        return efds\n",
            "    \n",
            "    def resample_contour(self, contour, n_samples):\n",
            "\n",
            "        # Calculate the arc length of the contour.\n",
            "        arc_length = np.cumsum(np.sqrt(np.sum(np.diff(contour, axis=0) ** 2, axis=1)))\n",
            "        arc_length = np.insert(arc_length, 0, 0) / arc_length[-1]\n",
            "\n",
            "        # Create a uniformly spaced grid of points along the arc length.\n",
            "        t = np.linspace(0, 1, n_samples)\n",
            "\n",
            "        # Interpolate the contour points along the arc length.\n",
            "        x = np.interp(t, arc_length, contour[:, 0])\n",
            "        y = np.interp(t, arc_length, contour[:, 1])\n",
            "\n",
            "        return np.column_stack((x, y))\n",
            "\n",
            "    def extract_efds_features(self, images):\n",
            "        # Load an image and extract a contour\n",
            "        coeffs = []\n",
            "        for image in images:    \n",
            "            binary_image = cv2.adaptiveThreshold(image, maxValue=255, \n",
            "                                                 adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
            "                                                thresholdType=cv2.THRESH_BINARY_INV,\n",
            "                                                    blockSize=11, C=2)\n",
            "            contour,_ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
            "            \n",
            "            contour = contour[0]\n",
            "            print(contour)\n",
            "            # print(np.all(binary_image == 0))\n",
            "            # plt.imshow(binary_image)\n",
            "            # plt.show()\n",
            "            # Compute the EFDs for the contour\n",
            "            num_coeff = 20\n",
            "            x = contour[:, 0, 0]\n",
            "            y = contour[:, 0, 1]\n",
            "            coeff = elliptic_fourier_descriptors(np.column_stack((x, y)), order=num_coeff, normalize=True)\n",
            "            coeffs.append(coeff.flatten())\n",
            "        return np.array(coeffs)\n",
            "        \n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 22:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class ClusteringSegmentation:\n",
            "        \n",
            "    def __init__(self, method='kmeans', n_clusters=3, compactness=30.0, sigma=1.0):\n",
            "\n",
            "        # method: 'kmeans' or 'fcm'\n",
            "        \n",
            "        self.method = method\n",
            "        self.n_clusters = n_clusters\n",
            "        self.compactness = compactness\n",
            "        self.sigma = sigma\n",
            "\n",
            "    def process(self, image):\n",
            "        # convert the image to grayscale\n",
            "\n",
            "        # apply SLIC algorithm to get superpixels\n",
            "        scaled_image = img_as_float(resize(image, (500, 500)))\n",
            "        segments = slic(scaled_image, n_segments=300, compactness=self.compactness, sigma=self.sigma)\n",
            "\n",
            "        \n",
            "        # calculate the color features of each superpixel\n",
            "        features = []\n",
            "        for i in np.unique(segments):\n",
            "            mask = segments == i    \n",
            "            feature = np.mean(scaled_image[mask])\n",
            "            features.append(feature)\n",
            "        features = np.array(features)\n",
            "\n",
            "        # cluster the superpixels based on their color features\n",
            "        if self.method == 'kmeans':\n",
            "            kmeans = KMeans(n_clusters=self.n_clusters, n_init =10).fit(features.reshape(-1, 1))\n",
            "            labels = kmeans.labels_\n",
            "\n",
            "        elif self.method == 'fcm':\n",
            "            gray_image = rgb2gray(image)\n",
            "\n",
            "            # Apply a threshold to the image\n",
            "            thresh = threshold_otsu(gray_image)\n",
            "            binary = gray_image > thresh\n",
            "\n",
            "            # Apply morphological operations to clean up the image\n",
            "            binary = closing(binary, disk(2))\n",
            "            binary = clear_border(binary)\n",
            "\n",
            "            # Obtain a skeleton of the binary image\n",
            "            skeleton = skeletonize(binary)\n",
            "\n",
            "            # Apply fuzzy logic to the skeleton\n",
            "            fuzzy_skeleton = gaussian(skeleton, sigma=2)\n",
            "            data = fuzzy_skeleton.reshape(-1, 1)\n",
            "            cntr, u, u0, d, jm, p, fpc = cmeans(data.T, 2, 2, error=0.005, maxiter=1000)\n",
            "            fuzzy_labels = np.argmax(u, axis=0).reshape(image.shape[:2])\n",
            "            return fuzzy_labels\n",
            "            \n",
            "\n",
            "        # create an image with each superpixel labeled by its cluster\n",
            "        labels = np.array(labels, dtype=np.float64)\n",
            "        label_image = np.zeros_like(segments)\n",
            "        for i, label in enumerate(np.unique(segments)):\n",
            "            mask = segments == label\n",
            "            label_image[mask] = labels[i]\n",
            "\n",
            "        # post-process the labeled image\n",
            "        label_image = label_image.astype(int)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         regions = regionprops(label_image)\n",
            "        for i, region in enumerate(regions):\n",
            "            if region.area < 500:\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "                 label_image[label_image == i+1] = 0\n",
            "\n",
            "        # color the regions for visualization\n",
            "        # labeled_regions = label2rgb(label_image, image=image, bg_label=0, kind='avg')\n",
            "        labeled_regions = label2rgb(label_image, image=scaled_image, bg_label=0, kind='avg')\n",
            "\n",
            "        return labeled_regions\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 23:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class ClusteringSegmentation:\n",
            "        \n",
            "    def __init__(self, method='kmeans', n_clusters=3, compactness=30.0, sigma=1.0):\n",
            "\n",
            "        # method: 'kmeans' or 'fcm'\n",
            "        \n",
            "        self.method = method\n",
            "        self.n_clusters = n_clusters\n",
            "        self.compactness = compactness\n",
            "        self.sigma = sigma\n",
            "\n",
            "    def process(self, image):\n",
            "        # convert the image to grayscale\n",
            "\n",
            "        # apply SLIC algorithm to get superpixels\n",
            "        scaled_image = img_as_float(resize(image, (500, 500)))\n",
            "        segments = slic(scaled_image, n_segments=300, compactness=self.compactness, sigma=self.sigma)\n",
            "\n",
            "        \n",
            "        # calculate the color features of each superpixel\n",
            "        features = []\n",
            "        for i in np.unique(segments):\n",
            "            mask = segments == i    \n",
            "            feature = np.mean(scaled_image[mask])\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "             features.append(feature)\n",
            "        features = np.array(features)\n",
            "\n",
            "        # cluster the superpixels based on their color features\n",
            "        if self.method == 'kmeans':\n",
            "            kmeans = KMeans(n_clusters=self.n_clusters, n_init =10).fit(features.reshape(-1, 1))\n",
            "            labels = kmeans.labels_\n",
            "\n",
            "        elif self.method == 'fcm':\n",
            "            gray_image = rgb2gray(image)\n",
            "\n",
            "            # Apply a threshold to the image\n",
            "            thresh = threshold_otsu(gray_image)\n",
            "            binary = gray_image > thresh\n",
            "\n",
            "            # Apply morphological operations to clean up the image\n",
            "            binary = closing(binary, disk(2))\n",
            "            binary = clear_border(binary)\n",
            "\n",
            "            # Obtain a skeleton of the binary image\n",
            "            skeleton = skeletonize(binary)\n",
            "\n",
            "            # Apply fuzzy logic to the skeleton\n",
            "            fuzzy_skeleton = gaussian(skeleton, sigma=2)\n",
            "            data = fuzzy_skeleton.reshape(-1, 1)\n",
            "            cntr, u, u0, d, jm, p, fpc = cmeans(data.T, 2, 2, error=0.005, maxiter=1000)\n",
            "            fuzzy_labels = np.argmax(u, axis=0).reshape(image.shape[:2])\n",
            "            return fuzzy_labels\n",
            "            \n",
            "\n",
            "        # create an image with each superpixel labeled by its cluster\n",
            "        labels = np.array(labels, dtype=np.float64)\n",
            "        label_image = np.zeros_like(segments)\n",
            "        for i, label in enumerate(np.unique(segments)):\n",
            "            mask = segments == label\n",
            "            label_image[mask] = labels[i]\n",
            "\n",
            "        # post-process the labeled image\n",
            "        label_image = label_image.astype(int)\n",
            "        regions = regionprops(label_image)\n",
            "        for i, region in enumerate(regions):\n",
            "            if region.area < 500:\n",
            "                label_image[label_image == i+1] = 0\n",
            "\n",
            "        # color the regions for visualization\n",
            "        # labeled_regions = label2rgb(label_image, image=image, bg_label=0, kind='avg')\n",
            "        labeled_regions = label2rgb(label_image, image=scaled_image, bg_label=0, kind='avg')\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " \n",
            "        return labeled_regions\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 24:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class ClusteringSegmentation:\n",
            "        \n",
            "    def __init__(self, method='kmeans', n_clusters=3, compactness=30.0, sigma=1.0):\n",
            "\n",
            "        # method: 'kmeans' or 'fcm'\n",
            "        \n",
            "        self.method = method\n",
            "        self.n_clusters = n_clusters\n",
            "        self.compactness = compactness\n",
            "        self.sigma = sigma\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "     def process(self, image):\n",
            "        # convert the image to grayscale\n",
            "\n",
            "        # apply SLIC algorithm to get superpixels\n",
            "        scaled_image = img_as_float(resize(image, (500, 500)))\n",
            "        segments = slic(scaled_image, n_segments=300, compactness=self.compactness, sigma=self.sigma)\n",
            "\n",
            "        \n",
            "        # calculate the color features of each superpixel\n",
            "        features = []\n",
            "        for i in np.unique(segments):\n",
            "            mask = segments == i    \n",
            "            feature = np.mean(scaled_image[mask])\n",
            "            features.append(feature)\n",
            "        features = np.array(features)\n",
            "\n",
            "        # cluster the superpixels based on their color features\n",
            "        if self.method == 'kmeans':\n",
            "            kmeans = KMeans(n_clusters=self.n_clusters, n_init =10).fit(features.reshape(-1, 1))\n",
            "            labels = kmeans.labels_\n",
            "\n",
            "        elif self.method == 'fcm':\n",
            "            gray_image = rgb2gray(image)\n",
            "\n",
            "            # Apply a threshold to the image\n",
            "            thresh = threshold_otsu(gray_image)\n",
            "            binary = gray_image > thresh\n",
            "\n",
            "            # Apply morphological operations to clean up the image\n",
            "            binary = closing(binary, disk(2))\n",
            "            binary = clear_border(binary)\n",
            "\n",
            "            # Obtain a skeleton of the binary image\n",
            "            skeleton = skeletonize(binary)\n",
            "\n",
            "            # Apply fuzzy logic to the skeleton\n",
            "            fuzzy_skeleton = gaussian(skeleton, sigma=2)\n",
            "            data = fuzzy_skeleton.reshape(-1, 1)\n",
            "            cntr, u, u0, d, jm, p, fpc = cmeans(data.T, 2, 2, error=0.005, maxiter=1000)\n",
            "            fuzzy_labels = np.argmax(u, axis=0).reshape(image.shape[:2])\n",
            "            return fuzzy_labels\n",
            "            \n",
            "\n",
            "        # create an image with each superpixel labeled by its cluster\n",
            "        labels = np.array(labels, dtype=np.float64)\n",
            "        label_image = np.zeros_like(segments)\n",
            "        for i, label in enumerate(np.unique(segments)):\n",
            "            mask = segments == label\n",
            "            label_image[mask] = labels[i]\n",
            "\n",
            "        # post-process the labeled image\n",
            "        label_image = label_image.astype(int)\n",
            "        regions = regionprops(label_image)\n",
            "        for i, region in enumerate(regions):\n",
            "            if region.area < 500:\n",
            "                label_image[label_image == i+1] = 0\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         # color the regions for visualization\n",
            "        # labeled_regions = label2rgb(label_image, image=image, bg_label=0, kind='avg')\n",
            "        labeled_regions = label2rgb(label_image, image=scaled_image, bg_label=0, kind='avg')\n",
            "\n",
            "        return labeled_regions\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 25:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class RegionBasedSegmentation:\n",
            "    def __init__(self, method=\"region_growing\", **kwargs):\n",
            "\n",
            "        # method: 'region_growing', 'region_splitting', 'region_merging'\n",
            "\n",
            "        self.method = method\n",
            "        self.kwargs = kwargs\n",
            "    \n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "     def process(self, image):\n",
            "        # Convert the image to grayscale\n",
            "        image = rgb2gray(image)\n",
            "        \n",
            "        if self.method == \"region_growing\":\n",
            "            # Region Growing segmentation\n",
            "            threshold = self.kwargs.get('threshold', 0.5)\n",
            "            seed_point = self.kwargs.get('seed_point', None)\n",
            "            if seed_point is None:\n",
            "                seed_point = (image.shape[0]//2, image.shape[1]//2)\n",
            "            mask = np.zeros_like(image)\n",
            "            mask[seed_point] = 1\n",
            "            segmented = ndi.binary_fill_holes(ndi.binary_dilation(mask, iterations=2))\n",
            "            return segmented\n",
            "        elif self.method == \"region_splitting\":\n",
            "            # Region Splitting segmentation\n",
            "            # min_size = self.kwargs.get('min_size', 50)\n",
            "            # max_size = self.kwargs.get('max_size', 1000)\n",
            "            segmented = felzenszwalb(image, scale=70, sigma=0.5)\n",
            "            return segmented\n",
            "        elif self.method == \"region_merging\":\n",
            "            # Region Merging segmentation\n",
            "            method = self.kwargs.get('method', \"slic\")\n",
            "            if method == \"slic\":\n",
            "                segmented = slic(image, n_segments=100, compactness=10, sigma=1)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "             elif method == \"quickshift\":\n",
            "                segmented = quickshift(image, kernel_size=3, max_dist=6, ratio=0.5)\n",
            "            else:\n",
            "                raise ValueError(\"Invalid method specified\")\n",
            "            return segmented\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 26:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class RegionBasedSegmentation:\n",
            "    def __init__(self, method=\"region_growing\", **kwargs):\n",
            "\n",
            "        # method: 'region_growing', 'region_splitting', 'region_merging'\n",
            "\n",
            "        self.method = method\n",
            "        self.kwargs = kwargs\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "     \n",
            "    def process(self, image):\n",
            "        # Convert the image to grayscale\n",
            "        image = rgb2gray(image)\n",
            "        \n",
            "        if self.method == \"region_growing\":\n",
            "            # Region Growing segmentation\n",
            "            threshold = self.kwargs.get('threshold', 0.5)\n",
            "            seed_point = self.kwargs.get('seed_point', None)\n",
            "            if seed_point is None:\n",
            "                seed_point = (image.shape[0]//2, image.shape[1]//2)\n",
            "            mask = np.zeros_like(image)\n",
            "            mask[seed_point] = 1\n",
            "            segmented = ndi.binary_fill_holes(ndi.binary_dilation(mask, iterations=2))\n",
            "            return segmented\n",
            "        elif self.method == \"region_splitting\":\n",
            "            # Region Splitting segmentation\n",
            "            # min_size = self.kwargs.get('min_size', 50)\n",
            "            # max_size = self.kwargs.get('max_size', 1000)\n",
            "            segmented = felzenszwalb(image, scale=70, sigma=0.5)\n",
            "            return segmented\n",
            "        elif self.method == \"region_merging\":\n",
            "            # Region Merging segmentation\n",
            "            method = self.kwargs.get('method', \"slic\")\n",
            "            if method == \"slic\":\n",
            "                segmented = slic(image, n_segments=100, compactness=10, sigma=1)\n",
            "            elif method == \"quickshift\":\n",
            "                segmented = quickshift(image, kernel_size=3, max_dist=6, ratio=0.5)\n",
            "            else:\n",
            "                raise ValueError(\"Invalid method specified\")\n",
            "            return segmented\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 27:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "from imports import *\n",
            "\n",
            "class RegionBasedSegmentation:\n",
            "    def __init__(self, method=\"region_growing\", **kwargs):\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         # method: 'region_growing', 'region_splitting', 'region_merging'\n",
            "\n",
            "        self.method = method\n",
            "        self.kwargs = kwargs\n",
            "    \n",
            "    def process(self, image):\n",
            "        # Convert the image to grayscale\n",
            "        image = rgb2gray(image)\n",
            "        \n",
            "        if self.method == \"region_growing\":\n",
            "            # Region Growing segmentation\n",
            "            threshold = self.kwargs.get('threshold', 0.5)\n",
            "            seed_point = self.kwargs.get('seed_point', None)\n",
            "            if seed_point is None:\n",
            "                seed_point = (image.shape[0]//2, image.shape[1]//2)\n",
            "            mask = np.zeros_like(image)\n",
            "            mask[seed_point] = 1\n",
            "            segmented = ndi.binary_fill_holes(ndi.binary_dilation(mask, iterations=2))\n",
            "            return segmented\n",
            "        elif self.method == \"region_splitting\":\n",
            "            # Region Splitting segmentation\n",
            "            # min_size = self.kwargs.get('min_size', 50)\n",
            "            # max_size = self.kwargs.get('max_size', 1000)\n",
            "            segmented = felzenszwalb(image, scale=70, sigma=0.5)\n",
            "            return segmented\n",
            "        elif self.method == \"region_merging\":\n",
            "            # Region Merging segmentation\n",
            "            method = self.kwargs.get('method', \"slic\")\n",
            "            if method == \"slic\":\n",
            "                segmented = slic(image, n_segments=100, compactness=10, sigma=1)\n",
            "            elif method == \"quickshift\":\n",
            "                segmented = quickshift(image, kernel_size=3, max_dist=6, ratio=0.5)\n",
            "            else:\n",
            "                raise ValueError(\"Invalid method specified\")\n",
            "            return segmented\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 28:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class ImagePreprocessor:\n",
            "    def __init__(self, method=\"HE\"):\n",
            "        # method: 'HE', 'AHE', 'CLAHE', 'log'\n",
            "        self.method = method\n",
            "        \n",
            "    \n",
            "    def process(self, image):\n",
            "        if self.method == \"HE\":\n",
            "            image = self._apply_histogram_equalization(image)\n",
            "        elif self.method == \"AHE\":\n",
            "            image = self._apply_adaptive_histogram_equalization(image)\n",
            "        elif self.method == \"CLAHE\":\n",
            "            image = self._apply_contrast_limited_adaptive_histogram_equalization(image)\n",
            "        elif self.method == \"log\":\n",
            "            image = self._apply_logarithmic_transformation(image)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         \n",
            "        return image\n",
            "    \n",
            "    def _apply_histogram_equalization(self, image):\n",
            "        return exposure.equalize_hist(image)\n",
            "    \n",
            "    def _apply_adaptive_histogram_equalization(self, image):\n",
            "        return exposure.equalize_adapthist(image, clip_limit=0.03)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "     \n",
            "    def _apply_contrast_limited_adaptive_histogram_equalization(self, image):\n",
            "        return exposure.equalize_adapthist(image, clip_limit=0.03)\n",
            "    \n",
            "    def _apply_logarithmic_transformation(self, image):\n",
            "        image = image.astype(np.float32) / 255.0  # Convert image to float and scale to [0, 1]\n",
            "        log_img = np.log10(1 + image)  # Apply log transform to each channel\n",
            "        log_img = (log_img / np.max(log_img)) * 255.0  # Scale log-transformed image back to [0, 255]\n",
            "        log_img = log_img.astype(np.uint8)  # Convert back to uint8 format\n",
            "        return log_img\n",
            "    \n",
            "        \n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 29:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "class ImagePreprocessor:\n",
            "    def __init__(self, method=\"HE\"):\n",
            "        # method: 'HE', 'AHE', 'CLAHE', 'log'\n",
            "        self.method = method\n",
            "        \n",
            "    \n",
            "    def process(self, image):\n",
            "        if self.method == \"HE\":\n",
            "            image = self._apply_histogram_equalization(image)\n",
            "        elif self.method == \"AHE\":\n",
            "            image = self._apply_adaptive_histogram_equalization(image)\n",
            "        elif self.method == \"CLAHE\":\n",
            "            image = self._apply_contrast_limited_adaptive_histogram_equalization(image)\n",
            "        elif self.method == \"log\":\n",
            "            image = self._apply_logarithmic_transformation(image)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "        \n",
            "        return image\n",
            "    \n",
            "    def _apply_histogram_equalization(self, image):\n",
            "        return exposure.equalize_hist(image)\n",
            "    \n",
            "    def _apply_adaptive_histogram_equalization(self, image):\n",
            "        return exposure.equalize_adapthist(image, clip_limit=0.03)\n",
            "    \n",
            "    def _apply_contrast_limited_adaptive_histogram_equalization(self, image):\n",
            "        return exposure.equalize_adapthist(image, clip_limit=0.03)\n",
            "    \n",
            "    def _apply_logarithmic_transformation(self, image):\n",
            "        image = image.astype(np.float32) / 255.0  # Convert image to float and scale to [0, 1]\n",
            "        log_img = np.log10(1 + image)  # Apply log transform to each channel\n",
            "        log_img = (log_img / np.max(log_img)) * 255.0  # Scale log-transformed image back to [0, 255]\n",
            "        log_img = log_img.astype(np.uint8)  # Convert back to uint8 format\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         return log_img\n",
            "    \n",
            "        \n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 30:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class ImagePreprocessor:\n",
            "    def __init__(self, method=\"HE\"):\n",
            "        # method: 'HE', 'AHE', 'CLAHE', 'log'\n",
            "        self.method = method\n",
            "        \n",
            "    \n",
            "    def process(self, image):\n",
            "        if self.method == \"HE\":\n",
            "            image = self._apply_histogram_equalization(image)\n",
            "        elif self.method == \"AHE\":\n",
            "            image = self._apply_adaptive_histogram_equalization(image)\n",
            "        elif self.method == \"CLAHE\":\n",
            "            image = self._apply_contrast_limited_adaptive_histogram_equalization(image)\n",
            "        elif self.method == \"log\":\n",
            "            image = self._apply_logarithmic_transformation(image)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "        \n",
            "        return image\n",
            "    \n",
            "    def _apply_histogram_equalization(self, image):\n",
            "        return exposure.equalize_hist(image)\n",
            "    \n",
            "    def _apply_adaptive_histogram_equalization(self, image):\n",
            "        return exposure.equalize_adapthist(image, clip_limit=0.03)\n",
            "    \n",
            "    def _apply_contrast_limited_adaptive_histogram_equalization(self, image):\n",
            "        return exposure.equalize_adapthist(image, clip_limit=0.03)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "     \n",
            "    def _apply_logarithmic_transformation(self, image):\n",
            "        image = image.astype(np.float32) / 255.0  # Convert image to float and scale to [0, 1]\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         log_img = np.log10(1 + image)  # Apply log transform to each channel\n",
            "        log_img = (log_img / np.max(log_img)) * 255.0  # Scale log-transformed image back to [0, 255]\n",
            "        log_img = log_img.astype(np.uint8)  # Convert back to uint8 format\n",
            "        return log_img\n",
            "    \n",
            "        \n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 31:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class EdgeDetection:\n",
            "    def __init__(self, method=\"sobel\"):\n",
            "\n",
            "        # method: 'sobel', 'prewitt', 'roberts', 'laplace', 'canny'\n",
            "        # for roberts and canny: image must be 2D\n",
            "\n",
            "        self.method = method\n",
            "    \n",
            "    def sobel(self, image):\n",
            "        return sobel(image)\n",
            "    \n",
            "    def prewitt(self, image):\n",
            "        return prewitt(image)\n",
            "    \n",
            "    def roberts(self, image):\n",
            "        return roberts(rgb2gray(image))\n",
            "    \n",
            "    def laplace(self, image):\n",
            "        return laplace(image)\n",
            "    \n",
            "    def canny(self, images, sigma=1.0, low_threshold=None, high_threshold=None, mask=None):\n",
            "        if (len(images.shape) == 3):\n",
            "            # Array of images\n",
            "            edge_detected_imgs = np.zeros((images.shape[0], images.shape[1], images.shape[2]))\n",
            "            for i in range(images.shape[0]):\n",
            "                edge_detected_imgs[i] = canny(images[i], \n",
            "                                              sigma=sigma, low_threshold=low_threshold, \n",
            "                                              high_threshold=high_threshold, mask=mask)\n",
            "            return edge_detected_imgs\n",
            "        else:\n",
            "            return canny(images, \n",
            "                         sigma=sigma, \n",
            "                         low_threshold=low_threshold, \n",
            "                         high_threshold=high_threshold, mask=mask)\n",
            "    \n",
            "    def process(self, image):\n",
            "        if self.method == \"sobel\":\n",
            "            # Sobel edge detection\n",
            "            return self.sobel(image)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         elif self.method == \"prewitt\":\n",
            "            # Prewitt edge detection\n",
            "            return self.prewitt(image)\n",
            "        elif self.method == \"roberts\":\n",
            "            # Roberts edge detection\n",
            "            return self.roberts(image)\n",
            "        elif self.method == \"laplace\":\n",
            "            # Laplacian edge detection\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "             return self.laplace(image)\n",
            "        elif self.method == \"canny\":\n",
            "            # Canny edge detection\n",
            "            return self.canny(image)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 32:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class EdgeDetection:\n",
            "    def __init__(self, method=\"sobel\"):\n",
            "\n",
            "        # method: 'sobel', 'prewitt', 'roberts', 'laplace', 'canny'\n",
            "        # for roberts and canny: image must be 2D\n",
            "\n",
            "        self.method = method\n",
            "    \n",
            "    def sobel(self, image):\n",
            "        return sobel(image)\n",
            "    \n",
            "    def prewitt(self, image):\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         return prewitt(image)\n",
            "    \n",
            "    def roberts(self, image):\n",
            "        return roberts(rgb2gray(image))\n",
            "    \n",
            "    def laplace(self, image):\n",
            "        return laplace(image)\n",
            "    \n",
            "    def canny(self, images, sigma=1.0, low_threshold=None, high_threshold=None, mask=None):\n",
            "        if (len(images.shape) == 3):\n",
            "            # Array of images\n",
            "            edge_detected_imgs = np.zeros((images.shape[0], images.shape[1], images.shape[2]))\n",
            "            for i in range(images.shape[0]):\n",
            "                edge_detected_imgs[i] = canny(images[i], \n",
            "                                              sigma=sigma, low_threshold=low_threshold, \n",
            "                                              high_threshold=high_threshold, mask=mask)\n",
            "            return edge_detected_imgs\n",
            "        else:\n",
            "            return canny(images, \n",
            "                         sigma=sigma, \n",
            "                         low_threshold=low_threshold, \n",
            "                         high_threshold=high_threshold, mask=mask)\n",
            "    \n",
            "    def process(self, image):\n",
            "        if self.method == \"sobel\":\n",
            "            # Sobel edge detection\n",
            "            return self.sobel(image)\n",
            "        elif self.method == \"prewitt\":\n",
            "            # Prewitt edge detection\n",
            "            return self.prewitt(image)\n",
            "        elif self.method == \"roberts\":\n",
            "            # Roberts edge detection\n",
            "            return self.roberts(image)\n",
            "        elif self.method == \"laplace\":\n",
            "            # Laplacian edge detection\n",
            "            return self.laplace(image)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         elif self.method == \"canny\":\n",
            "            # Canny edge detection\n",
            "            return self.canny(image)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 33:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class EdgeDetection:\n",
            "    def __init__(self, method=\"sobel\"):\n",
            "\n",
            "        # method: 'sobel', 'prewitt', 'roberts', 'laplace', 'canny'\n",
            "        # for roberts and canny: image must be 2D\n",
            "\n",
            "        self.method = method\n",
            "    \n",
            "    def sobel(self, image):\n",
            "        return sobel(image)\n",
            "    \n",
            "    def prewitt(self, image):\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         return prewitt(image)\n",
            "    \n",
            "    def roberts(self, image):\n",
            "        return roberts(rgb2gray(image))\n",
            "    \n",
            "    def laplace(self, image):\n",
            "        return laplace(image)\n",
            "    \n",
            "    def canny(self, images, sigma=1.0, low_threshold=None, high_threshold=None, mask=None):\n",
            "        if (len(images.shape) == 3):\n",
            "            # Array of images\n",
            "            edge_detected_imgs = np.zeros((images.shape[0], images.shape[1], images.shape[2]))\n",
            "            for i in range(images.shape[0]):\n",
            "                edge_detected_imgs[i] = canny(images[i], \n",
            "                                              sigma=sigma, low_threshold=low_threshold, \n",
            "                                              high_threshold=high_threshold, mask=mask)\n",
            "            return edge_detected_imgs\n",
            "        else:\n",
            "            return canny(images, \n",
            "                         sigma=sigma, \n",
            "                         low_threshold=low_threshold, \n",
            "                         high_threshold=high_threshold, mask=mask)\n",
            "    \n",
            "    def process(self, image):\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         if self.method == \"sobel\":\n",
            "            # Sobel edge detection\n",
            "            return self.sobel(image)\n",
            "        elif self.method == \"prewitt\":\n",
            "            # Prewitt edge detection\n",
            "            return self.prewitt(image)\n",
            "        elif self.method == \"roberts\":\n",
            "            # Roberts edge detection\n",
            "            return self.roberts(image)\n",
            "        elif self.method == \"laplace\":\n",
            "            # Laplacian edge detection\n",
            "            return self.laplace(image)\n",
            "        elif self.method == \"canny\":\n",
            "            # Canny edge detection\n",
            "            return self.canny(image)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 34:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class ImageAligner:\n",
            "    def init(self):\n",
            "        pass\n",
            "\n",
            "    def align_image(self, binary_images):\n",
            "        \n",
            "        aligned_images = []\n",
            "        for image in binary_images:\n",
            "            # Apply Canny edge detection to the image\n",
            "            edges = cv2.Canny(image, 20, 100)\n",
            "            # plt.imshow(edges, cmap='gray')\n",
            "            # plt.show()\n",
            "\n",
            "            # print(np.all(edges == 0))\n",
            "            # print('Edges:', edges)\n",
            "            # Detect the lines in the image using the Hough transform\n",
            "            lines = cv2.HoughLines(edges, 1, np.pi/180, 50)\n",
            "            \n",
            "            # Count the number of lines with each angle\n",
            "            angle_counts = {}\n",
            "            # print('Lines', lines)\n",
            "            if (not (lines is None)):\n",
            "                for line in lines:\n",
            "                    # print('Line', line)\n",
            "                    rho, theta = line[0]\n",
            "                    angle_degrees = int(theta * 180/np.pi)\n",
            "                    # print('Angle degrees', angle_degrees)\n",
            "                    if angle_degrees in angle_counts:\n",
            "                        angle_counts[angle_degrees] += 1\n",
            "                    else:\n",
            "                        angle_counts[angle_degrees] = 1\n",
            "            \n",
            "\n",
            "                    # print(angle_counts)\n",
            "                    # Find the angle with the highest count\n",
            "                    most_frequent_angle = max(angle_counts, key=angle_counts.get)\n",
            "                    # print(\"Most frequent angle:\", most_frequent_angle)\n",
            "                    # Rotate the image to align with the median angle\n",
            "                    rows, cols = image.shape[:2]\n",
            "                    M = cv2.getRotationMatrix2D((cols/2, rows/2), most_frequent_angle, 1)\n",
            "                    aligned_image = cv2.warpAffine(image, M, (cols, rows))\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "\n",
            "                pixels_up = np.sum(np.sum(aligned_image, axis = 1)[:70])\n",
            "                pixels_down = np.sum(np.sum(aligned_image, axis = 1)[-70:])\n",
            "                # plt.imshow(aligned_image, cmap='gray')\n",
            "                # plt.show()\n",
            "                # print(pixels_up, pixels_down)\n",
            "                if (pixels_up > pixels_down):\n",
            "                    aligned_image = np.rot90(aligned_image, 2)            \n",
            "            \n",
            "                aligned_images.append(aligned_image)\n",
            "            else:\n",
            "                aligned_images.append(image)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "     \n",
            "        return np.array(aligned_images)\n",
            "        \n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 35:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " class ImageAligner:\n",
            "    def init(self):\n",
            "        pass\n",
            "\n",
            "    def align_image(self, binary_images):\n",
            "        \n",
            "        aligned_images = []\n",
            "        for image in binary_images:\n",
            "            # Apply Canny edge detection to the image\n",
            "            edges = cv2.Canny(image, 20, 100)\n",
            "            # plt.imshow(edges, cmap='gray')\n",
            "            # plt.show()\n",
            "\n",
            "            # print(np.all(edges == 0))\n",
            "            # print('Edges:', edges)\n",
            "            # Detect the lines in the image using the Hough transform\n",
            "            lines = cv2.HoughLines(edges, 1, np.pi/180, 50)\n",
            "            \n",
            "            # Count the number of lines with each angle\n",
            "            angle_counts = {}\n",
            "            # print('Lines', lines)\n",
            "            if (not (lines is None)):\n",
            "                for line in lines:\n",
            "                    # print('Line', line)\n",
            "                    rho, theta = line[0]\n",
            "                    angle_degrees = int(theta * 180/np.pi)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "                     # print('Angle degrees', angle_degrees)\n",
            "                    if angle_degrees in angle_counts:\n",
            "                        angle_counts[angle_degrees] += 1\n",
            "                    else:\n",
            "                        angle_counts[angle_degrees] = 1\n",
            "            \n",
            "\n",
            "                    # print(angle_counts)\n",
            "                    # Find the angle with the highest count\n",
            "                    most_frequent_angle = max(angle_counts, key=angle_counts.get)\n",
            "                    # print(\"Most frequent angle:\", most_frequent_angle)\n",
            "                    # Rotate the image to align with the median angle\n",
            "                    rows, cols = image.shape[:2]\n",
            "                    M = cv2.getRotationMatrix2D((cols/2, rows/2), most_frequent_angle, 1)\n",
            "                    aligned_image = cv2.warpAffine(image, M, (cols, rows))\n",
            "\n",
            "\n",
            "                pixels_up = np.sum(np.sum(aligned_image, axis = 1)[:70])\n",
            "                pixels_down = np.sum(np.sum(aligned_image, axis = 1)[-70:])\n",
            "                # plt.imshow(aligned_image, cmap='gray')\n",
            "                # plt.show()\n",
            "                # print(pixels_up, pixels_down)\n",
            "                if (pixels_up > pixels_down):\n",
            "                    aligned_image = np.rot90(aligned_image, 2)            \n",
            "            \n",
            "                aligned_images.append(aligned_image)\n",
            "            else:\n",
            "                aligned_images.append(image)\n",
            "    \n",
            "        return np.array(aligned_images)\n",
            "        \n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 36:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class ImageAligner:\n",
            "    def init(self):\n",
            "        pass\n",
            "\n",
            "    def align_image(self, binary_images):\n",
            "        \n",
            "        aligned_images = []\n",
            "        for image in binary_images:\n",
            "            # Apply Canny edge detection to the image\n",
            "            edges = cv2.Canny(image, 20, 100)\n",
            "            # plt.imshow(edges, cmap='gray')\n",
            "            # plt.show()\n",
            "\n",
            "            # print(np.all(edges == 0))\n",
            "            # print('Edges:', edges)\n",
            "            # Detect the lines in the image using the Hough transform\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "             lines = cv2.HoughLines(edges, 1, np.pi/180, 50)\n",
            "            \n",
            "            # Count the number of lines with each angle\n",
            "            angle_counts = {}\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "             # print('Lines', lines)\n",
            "            if (not (lines is None)):\n",
            "                for line in lines:\n",
            "                    # print('Line', line)\n",
            "                    rho, theta = line[0]\n",
            "                    angle_degrees = int(theta * 180/np.pi)\n",
            "                    # print('Angle degrees', angle_degrees)\n",
            "                    if angle_degrees in angle_counts:\n",
            "                        angle_counts[angle_degrees] += 1\n",
            "                    else:\n",
            "                        angle_counts[angle_degrees] = 1\n",
            "            \n",
            "\n",
            "                    # print(angle_counts)\n",
            "                    # Find the angle with the highest count\n",
            "                    most_frequent_angle = max(angle_counts, key=angle_counts.get)\n",
            "                    # print(\"Most frequent angle:\", most_frequent_angle)\n",
            "                    # Rotate the image to align with the median angle\n",
            "                    rows, cols = image.shape[:2]\n",
            "                    M = cv2.getRotationMatrix2D((cols/2, rows/2), most_frequent_angle, 1)\n",
            "                    aligned_image = cv2.warpAffine(image, M, (cols, rows))\n",
            "\n",
            "\n",
            "                pixels_up = np.sum(np.sum(aligned_image, axis = 1)[:70])\n",
            "                pixels_down = np.sum(np.sum(aligned_image, axis = 1)[-70:])\n",
            "                # plt.imshow(aligned_image, cmap='gray')\n",
            "                # plt.show()\n",
            "                # print(pixels_up, pixels_down)\n",
            "                if (pixels_up > pixels_down):\n",
            "                    aligned_image = np.rot90(aligned_image, 2)            \n",
            "            \n",
            "                aligned_images.append(aligned_image)\n",
            "            else:\n",
            "                aligned_images.append(image)\n",
            "    \n",
            "        return np.array(aligned_images)\n",
            "        \n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 37:\n",
            "Prefix: \n",
            " import sys\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " \n",
            "class ThresholdSegmentation:\n",
            "    def init(self, method=\"Global\", block_size=35, thresh_method=\"otsu\", n_thresholds=3):\n",
            "        self.method = method\n",
            "        self.block_size = block_size\n",
            "        self.thresh_method = thresh_method\n",
            "        self.n_thresholds = n_thresholds\n",
            "    \n",
            "    def process(self, image):\n",
            "        #TODO may need to do copy of the image\n",
            "        # Convert the image to grayscale\n",
            "        image = rgb2gray(image)\n",
            "        \n",
            "        if self.method == \"Global\":\n",
            "            # Global thresholding\n",
            "            thresh = threshold_otsu(image)\n",
            "            binary = image > thresh\n",
            "        elif self.method == \"Otsu\":\n",
            "            # Otsu thresholding\n",
            "            thresh = threshold_otsu(image)\n",
            "            binary = image > thresh\n",
            "        elif self.method == \"Local\":\n",
            "            # Local adaptive thresholding\n",
            "            binary = threshold_local(image, self.block_size)\n",
            "        elif self.method == \"Multilevel\":\n",
            "            # Multilevel thresholding\n",
            "            if self.thresh_method == \"otsu\":\n",
            "                thresh_func = threshold_otsu\n",
            "            else:\n",
            "                thresh_func = threshold_local\n",
            "            # thresh_vals = threshold_multilevel(image, self.n_thresholds, method=thresh_func)\n",
            "            # binary = np.digitize(image, thresh_vals)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "        \n",
            "        return binary\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 38:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class ThresholdSegmentation:\n",
            "    def init(self, method=\"Global\", block_size=35, thresh_method=\"otsu\", n_thresholds=3):\n",
            "        self.method = method\n",
            "        self.block_size = block_size\n",
            "        self.thresh_method = thresh_method\n",
            "        self.n_thresholds = n_thresholds\n",
            "    \n",
            "    def process(self, image):\n",
            "        #TODO may need to do copy of the image\n",
            "        # Convert the image to grayscale\n",
            "        image = rgb2gray(image)\n",
            "        \n",
            "        if self.method == \"Global\":\n",
            "            # Global thresholding\n",
            "            thresh = threshold_otsu(image)\n",
            "            binary = image > thresh\n",
            "        elif self.method == \"Otsu\":\n",
            "            # Otsu thresholding\n",
            "            thresh = threshold_otsu(image)\n",
            "            binary = image > thresh\n",
            "        elif self.method == \"Local\":\n",
            "            # Local adaptive thresholding\n",
            "            binary = threshold_local(image, self.block_size)\n",
            "        elif self.method == \"Multilevel\":\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "             # Multilevel thresholding\n",
            "            if self.thresh_method == \"otsu\":\n",
            "                thresh_func = threshold_otsu\n",
            "            else:\n",
            "                thresh_func = threshold_local\n",
            "            # thresh_vals = threshold_multilevel(image, self.n_thresholds, method=thresh_func)\n",
            "            # binary = np.digitize(image, thresh_vals)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         \n",
            "        return binary\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 39:\n",
            "Prefix: \n",
            " import sys\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "class ThresholdSegmentation:\n",
            "    def init(self, method=\"Global\", block_size=35, thresh_method=\"otsu\", n_thresholds=3):\n",
            "        self.method = method\n",
            "        self.block_size = block_size\n",
            "        self.thresh_method = thresh_method\n",
            "        self.n_thresholds = n_thresholds\n",
            "    \n",
            "    def process(self, image):\n",
            "        #TODO may need to do copy of the image\n",
            "        # Convert the image to grayscale\n",
            "        image = rgb2gray(image)\n",
            "        \n",
            "        if self.method == \"Global\":\n",
            "            # Global thresholding\n",
            "            thresh = threshold_otsu(image)\n",
            "            binary = image > thresh\n",
            "        elif self.method == \"Otsu\":\n",
            "            # Otsu thresholding\n",
            "            thresh = threshold_otsu(image)\n",
            "            binary = image > thresh\n",
            "        elif self.method == \"Local\":\n",
            "            # Local adaptive thresholding\n",
            "            binary = threshold_local(image, self.block_size)\n",
            "        elif self.method == \"Multilevel\":\n",
            "            # Multilevel thresholding\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "             if self.thresh_method == \"otsu\":\n",
            "                thresh_func = threshold_otsu\n",
            "            else:\n",
            "                thresh_func = threshold_local\n",
            "            # thresh_vals = threshold_multilevel(image, self.n_thresholds, method=thresh_func)\n",
            "            # binary = np.digitize(image, thresh_vals)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "        \n",
            "        return binary\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 40:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "import numpy as np\n",
            "\n",
            "class ImageRestorer:\n",
            "    def __init__(self, method=\"median\"):\n",
            "\n",
            "        # method: 'mean_circular', 'mean_rectangular', 'median', 'gaussian', 'adaptive', 'wiener'\n",
            "\n",
            "        self.method = method\n",
            "    \n",
            "    def process(self, image):\n",
            "        if self.method == \"mean_circular\":\n",
            "            # Mean filter\n",
            "            image = self.mean_filter_using_circular_disk(image)\n",
            "        elif self.method == \"mean_rectangular\":\n",
            "            # Mean filter\n",
            "            image = self.mean_filter_using_rectangular_disk(image)\n",
            "        elif self.method == \"median\":\n",
            "            # Median filter\n",
            "            image = self.median_filter(image)\n",
            "        elif self.method == \"gaussian\":\n",
            "            # Gaussian filter\n",
            "            image = self.gaussian_filter(image)\n",
            "        elif self.method == \"adaptive\":\n",
            "            # Adaptive filter\n",
            "            image = self.adaptive_filter(image)\n",
            "        elif self.method == \"wiener\":\n",
            "            # Wiener filter\n",
            "            image = self.wiener_filter(image)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "        \n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         return image\n",
            "    \n",
            "    def mean_filter_using_rectangular_disk(self, image, width=3, height=3):\n",
            "        kernel = np.ones((height, width, 3)) / (height * width)\n",
            "        filtered_image = convolve(image, kernel)\n",
            "        return filtered_image\n",
            "\n",
            "\n",
            "    def mean_filter_using_circular_disk(self, image, radius=3):\n",
            "        # Define a disk structuring element\n",
            "        selem = disk(radius)\n",
            "        selem = selem[:, np.newaxis]\n",
            "       \n",
            "        # Apply the mean filter using the structuring element\n",
            "        return rank.mean(image = image,footprint = selem)\n",
            "    \n",
            "    def median_filter(self, image):\n",
            "        # Median filter\n",
            "        return median(image)\n",
            "    \n",
            "    def gaussian_filter(self, image):\n",
            "        # Gaussian filter\n",
            "        return gaussian(image, sigma=1, mode='reflect', cval=0, multichannel=True, preserve_range=False, truncate=4.0)\n",
            "    \n",
            "    def adaptive_filter(self, image):\n",
            "        # Adaptive filter\n",
            "        return denoise_nl_means(image, h=0.8 * 1.0, fast_mode=True, patch_size=5, patch_distance=3, \n",
            "                                multichannel=True, preserve_range=False)\n",
            "    \n",
            "    def wiener_filter(self, image):\n",
            "        # Wiener filter\n",
            "        image = rgb2gray(image)\n",
            "        psf = np.ones((5, 5)) / 25\n",
            "        img = convolve2d(image, psf, 'same')\n",
            "        rng = np.random.default_rng()\n",
            "        img += 0.1 * img.std() * rng.standard_normal(image.shape)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         deconvolved_img = wiener(image, psf, 0.1)\n",
            "        return deconvolved_img\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 41:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "import numpy as np\n",
            "\n",
            "class ImageRestorer:\n",
            "    def __init__(self, method=\"median\"):\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         # method: 'mean_circular', 'mean_rectangular', 'median', 'gaussian', 'adaptive', 'wiener'\n",
            "\n",
            "        self.method = method\n",
            "    \n",
            "    def process(self, image):\n",
            "        if self.method == \"mean_circular\":\n",
            "            # Mean filter\n",
            "            image = self.mean_filter_using_circular_disk(image)\n",
            "        elif self.method == \"mean_rectangular\":\n",
            "            # Mean filter\n",
            "            image = self.mean_filter_using_rectangular_disk(image)\n",
            "        elif self.method == \"median\":\n",
            "            # Median filter\n",
            "            image = self.median_filter(image)\n",
            "        elif self.method == \"gaussian\":\n",
            "            # Gaussian filter\n",
            "            image = self.gaussian_filter(image)\n",
            "        elif self.method == \"adaptive\":\n",
            "            # Adaptive filter\n",
            "            image = self.adaptive_filter(image)\n",
            "        elif self.method == \"wiener\":\n",
            "            # Wiener filter\n",
            "            image = self.wiener_filter(image)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "        \n",
            "        return image\n",
            "    \n",
            "    def mean_filter_using_rectangular_disk(self, image, width=3, height=3):\n",
            "        kernel = np.ones((height, width, 3)) / (height * width)\n",
            "        filtered_image = convolve(image, kernel)\n",
            "        return filtered_image\n",
            "\n",
            "\n",
            "    def mean_filter_using_circular_disk(self, image, radius=3):\n",
            "        # Define a disk structuring element\n",
            "        selem = disk(radius)\n",
            "        selem = selem[:, np.newaxis]\n",
            "       \n",
            "        # Apply the mean filter using the structuring element\n",
            "        return rank.mean(image = image,footprint = selem)\n",
            "    \n",
            "    def median_filter(self, image):\n",
            "        # Median filter\n",
            "        return median(image)\n",
            "    \n",
            "    def gaussian_filter(self, image):\n",
            "        # Gaussian filter\n",
            "        return gaussian(image, sigma=1, mode='reflect', cval=0, multichannel=True, preserve_range=False, truncate=4.0)\n",
            "    \n",
            "    def adaptive_filter(self, image):\n",
            "        # Adaptive filter\n",
            "        return denoise_nl_means(image, h=0.8 * 1.0, fast_mode=True, patch_size=5, patch_distance=3, \n",
            "                                multichannel=True, preserve_range=False)\n",
            "    \n",
            "    def wiener_filter(self, image):\n",
            "        # Wiener filter\n",
            "        image = rgb2gray(image)\n",
            "        psf = np.ones((5, 5)) / 25\n",
            "        img = convolve2d(image, psf, 'same')\n",
            "        rng = np.random.default_rng()\n",
            "        img += 0.1 * img.std() * rng.standard_normal(image.shape)\n",
            "        deconvolved_img = wiener(image, psf, 0.1)\n",
            "        return deconvolved_img\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 42:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "import numpy as np\n",
            "\n",
            "class ImageRestorer:\n",
            "    def __init__(self, method=\"median\"):\n",
            "\n",
            "        # method: 'mean_circular', 'mean_rectangular', 'median', 'gaussian', 'adaptive', 'wiener'\n",
            "\n",
            "        self.method = method\n",
            "    \n",
            "    def process(self, image):\n",
            "        if self.method == \"mean_circular\":\n",
            "            # Mean filter\n",
            "            image = self.mean_filter_using_circular_disk(image)\n",
            "        elif self.method == \"mean_rectangular\":\n",
            "            # Mean filter\n",
            "            image = self.mean_filter_using_rectangular_disk(image)\n",
            "        elif self.method == \"median\":\n",
            "            # Median filter\n",
            "            image = self.median_filter(image)\n",
            "        elif self.method == \"gaussian\":\n",
            "            # Gaussian filter\n",
            "            image = self.gaussian_filter(image)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         elif self.method == \"adaptive\":\n",
            "            # Adaptive filter\n",
            "            image = self.adaptive_filter(image)\n",
            "        elif self.method == \"wiener\":\n",
            "            # Wiener filter\n",
            "            image = self.wiener_filter(image)\n",
            "        else:\n",
            "            raise ValueError(\"Invalid method specified\")\n",
            "        \n",
            "        return image\n",
            "    \n",
            "    def mean_filter_using_rectangular_disk(self, image, width=3, height=3):\n",
            "        kernel = np.ones((height, width, 3)) / (height * width)\n",
            "        filtered_image = convolve(image, kernel)\n",
            "        return filtered_image\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " \n",
            "    def mean_filter_using_circular_disk(self, image, radius=3):\n",
            "        # Define a disk structuring element\n",
            "        selem = disk(radius)\n",
            "        selem = selem[:, np.newaxis]\n",
            "       \n",
            "        # Apply the mean filter using the structuring element\n",
            "        return rank.mean(image = image,footprint = selem)\n",
            "    \n",
            "    def median_filter(self, image):\n",
            "        # Median filter\n",
            "        return median(image)\n",
            "    \n",
            "    def gaussian_filter(self, image):\n",
            "        # Gaussian filter\n",
            "        return gaussian(image, sigma=1, mode='reflect', cval=0, multichannel=True, preserve_range=False, truncate=4.0)\n",
            "    \n",
            "    def adaptive_filter(self, image):\n",
            "        # Adaptive filter\n",
            "        return denoise_nl_means(image, h=0.8 * 1.0, fast_mode=True, patch_size=5, patch_distance=3, \n",
            "                                multichannel=True, preserve_range=False)\n",
            "    \n",
            "    def wiener_filter(self, image):\n",
            "        # Wiener filter\n",
            "        image = rgb2gray(image)\n",
            "        psf = np.ones((5, 5)) / 25\n",
            "        img = convolve2d(image, psf, 'same')\n",
            "        rng = np.random.default_rng()\n",
            "        img += 0.1 * img.std() * rng.standard_normal(image.shape)\n",
            "        deconvolved_img = wiener(image, psf, 0.1)\n",
            "        return deconvolved_img\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 43:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class ModelSelection:\n",
            "    def __init__(self, x_train, y_train, x_val, y_val):\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         self.x_train = x_train\n",
            "        self.y_train = y_train\n",
            "        self.x_val = x_val\n",
            "        self.y_val = y_val\n",
            "\n",
            "    def KNN(self, n_neighbors=3):\n",
            "        # create KNN classifier\n",
            "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
            "        \n",
            "        # train the model using the training data\n",
            "        knn.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        pred_train = knn.predict(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data\n",
            "        pred_val = knn.predict(self.x_val)\n",
            "\n",
            "        self.save_model(knn, \"knn.pkl\")\n",
            "\n",
            "        return knn, pred_train, pred_val\n",
            "\n",
            "    def ANN(self, input_dim, output_dim, hidden_layers=[500, 400]):\n",
            "\n",
            "        print(f'input_dim: {input_dim}')\n",
            "        print(f'output_dim: {output_dim}')\n",
            "        print(f'x_train: {self.x_train.shape}')\n",
            "        print(f'y_train: {self.y_train.shape}')\n",
            "\n",
            "\n",
            "        # create sequential model\n",
            "        model = Sequential()\n",
            "        \n",
            "        # add input layer\n",
            "        model.add(Dense(hidden_layers[0], activation=\"relu\", input_dim=input_dim,\n",
            "                        kernel_regularizer=regularizers.l2(0.01)))\n",
            "\n",
            "\n",
            "\n",
            "        # add hidden layers\n",
            "        for units in hidden_layers[1:]:\n",
            "            model.add(Dense(units, activation=\"relu\"))\n",
            "            \n",
            "        # add output layer\n",
            "        model.add(Dense(output_dim, activation=\"softmax\"))\n",
            "\n",
            "        y_onehot_train = to_categorical(self.y_train, num_classes=6)\n",
            "        y_onehot_val = to_categorical(self.y_val, num_classes=6)\n",
            "        print(f'y_onehot: {y_onehot_train.shape}')\n",
            "        \n",
            "        # compile the model\n",
            "        model.compile(\n",
            "            loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
            "        )\n",
            "        \n",
            "        # model.summary()\n",
            "        # print(f'Output shape: {model.output_shape}')\n",
            "\n",
            "\n",
            "        # train the model using the training data\n",
            "        model.fit(\n",
            "            self.x_train,\n",
            "            y_onehot_train,\n",
            "            epochs=10,\n",
            "            batch_size=32,\n",
            "            validation_data=(self.x_val, y_onehot_val),\n",
            "        )\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " \n",
            "        # Predict the classes of the training data\n",
            "        pred_train = model.predict(self.x_train)\n",
            "        pred_train = pred_train.argmax(axis=1)\n",
            "\n",
            "        # Predict the classes of the validation data\n",
            "        pred_val = model.predict(self.x_val)\n",
            "        pred_val = pred_val.argmax(axis=1)\n",
            "\n",
            "        # Evaluate the model on the test data\n",
            "        loss, test_accuracy = model.evaluate(self.x_val, y_onehot_val, verbose=0)\n",
            "        print(f\"Test accuracy: {test_accuracy}\")\n",
            "        print(f\"Test loss: {loss}\")\n",
            "        \n",
            "        model.save(\"ann.h5\")\n",
            "\n",
            "        return model, pred_train, pred_val\n",
            "\n",
            "    def SVM(self, kernel=\"linear\", C=1.0):\n",
            "        # create SVM classifier\n",
            "        svm = SVC(kernel=kernel, C=C)\n",
            "        \n",
            "        # train the model using the training data\n",
            "        svm.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        pred_train = svm.predict(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data\n",
            "        pred_val = svm.predict(self.x_val)\n",
            "\n",
            "        self.save_model(svm, \"svm.pkl\")\n",
            "\n",
            "        return svm, pred_train, pred_val\n",
            "\n",
            "    def HMM(self, n_components=2):\n",
            "        # create HMM model\n",
            "        model = hmm.GaussianHMM(n_components=n_components)\n",
            "        \n",
            "        # train the model using the training data\n",
            "        model.fit(self.x_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        log_likelihood, pred_train = model.decode(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data\n",
            "        log_likelihood, pred_val = model.decode(self.x_val)\n",
            "\n",
            "        self.save_model(model, \"hmm.pkl\")\n",
            "\n",
            "        return model, pred_train, pred_val\n",
            "\n",
            "    def Ensemble(self):\n",
            "        # create Random Forest classifier\n",
            "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
            "\n",
            "        # train the models using the training data\n",
            "        rf.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        pred_train = rf.predict(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data using each classifier\n",
            "        pred_val = rf.predict(self.x_val)\n",
            "\n",
            "        self.save_model(rf, \"random_forest.pkl\")\n",
            "\n",
            "        return rf, pred_train, pred_val\n",
            "\n",
            "    def AdaBoost(self):\n",
            "        # Initialize the classifier\n",
            "        clf = AdaBoostClassifier()\n",
            "\n",
            "        # Fit the classifier on training data\n",
            "        clf.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # Predict on training data\n",
            "        pred_train = clf.predict(self.x_train)\n",
            "\n",
            "        # Predict on validation data\n",
            "        pred_val = clf.predict(self.x_val)\n",
            "\n",
            "        self.save_model(clf, \"adaboost.pkl\")\n",
            "\n",
            "        return clf, pred_train, pred_val\n",
            "\n",
            "    def save_model(self, model, model_name):\n",
            "        pickle.dump(model, open(model_name, \"wb\"))\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 44:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class ModelSelection:\n",
            "    def __init__(self, x_train, y_train, x_val, y_val):\n",
            "        self.x_train = x_train\n",
            "        self.y_train = y_train\n",
            "        self.x_val = x_val\n",
            "        self.y_val = y_val\n",
            "\n",
            "    def KNN(self, n_neighbors=3):\n",
            "        # create KNN classifier\n",
            "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
            "        \n",
            "        # train the model using the training data\n",
            "        knn.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        pred_train = knn.predict(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data\n",
            "        pred_val = knn.predict(self.x_val)\n",
            "\n",
            "        self.save_model(knn, \"knn.pkl\")\n",
            "\n",
            "        return knn, pred_train, pred_val\n",
            "\n",
            "    def ANN(self, input_dim, output_dim, hidden_layers=[500, 400]):\n",
            "\n",
            "        print(f'input_dim: {input_dim}')\n",
            "        print(f'output_dim: {output_dim}')\n",
            "        print(f'x_train: {self.x_train.shape}')\n",
            "        print(f'y_train: {self.y_train.shape}')\n",
            "\n",
            "\n",
            "        # create sequential model\n",
            "        model = Sequential()\n",
            "        \n",
            "        # add input layer\n",
            "        model.add(Dense(hidden_layers[0], activation=\"relu\", input_dim=input_dim,\n",
            "                        kernel_regularizer=regularizers.l2(0.01)))\n",
            "\n",
            "\n",
            "\n",
            "        # add hidden layers\n",
            "        for units in hidden_layers[1:]:\n",
            "            model.add(Dense(units, activation=\"relu\"))\n",
            "            \n",
            "        # add output layer\n",
            "        model.add(Dense(output_dim, activation=\"softmax\"))\n",
            "\n",
            "        y_onehot_train = to_categorical(self.y_train, num_classes=6)\n",
            "        y_onehot_val = to_categorical(self.y_val, num_classes=6)\n",
            "        print(f'y_onehot: {y_onehot_train.shape}')\n",
            "        \n",
            "        # compile the model\n",
            "        model.compile(\n",
            "            loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
            "        )\n",
            "        \n",
            "        # model.summary()\n",
            "        # print(f'Output shape: {model.output_shape}')\n",
            "\n",
            "\n",
            "        # train the model using the training data\n",
            "        model.fit(\n",
            "            self.x_train,\n",
            "            y_onehot_train,\n",
            "            epochs=10,\n",
            "            batch_size=32,\n",
            "            validation_data=(self.x_val, y_onehot_val),\n",
            "        )\n",
            "\n",
            "        # Predict the classes of the training data\n",
            "        pred_train = model.predict(self.x_train)\n",
            "        pred_train = pred_train.argmax(axis=1)\n",
            "\n",
            "        # Predict the classes of the validation data\n",
            "        pred_val = model.predict(self.x_val)\n",
            "        pred_val = pred_val.argmax(axis=1)\n",
            "\n",
            "        # Evaluate the model on the test data\n",
            "        loss, test_accuracy = model.evaluate(self.x_val, y_onehot_val, verbose=0)\n",
            "        print(f\"Test accuracy: {test_accuracy}\")\n",
            "        print(f\"Test loss: {loss}\")\n",
            "        \n",
            "        model.save(\"ann.h5\")\n",
            "\n",
            "        return model, pred_train, pred_val\n",
            "\n",
            "    def SVM(self, kernel=\"linear\", C=1.0):\n",
            "        # create SVM classifier\n",
            "        svm = SVC(kernel=kernel, C=C)\n",
            "        \n",
            "        # train the model using the training data\n",
            "        svm.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        pred_train = svm.predict(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         pred_val = svm.predict(self.x_val)\n",
            "\n",
            "        self.save_model(svm, \"svm.pkl\")\n",
            "\n",
            "        return svm, pred_train, pred_val\n",
            "\n",
            "    def HMM(self, n_components=2):\n",
            "        # create HMM model\n",
            "        model = hmm.GaussianHMM(n_components=n_components)\n",
            "        \n",
            "        # train the model using the training data\n",
            "        model.fit(self.x_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        log_likelihood, pred_train = model.decode(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data\n",
            "        log_likelihood, pred_val = model.decode(self.x_val)\n",
            "\n",
            "        self.save_model(model, \"hmm.pkl\")\n",
            "\n",
            "        return model, pred_train, pred_val\n",
            "\n",
            "    def Ensemble(self):\n",
            "        # create Random Forest classifier\n",
            "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
            "\n",
            "        # train the models using the training data\n",
            "        rf.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        pred_train = rf.predict(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data using each classifier\n",
            "        pred_val = rf.predict(self.x_val)\n",
            "\n",
            "        self.save_model(rf, \"random_forest.pkl\")\n",
            "\n",
            "        return rf, pred_train, pred_val\n",
            "\n",
            "    def AdaBoost(self):\n",
            "        # Initialize the classifier\n",
            "        clf = AdaBoostClassifier()\n",
            "\n",
            "        # Fit the classifier on training data\n",
            "        clf.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # Predict on training data\n",
            "        pred_train = clf.predict(self.x_train)\n",
            "\n",
            "        # Predict on validation data\n",
            "        pred_val = clf.predict(self.x_val)\n",
            "\n",
            "        self.save_model(clf, \"adaboost.pkl\")\n",
            "\n",
            "        return clf, pred_train, pred_val\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "     def save_model(self, model, model_name):\n",
            "        pickle.dump(model, open(model_name, \"wb\"))\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 45:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class ModelSelection:\n",
            "    def __init__(self, x_train, y_train, x_val, y_val):\n",
            "        self.x_train = x_train\n",
            "        self.y_train = y_train\n",
            "        self.x_val = x_val\n",
            "        self.y_val = y_val\n",
            "\n",
            "    def KNN(self, n_neighbors=3):\n",
            "        # create KNN classifier\n",
            "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
            "        \n",
            "        # train the model using the training data\n",
            "        knn.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        pred_train = knn.predict(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data\n",
            "        pred_val = knn.predict(self.x_val)\n",
            "\n",
            "        self.save_model(knn, \"knn.pkl\")\n",
            "\n",
            "        return knn, pred_train, pred_val\n",
            "\n",
            "    def ANN(self, input_dim, output_dim, hidden_layers=[500, 400]):\n",
            "\n",
            "        print(f'input_dim: {input_dim}')\n",
            "        print(f'output_dim: {output_dim}')\n",
            "        print(f'x_train: {self.x_train.shape}')\n",
            "        print(f'y_train: {self.y_train.shape}')\n",
            "\n",
            "\n",
            "        # create sequential model\n",
            "        model = Sequential()\n",
            "        \n",
            "        # add input layer\n",
            "        model.add(Dense(hidden_layers[0], activation=\"relu\", input_dim=input_dim,\n",
            "                        kernel_regularizer=regularizers.l2(0.01)))\n",
            "\n",
            "\n",
            "\n",
            "        # add hidden layers\n",
            "        for units in hidden_layers[1:]:\n",
            "            model.add(Dense(units, activation=\"relu\"))\n",
            "            \n",
            "        # add output layer\n",
            "        model.add(Dense(output_dim, activation=\"softmax\"))\n",
            "\n",
            "        y_onehot_train = to_categorical(self.y_train, num_classes=6)\n",
            "        y_onehot_val = to_categorical(self.y_val, num_classes=6)\n",
            "        print(f'y_onehot: {y_onehot_train.shape}')\n",
            "        \n",
            "        # compile the model\n",
            "        model.compile(\n",
            "            loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
            "        )\n",
            "        \n",
            "        # model.summary()\n",
            "        # print(f'Output shape: {model.output_shape}')\n",
            "\n",
            "\n",
            "        # train the model using the training data\n",
            "        model.fit(\n",
            "            self.x_train,\n",
            "            y_onehot_train,\n",
            "            epochs=10,\n",
            "            batch_size=32,\n",
            "            validation_data=(self.x_val, y_onehot_val),\n",
            "        )\n",
            "\n",
            "        # Predict the classes of the training data\n",
            "        pred_train = model.predict(self.x_train)\n",
            "        pred_train = pred_train.argmax(axis=1)\n",
            "\n",
            "        # Predict the classes of the validation data\n",
            "        pred_val = model.predict(self.x_val)\n",
            "        pred_val = pred_val.argmax(axis=1)\n",
            "\n",
            "        # Evaluate the model on the test data\n",
            "        loss, test_accuracy = model.evaluate(self.x_val, y_onehot_val, verbose=0)\n",
            "        print(f\"Test accuracy: {test_accuracy}\")\n",
            "        print(f\"Test loss: {loss}\")\n",
            "        \n",
            "        model.save(\"ann.h5\")\n",
            "\n",
            "        return model, pred_train, pred_val\n",
            "\n",
            "    def SVM(self, kernel=\"linear\", C=1.0):\n",
            "        # create SVM classifier\n",
            "        svm = SVC(kernel=kernel, C=C)\n",
            "        \n",
            "        # train the model using the training data\n",
            "        svm.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        pred_train = svm.predict(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data\n",
            "        pred_val = svm.predict(self.x_val)\n",
            "\n",
            "        self.save_model(svm, \"svm.pkl\")\n",
            "\n",
            "        return svm, pred_train, pred_val\n",
            "\n",
            "    def HMM(self, n_components=2):\n",
            "        # create HMM model\n",
            "        model = hmm.GaussianHMM(n_components=n_components)\n",
            "        \n",
            "        # train the model using the training data\n",
            "        model.fit(self.x_train)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "        # predict the classes of the training data\n",
            "        log_likelihood, pred_train = model.decode(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data\n",
            "        log_likelihood, pred_val = model.decode(self.x_val)\n",
            "\n",
            "        self.save_model(model, \"hmm.pkl\")\n",
            "\n",
            "        return model, pred_train, pred_val\n",
            "\n",
            "    def Ensemble(self):\n",
            "        # create Random Forest classifier\n",
            "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
            "\n",
            "        # train the models using the training data\n",
            "        rf.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # predict the classes of the training data\n",
            "        pred_train = rf.predict(self.x_train)\n",
            "\n",
            "        # predict the classes of the validation data using each classifier\n",
            "        pred_val = rf.predict(self.x_val)\n",
            "\n",
            "        self.save_model(rf, \"random_forest.pkl\")\n",
            "\n",
            "        return rf, pred_train, pred_val\n",
            "\n",
            "    def AdaBoost(self):\n",
            "        # Initialize the classifier\n",
            "        clf = AdaBoostClassifier()\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         # Fit the classifier on training data\n",
            "        clf.fit(self.x_train, self.y_train)\n",
            "\n",
            "        # Predict on training data\n",
            "        pred_train = clf.predict(self.x_train)\n",
            "\n",
            "        # Predict on validation data\n",
            "        pred_val = clf.predict(self.x_val)\n",
            "\n",
            "        self.save_model(clf, \"adaboost.pkl\")\n",
            "\n",
            "        return clf, pred_train, pred_val\n",
            "\n",
            "    def save_model(self, model, model_name):\n",
            "        pickle.dump(model, open(model_name, \"wb\"))\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 46:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class PerformanceAnalysis:\n",
            "    def __init__(self, modelName, predictions, true_labels, validation=False):\n",
            "        self.modelName = modelName\n",
            "        self.predictions = predictions\n",
            "        self.true_labels = true_labels\n",
            "        self.validation = validation\n",
            "\n",
            "        # Weights\n",
            "        self.weights = np.zeros(6)\n",
            "        for i in range(6):\n",
            "            self.weights[i] = np.sum(self.true_labels == i) / len(self.true_labels)\n",
            "\n",
            "        \n",
            "        # Performance Metrics\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            " \n",
            "        self.accuracy = 0\n",
            "        \n",
            "        ## Confusion Matrix Parameters\n",
            "        self.true_positives = np.zeros(6)\n",
            "        self.false_positives = np.zeros(6)\n",
            "        self.true_negatives = np.zeros(6)\n",
            "        self.false_negatives = np.zeros(6)\n",
            "        self.confusion_matrix_computed = False\n",
            "        \n",
            "        ## Micro Average\n",
            "        self.micro_avg_precision = 0\n",
            "        self.micro_avg_recall = 0\n",
            "        self.micro_avg_f1 = 0\n",
            "        self.total_TP = 0\n",
            "        self.total_FP = 0\n",
            "        self.total_TN = 0\n",
            "        self.total_FN = 0\n",
            "        \n",
            "        ## Macro Average\n",
            "        self.macro_avg_precision = 0\n",
            "        self.macro_avg_recall = 0\n",
            "        self.macro_avg_f1 = 0\n",
            "        self.avg_TP = 0\n",
            "        self.avg_FP = 0\n",
            "        self.avg_TN = 0\n",
            "        self.avg_FN = 0\n",
            "        \n",
            "        ## Weighted Macro Average\n",
            "        self.weighted_macro_avg_precision = 0\n",
            "        self.weighted_macro_avg_recall = 0\n",
            "        self.weighted_macro_avg_f1 = 0\n",
            "        self.weighted_avg_TP = 0\n",
            "        self.weighted_avg_FP = 0\n",
            "        self.weighted_avg_TN = 0\n",
            "        self.weighted_avg_FN = 0\n",
            "        \n",
            "    def calculate_performance_metrics(self):\n",
            "        # Calculate the confusion matrix\n",
            "        self.__confusion_matrix()\n",
            "        \n",
            "        # Write them to a file\n",
            "        with open('performance_metrics.txt', 'w') as f:\n",
            "            f.write('========================================\\n')\n",
            "            f.write(f'Timestamp: {str(datetime.datetime.now())}\\n')\n",
            "            f.write(f'Model: {self.modelName}\\n')\n",
            "            f.write(f'Accuracy: {np.round(self.accuracy * 100, 2)}%\\n\\n')\n",
            "            f.write(f'Micro Average Precision: {str(self.micro_avg_precision)}\\n')\n",
            "            f.write(f'Micro Average Recall: {str(self.micro_avg_recall)}\\n')\n",
            "            f.write(f'Micro Average F1: {str(np.round(self.micro_avg_f1,2))}\\n\\n')\n",
            "            f.write(f'Macro Average Precision: {str(self.macro_avg_precision)}\\n')\n",
            "            f.write(f'Macro Average Recall: {str(self.macro_avg_recall)}\\n')\n",
            "            f.write(f'Macro Average F1: {str(self.macro_avg_f1)}\\n\\n')\n",
            "            f.write(f'Weighted Macro Average Precision: {str(self.weighted_macro_avg_precision)}\\n')\n",
            "            f.write(f'Weighted Macro Average Recall: {str(self.weighted_macro_avg_recall)}\\n')\n",
            "            f.write(f'Weighted Macro Average F1: {str(self.weighted_macro_avg_f1)}\\n')\n",
            "            f.write('========================================\\n\\n')\n",
            "        \n",
            "        # Print them to the console\n",
            "        if (not self.validation):\n",
            "            print('========================================')\n",
            "            # print(f'Timestamp: {str(datetime.datetime.now())}')\n",
            "            print(f'Model: {self.modelName}')\n",
            "            print(f'Accuracy: {np.round(self.accuracy * 100, 2)}%')\n",
            "            # print(f'Micro Average Precision: {str(self.micro_avg_precision)}')\n",
            "            # print(f'Micro Average Recall: {str(self.micro_avg_recall)}')\n",
            "            # print(f'Micro Average F1: {str(np.round(self.micro_avg_f1,2))}\\n')\n",
            "            # print(f'Macro Average Precision: {str(self.macro_avg_precision)}')\n",
            "            # print(f'Macro Average Recall: {str(self.macro_avg_recall)}')\n",
            "            # print(f'Macro Average F1: {str(self.macro_avg_f1)}\\n')\n",
            "            # print(f'Weighted Macro Average Precision: {str(self.weighted_macro_avg_precision)}')\n",
            "            # print(f'Weighted Macro Average Recall: {str(self.weighted_macro_avg_recall)}')\n",
            "            # print(f'Weighted Macro Average F1: {str(self.weighted_macro_avg_f1)}')\n",
            "            print('========================================\\n')\n",
            "\n",
            "        else:\n",
            "            print(Fore.RED)            \n",
            "            print('*****************************************')\n",
            "            # print(f'Timestamp: {str(datetime.datetime.now())}')\n",
            "            print(f'Model: {self.modelName}')\n",
            "            print(f'Accuracy: {np.round(self.accuracy * 100, 2)}%')\n",
            "            # print(f'Micro Average Precision: {str(self.micro_avg_precision)}')\n",
            "            # print(f'Micro Average Recall: {str(self.micro_avg_recall)}')\n",
            "            # print(f'Micro Average F1: {str(np.round(self.micro_avg_f1,2))}\\n')\n",
            "            # print(f'Macro Average Precision: {str(self.macro_avg_precision)}')\n",
            "            # print(f'Macro Average Recall: {str(self.macro_avg_recall)}')\n",
            "            # print(f'Macro Average F1: {str(self.macro_avg_f1)}\\n')\n",
            "            # print(f'Weighted Macro Average Precision: {str(self.weighted_macro_avg_precision)}')\n",
            "            # print(f'Weighted Macro Average Recall: {str(self.weighted_macro_avg_recall)}')\n",
            "            # print(f'Weighted Macro Average F1: {str(self.weighted_macro_avg_f1)}')\n",
            "            print('*****************************************\\n')\n",
            "            print(Style.RESET_ALL)\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         \n",
            "  \n",
            "    def __confusion_matrix(self):\n",
            "        # print('Predictions shape: ' + str(self.predictions.shape))\n",
            "        for i in range(6):\n",
            "            self.true_positives[i] = np.sum((self.predictions == i) & (self.true_labels == i))\n",
            "            self.false_positives[i] = np.sum((self.predictions == i) & (self.true_labels != i))\n",
            "            self.true_negatives[i] = np.sum((self.predictions != i) & (self.true_labels != i))\n",
            "            self.false_negatives[i] = np.sum((self.predictions != i) & (self.true_labels == i))\n",
            "        self.total_TP = np.sum(self.true_positives)\n",
            "        self.total_FP = np.sum(self.false_positives)\n",
            "        self.total_TN = np.sum(self.true_negatives)\n",
            "        self.total_FN = np.sum(self.false_negatives)\n",
            "        self.avg_TP = np.mean(self.true_positives)\n",
            "        self.avg_FP = np.mean(self.false_positives)\n",
            "        self.avg_TN = np.mean(self.true_negatives)\n",
            "        self.avg_FN = np.mean(self.false_negatives)\n",
            "    \n",
            "        self.__accuracy()\n",
            "        self.__micro_avg_precision()\n",
            "        self.__micro_avg_recall()\n",
            "        self.__micro_avg_f1()\n",
            "        self.__macro_avg_precision()\n",
            "        self.__macro_avg_recall()\n",
            "        self.__macro_avg_f1()\n",
            "        self.__weighted_macro_avg_precision()\n",
            "        self.__weighted_macro_avg_recall()\n",
            "        self.__weighted_macro_avg_f1()\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    def __accuracy(self):\n",
            "        self.accuracy = np.sum(self.predictions == self.true_labels.flatten()) / len(self.true_labels.flatten())\n",
            "        return self.accuracy\n",
            "\n",
            "\n",
            "\n",
            "    #========================================MICRO AVERAGE========================================\n",
            "\n",
            "    def __micro_avg_precision(self):\n",
            "        self.micro_avg_precision = self.total_TP / (self.total_TP + self.total_FP)\n",
            "        # print('Micro Average Precision: ' + str(self.micro_avg_precision_))\n",
            "        return self.micro_avg_precision\n",
            "\n",
            "    def __micro_avg_recall(self):\n",
            "        self.micro_avg_recall =  self.total_TP / (self.total_TP + self.total_FN)\n",
            "        # print('Micro Average Recall: ' + str(self.micro_avg_recall_))\n",
            "        return self.micro_avg_recall\n",
            "    \n",
            "    def __micro_avg_f1(self):\n",
            "        self.micro_avg_f1 = 2 * (self.micro_avg_precision * self.micro_avg_recall) / (self.micro_avg_precision + self.micro_avg_recall)\n",
            "        return self.micro_avg_f1\n",
            "        \n",
            "    \n",
            "    #========================================MACRO AVERAGE========================================\n",
            "\n",
            "    def __macro_avg_precision(self):\n",
            "        temp_arr = self.true_positives / (self.true_positives + self.false_positives)\n",
            "        self.macro_avg_precision = np.mean(temp_arr)\n",
            "        return self.macro_avg_precision\n",
            "\n",
            "    def __macro_avg_recall(self):\n",
            "        temp_arr = self.true_positives / (self.true_positives + self.false_negatives)\n",
            "        self.macro_avg_recall = np.mean(temp_arr)\n",
            "        return self.macro_avg_recall\n",
            "\n",
            "    def __macro_avg_f1(self):\n",
            "        precisions = self.true_positives / (self.true_positives + self.false_negatives)\n",
            "        recalls = self.true_positives / (self.true_positives + self.false_positives)\n",
            "        self.macro_avg_f1 = np.mean(2 * (precisions * recalls) / (precisions + recalls))\n",
            "        return self.macro_avg_f1\n",
            "    \n",
            "    #========================================WEIGHTED MACRO AVERAGE========================================\n",
            "\n",
            "    def __weighted_macro_avg_precision(self):\n",
            "        self.weighted_macro_avg_precision = np.sum(self.weights * (self.true_positives / (self.true_positives + self.false_positives)))\n",
            "        return self.weighted_macro_avg_precision\n",
            "        \n",
            "    def __weighted_macro_avg_recall(self):\n",
            "        self.weighted_macro_avg_recall = np.sum(self.weights * (self.true_positives / (self.true_positives + self.false_negatives)))\n",
            "        return self.weighted_macro_avg_recall\n",
            "        \n",
            "    def __weighted_macro_avg_f1(self):\n",
            "        precisions = self.true_positives / (self.true_positives + self.false_negatives)\n",
            "        recalls = self.true_positives / (self.true_positives + self.false_positives)\n",
            "        self.weighted_macro_avg_f1 = np.sum(self.weights * (2 * (precisions * recalls) / (precisions + recalls)))\n",
            "        return self.weighted_macro_avg_f1\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 47:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class PerformanceAnalysis:\n",
            "    def __init__(self, modelName, predictions, true_labels, validation=False):\n",
            "        self.modelName = modelName\n",
            "        self.predictions = predictions\n",
            "        self.true_labels = true_labels\n",
            "        self.validation = validation\n",
            "\n",
            "        # Weights\n",
            "        self.weights = np.zeros(6)\n",
            "        for i in range(6):\n",
            "            self.weights[i] = np.sum(self.true_labels == i) / len(self.true_labels)\n",
            "\n",
            "        \n",
            "        # Performance Metrics\n",
            "\n",
            "        self.accuracy = 0\n",
            "        \n",
            "        ## Confusion Matrix Parameters\n",
            "        self.true_positives = np.zeros(6)\n",
            "        self.false_positives = np.zeros(6)\n",
            "        self.true_negatives = np.zeros(6)\n",
            "        self.false_negatives = np.zeros(6)\n",
            "        self.confusion_matrix_computed = False\n",
            "        \n",
            "        ## Micro Average\n",
            "        self.micro_avg_precision = 0\n",
            "        self.micro_avg_recall = 0\n",
            "        self.micro_avg_f1 = 0\n",
            "        self.total_TP = 0\n",
            "        self.total_FP = 0\n",
            "        self.total_TN = 0\n",
            "        self.total_FN = 0\n",
            "        \n",
            "        ## Macro Average\n",
            "        self.macro_avg_precision = 0\n",
            "        self.macro_avg_recall = 0\n",
            "        self.macro_avg_f1 = 0\n",
            "        self.avg_TP = 0\n",
            "        self.avg_FP = 0\n",
            "        self.avg_TN = 0\n",
            "        self.avg_FN = 0\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         \n",
            "        ## Weighted Macro Average\n",
            "        self.weighted_macro_avg_precision = 0\n",
            "        self.weighted_macro_avg_recall = 0\n",
            "        self.weighted_macro_avg_f1 = 0\n",
            "        self.weighted_avg_TP = 0\n",
            "        self.weighted_avg_FP = 0\n",
            "        self.weighted_avg_TN = 0\n",
            "        self.weighted_avg_FN = 0\n",
            "        \n",
            "    def calculate_performance_metrics(self):\n",
            "        # Calculate the confusion matrix\n",
            "        self.__confusion_matrix()\n",
            "        \n",
            "        # Write them to a file\n",
            "        with open('performance_metrics.txt', 'w') as f:\n",
            "            f.write('========================================\\n')\n",
            "            f.write(f'Timestamp: {str(datetime.datetime.now())}\\n')\n",
            "            f.write(f'Model: {self.modelName}\\n')\n",
            "            f.write(f'Accuracy: {np.round(self.accuracy * 100, 2)}%\\n\\n')\n",
            "            f.write(f'Micro Average Precision: {str(self.micro_avg_precision)}\\n')\n",
            "            f.write(f'Micro Average Recall: {str(self.micro_avg_recall)}\\n')\n",
            "            f.write(f'Micro Average F1: {str(np.round(self.micro_avg_f1,2))}\\n\\n')\n",
            "            f.write(f'Macro Average Precision: {str(self.macro_avg_precision)}\\n')\n",
            "            f.write(f'Macro Average Recall: {str(self.macro_avg_recall)}\\n')\n",
            "            f.write(f'Macro Average F1: {str(self.macro_avg_f1)}\\n\\n')\n",
            "            f.write(f'Weighted Macro Average Precision: {str(self.weighted_macro_avg_precision)}\\n')\n",
            "            f.write(f'Weighted Macro Average Recall: {str(self.weighted_macro_avg_recall)}\\n')\n",
            "            f.write(f'Weighted Macro Average F1: {str(self.weighted_macro_avg_f1)}\\n')\n",
            "            f.write('========================================\\n\\n')\n",
            "        \n",
            "        # Print them to the console\n",
            "        if (not self.validation):\n",
            "            print('========================================')\n",
            "            # print(f'Timestamp: {str(datetime.datetime.now())}')\n",
            "            print(f'Model: {self.modelName}')\n",
            "            print(f'Accuracy: {np.round(self.accuracy * 100, 2)}%')\n",
            "            # print(f'Micro Average Precision: {str(self.micro_avg_precision)}')\n",
            "            # print(f'Micro Average Recall: {str(self.micro_avg_recall)}')\n",
            "            # print(f'Micro Average F1: {str(np.round(self.micro_avg_f1,2))}\\n')\n",
            "            # print(f'Macro Average Precision: {str(self.macro_avg_precision)}')\n",
            "            # print(f'Macro Average Recall: {str(self.macro_avg_recall)}')\n",
            "            # print(f'Macro Average F1: {str(self.macro_avg_f1)}\\n')\n",
            "            # print(f'Weighted Macro Average Precision: {str(self.weighted_macro_avg_precision)}')\n",
            "            # print(f'Weighted Macro Average Recall: {str(self.weighted_macro_avg_recall)}')\n",
            "            # print(f'Weighted Macro Average F1: {str(self.weighted_macro_avg_f1)}')\n",
            "            print('========================================\\n')\n",
            "\n",
            "        else:\n",
            "            print(Fore.RED)            \n",
            "            print('*****************************************')\n",
            "            # print(f'Timestamp: {str(datetime.datetime.now())}')\n",
            "            print(f'Model: {self.modelName}')\n",
            "            print(f'Accuracy: {np.round(self.accuracy * 100, 2)}%')\n",
            "            # print(f'Micro Average Precision: {str(self.micro_avg_precision)}')\n",
            "            # print(f'Micro Average Recall: {str(self.micro_avg_recall)}')\n",
            "            # print(f'Micro Average F1: {str(np.round(self.micro_avg_f1,2))}\\n')\n",
            "            # print(f'Macro Average Precision: {str(self.macro_avg_precision)}')\n",
            "            # print(f'Macro Average Recall: {str(self.macro_avg_recall)}')\n",
            "            # print(f'Macro Average F1: {str(self.macro_avg_f1)}\\n')\n",
            "            # print(f'Weighted Macro Average Precision: {str(self.weighted_macro_avg_precision)}')\n",
            "            # print(f'Weighted Macro Average Recall: {str(self.weighted_macro_avg_recall)}')\n",
            "            # print(f'Weighted Macro Average F1: {str(self.weighted_macro_avg_f1)}')\n",
            "            print('*****************************************\\n')\n",
            "            print(Style.RESET_ALL)\n",
            "\n",
            "        \n",
            "  \n",
            "    def __confusion_matrix(self):\n",
            "        # print('Predictions shape: ' + str(self.predictions.shape))\n",
            "        for i in range(6):\n",
            "            self.true_positives[i] = np.sum((self.predictions == i) & (self.true_labels == i))\n",
            "            self.false_positives[i] = np.sum((self.predictions == i) & (self.true_labels != i))\n",
            "            self.true_negatives[i] = np.sum((self.predictions != i) & (self.true_labels != i))\n",
            "            self.false_negatives[i] = np.sum((self.predictions != i) & (self.true_labels == i))\n",
            "        self.total_TP = np.sum(self.true_positives)\n",
            "        self.total_FP = np.sum(self.false_positives)\n",
            "        self.total_TN = np.sum(self.true_negatives)\n",
            "        self.total_FN = np.sum(self.false_negatives)\n",
            "        self.avg_TP = np.mean(self.true_positives)\n",
            "        self.avg_FP = np.mean(self.false_positives)\n",
            "        self.avg_TN = np.mean(self.true_negatives)\n",
            "        self.avg_FN = np.mean(self.false_negatives)\n",
            "    \n",
            "        self.__accuracy()\n",
            "        self.__micro_avg_precision()\n",
            "        self.__micro_avg_recall()\n",
            "        self.__micro_avg_f1()\n",
            "        self.__macro_avg_precision()\n",
            "        self.__macro_avg_recall()\n",
            "        self.__macro_avg_f1()\n",
            "        self.__weighted_macro_avg_precision()\n",
            "        self.__weighted_macro_avg_recall()\n",
            "        self.__weighted_macro_avg_f1()\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    def __accuracy(self):\n",
            "        self.accuracy = np.sum(self.predictions == self.true_labels.flatten()) / len(self.true_labels.flatten())\n",
            "        return self.accuracy\n",
            "\n",
            "\n",
            "\n",
            "    #========================================MICRO AVERAGE========================================\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            " \n",
            "    def __micro_avg_precision(self):\n",
            "        self.micro_avg_precision = self.total_TP / (self.total_TP + self.total_FP)\n",
            "        # print('Micro Average Precision: ' + str(self.micro_avg_precision_))\n",
            "        return self.micro_avg_precision\n",
            "\n",
            "    def __micro_avg_recall(self):\n",
            "        self.micro_avg_recall =  self.total_TP / (self.total_TP + self.total_FN)\n",
            "        # print('Micro Average Recall: ' + str(self.micro_avg_recall_))\n",
            "        return self.micro_avg_recall\n",
            "    \n",
            "    def __micro_avg_f1(self):\n",
            "        self.micro_avg_f1 = 2 * (self.micro_avg_precision * self.micro_avg_recall) / (self.micro_avg_precision + self.micro_avg_recall)\n",
            "        return self.micro_avg_f1\n",
            "        \n",
            "    \n",
            "    #========================================MACRO AVERAGE========================================\n",
            "\n",
            "    def __macro_avg_precision(self):\n",
            "        temp_arr = self.true_positives / (self.true_positives + self.false_positives)\n",
            "        self.macro_avg_precision = np.mean(temp_arr)\n",
            "        return self.macro_avg_precision\n",
            "\n",
            "    def __macro_avg_recall(self):\n",
            "        temp_arr = self.true_positives / (self.true_positives + self.false_negatives)\n",
            "        self.macro_avg_recall = np.mean(temp_arr)\n",
            "        return self.macro_avg_recall\n",
            "\n",
            "    def __macro_avg_f1(self):\n",
            "        precisions = self.true_positives / (self.true_positives + self.false_negatives)\n",
            "        recalls = self.true_positives / (self.true_positives + self.false_positives)\n",
            "        self.macro_avg_f1 = np.mean(2 * (precisions * recalls) / (precisions + recalls))\n",
            "        return self.macro_avg_f1\n",
            "    \n",
            "    #========================================WEIGHTED MACRO AVERAGE========================================\n",
            "\n",
            "    def __weighted_macro_avg_precision(self):\n",
            "        self.weighted_macro_avg_precision = np.sum(self.weights * (self.true_positives / (self.true_positives + self.false_positives)))\n",
            "        return self.weighted_macro_avg_precision\n",
            "        \n",
            "    def __weighted_macro_avg_recall(self):\n",
            "        self.weighted_macro_avg_recall = np.sum(self.weights * (self.true_positives / (self.true_positives + self.false_negatives)))\n",
            "        return self.weighted_macro_avg_recall\n",
            "        \n",
            "    def __weighted_macro_avg_f1(self):\n",
            "        precisions = self.true_positives / (self.true_positives + self.false_negatives)\n",
            "        recalls = self.true_positives / (self.true_positives + self.false_positives)\n",
            "        self.weighted_macro_avg_f1 = np.sum(self.weights * (2 * (precisions * recalls) / (precisions + recalls)))\n",
            "        return self.weighted_macro_avg_f1\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n",
            "Example 48:\n",
            "Prefix: \n",
            " import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class PerformanceAnalysis:\n",
            "    def __init__(self, modelName, predictions, true_labels, validation=False):\n",
            "        self.modelName = modelName\n",
            "        self.predictions = predictions\n",
            "        self.true_labels = true_labels\n",
            "        self.validation = validation\n",
            "\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Middle (missing): \n",
            "         # Weights\n",
            "        self.weights = np.zeros(6)\n",
            "        for i in range(6):\n",
            "            self.weights[i] = np.sum(self.true_labels == i) / len(self.true_labels)\n",
            "\n",
            "        \n",
            "        # Performance Metrics\n",
            "\n",
            "        self.accuracy = 0\n",
            "        \n",
            "        ## Confusion Matrix Parameters\n",
            "        self.true_positives = np.zeros(6)\n",
            "        self.false_positives = np.zeros(6)\n",
            "        self.true_negatives = np.zeros(6)\n",
            "        self.false_negatives = np.zeros(6)\n",
            "        self.confusion_matrix_computed = False\n",
            "        \n",
            "        ## Micro Average\n",
            "        self.micro_avg_precision = 0\n",
            "        self.micro_avg_recall = 0\n",
            "        self.micro_avg_f1 = 0\n",
            "        self.total_TP = 0\n",
            "        self.total_FP = 0\n",
            "        self.total_TN = 0\n",
            "        self.total_FN = 0\n",
            "        \n",
            "        ## Macro Average\n",
            "        self.macro_avg_precision = 0\n",
            "        self.macro_avg_recall = 0\n",
            "        self.macro_avg_f1 = 0\n",
            "        self.avg_TP = 0\n",
            "        self.avg_FP = 0\n",
            "        self.avg_TN = 0\n",
            "        self.avg_FN = 0\n",
            "        \n",
            "        ## Weighted Macro Average\n",
            "        self.weighted_macro_avg_precision = 0\n",
            "        self.weighted_macro_avg_recall = 0\n",
            "        self.weighted_macro_avg_f1 = 0\n",
            "        self.weighted_avg_TP = 0\n",
            "        self.weighted_avg_FP = 0\n",
            "        self.weighted_avg_TN = 0\n",
            "        self.weighted_avg_FN = 0\n",
            "        \n",
            "    def calculate_performance_metrics(self):\n",
            "        # Calculate the confusion matrix\n",
            "        self.__confusion_matrix()\n",
            "        \n",
            "        # Write them to a file\n",
            "        with open('performance_metrics.txt', 'w') as f:\n",
            "            f.write('========================================\\n')\n",
            "            f.write(f'Timestamp: {str(datetime.datetime.now())}\\n')\n",
            "            f.write(f'Model: {self.modelName}\\n')\n",
            "            f.write(f'Accuracy: {np.round(self.accuracy * 100, 2)}%\\n\\n')\n",
            "            f.write(f'Micro Average Precision: {str(self.micro_avg_precision)}\\n')\n",
            "            f.write(f'Micro Average Recall: {str(self.micro_avg_recall)}\\n')\n",
            "            f.write(f'Micro Average F1: {str(np.round(self.micro_avg_f1,2))}\\n\\n')\n",
            "            f.write(f'Macro Average Precision: {str(self.macro_avg_precision)}\\n')\n",
            "            f.write(f'Macro Average Recall: {str(self.macro_avg_recall)}\\n')\n",
            "            f.write(f'Macro Average F1: {str(self.macro_avg_f1)}\\n\\n')\n",
            "            f.write(f'Weighted Macro Average Precision: {str(self.weighted_macro_avg_precision)}\\n')\n",
            "            f.write(f'Weighted Macro Average Recall: {str(self.weighted_macro_avg_recall)}\\n')\n",
            "            f.write(f'Weighted Macro Average F1: {str(self.weighted_macro_avg_f1)}\\n')\n",
            "            f.write('========================================\\n\\n')\n",
            "        \n",
            "        # Print them to the console\n",
            "        if (not self.validation):\n",
            "            print('========================================')\n",
            "            # print(f'Timestamp: {str(datetime.datetime.now())}')\n",
            "            print(f'Model: {self.modelName}')\n",
            "            print(f'Accuracy: {np.round(self.accuracy * 100, 2)}%')\n",
            "            # print(f'Micro Average Precision: {str(self.micro_avg_precision)}')\n",
            "            # print(f'Micro Average Recall: {str(self.micro_avg_recall)}')\n",
            "            # print(f'Micro Average F1: {str(np.round(self.micro_avg_f1,2))}\\n')\n",
            "            # print(f'Macro Average Precision: {str(self.macro_avg_precision)}')\n",
            "            # print(f'Macro Average Recall: {str(self.macro_avg_recall)}')\n",
            "            # print(f'Macro Average F1: {str(self.macro_avg_f1)}\\n')\n",
            "            # print(f'Weighted Macro Average Precision: {str(self.weighted_macro_avg_precision)}')\n",
            "            # print(f'Weighted Macro Average Recall: {str(self.weighted_macro_avg_recall)}')\n",
            "            # print(f'Weighted Macro Average F1: {str(self.weighted_macro_avg_f1)}')\n",
            "            print('========================================\\n')\n",
            "\n",
            "        else:\n",
            "            print(Fore.RED)            \n",
            "            print('*****************************************')\n",
            "            # print(f'Timestamp: {str(datetime.datetime.now())}')\n",
            "            print(f'Model: {self.modelName}')\n",
            "            print(f'Accuracy: {np.round(self.accuracy * 100, 2)}%')\n",
            "            # print(f'Micro Average Precision: {str(self.micro_avg_precision)}')\n",
            "            # print(f'Micro Average Recall: {str(self.micro_avg_recall)}')\n",
            "            # print(f'Micro Average F1: {str(np.round(self.micro_avg_f1,2))}\\n')\n",
            "            # print(f'Macro Average Precision: {str(self.macro_avg_precision)}')\n",
            "            # print(f'Macro Average Recall: {str(self.macro_avg_recall)}')\n",
            "            # print(f'Macro Average F1: {str(self.macro_avg_f1)}\\n')\n",
            "            # print(f'Weighted Macro Average Precision: {str(self.weighted_macro_avg_precision)}')\n",
            "            # print(f'Weighted Macro Average Recall: {str(self.weighted_macro_avg_recall)}')\n",
            "            # print(f'Weighted Macro Average F1: {str(self.weighted_macro_avg_f1)}')\n",
            "            print('*****************************************\\n')\n",
            "            print(Style.RESET_ALL)\n",
            "\n",
            "        \n",
            "  \n",
            "    def __confusion_matrix(self):\n",
            "        # print('Predictions shape: ' + str(self.predictions.shape))\n",
            "        for i in range(6):\n",
            "            self.true_positives[i] = np.sum((self.predictions == i) & (self.true_labels == i))\n",
            "            self.false_positives[i] = np.sum((self.predictions == i) & (self.true_labels != i))\n",
            "            self.true_negatives[i] = np.sum((self.predictions != i) & (self.true_labels != i))\n",
            "            self.false_negatives[i] = np.sum((self.predictions != i) & (self.true_labels == i))\n",
            "        self.total_TP = np.sum(self.true_positives)\n",
            "        self.total_FP = np.sum(self.false_positives)\n",
            "        self.total_TN = np.sum(self.true_negatives)\n",
            "        self.total_FN = np.sum(self.false_negatives)\n",
            "        self.avg_TP = np.mean(self.true_positives)\n",
            "        self.avg_FP = np.mean(self.false_positives)\n",
            "        self.avg_TN = np.mean(self.true_negatives)\n",
            "        self.avg_FN = np.mean(self.false_negatives)\n",
            "    \n",
            "        self.__accuracy()\n",
            "        self.__micro_avg_precision()\n",
            "        self.__micro_avg_recall()\n",
            "        self.__micro_avg_f1()\n",
            "        self.__macro_avg_precision()\n",
            "        self.__macro_avg_recall()\n",
            "        self.__macro_avg_f1()\n",
            "        self.__weighted_macro_avg_precision()\n",
            "        self.__weighted_macro_avg_recall()\n",
            "        self.__weighted_macro_avg_f1()\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    def __accuracy(self):\n",
            "        self.accuracy = np.sum(self.predictions == self.true_labels.flatten()) / len(self.true_labels.flatten())\n",
            "        return self.accuracy\n",
            "\n",
            "\n",
            "\n",
            "    #========================================MICRO AVERAGE========================================\n",
            "\n",
            "    def __micro_avg_precision(self):\n",
            "        self.micro_avg_precision = self.total_TP / (self.total_TP + self.total_FP)\n",
            "        # print('Micro Average Precision: ' + str(self.micro_avg_precision_))\n",
            "        return self.micro_avg_precision\n",
            "\n",
            "    def __micro_avg_recall(self):\n",
            "        self.micro_avg_recall =  self.total_TP / (self.total_TP + self.total_FN)\n",
            "        # print('Micro Average Recall: ' + str(self.micro_avg_recall_))\n",
            "        return self.micro_avg_recall\n",
            "    \n",
            "    def __micro_avg_f1(self):\n",
            "        self.micro_avg_f1 = 2 * (self.micro_avg_precision * self.micro_avg_recall) / (self.micro_avg_precision + self.micro_avg_recall)\n",
            "        return self.micro_avg_f1\n",
            "        \n",
            "    \n",
            "    #========================================MACRO AVERAGE========================================\n",
            "\n",
            "    def __macro_avg_precision(self):\n",
            "        temp_arr = self.true_positives / (self.true_positives + self.false_positives)\n",
            "        self.macro_avg_precision = np.mean(temp_arr)\n",
            "        return self.macro_avg_precision\n",
            "\n",
            "    def __macro_avg_recall(self):\n",
            "        temp_arr = self.true_positives / (self.true_positives + self.false_negatives)\n",
            "        self.macro_avg_recall = np.mean(temp_arr)\n",
            "        return self.macro_avg_recall\n",
            "\n",
            "    def __macro_avg_f1(self):\n",
            "        precisions = self.true_positives / (self.true_positives + self.false_negatives)\n",
            "        recalls = self.true_positives / (self.true_positives + self.false_positives)\n",
            "        self.macro_avg_f1 = np.mean(2 * (precisions * recalls) / (precisions + recalls))\n",
            "        return self.macro_avg_f1\n",
            "    \n",
            "    #========================================WEIGHTED MACRO AVERAGE========================================\n",
            "\n",
            "    def __weighted_macro_avg_precision(self):\n",
            "        self.weighted_macro_avg_precision = np.sum(self.weights * (self.true_positives / (self.true_positives + self.false_positives)))\n",
            "        return self.weighted_macro_avg_precision\n",
            "        \n",
            "    def __weighted_macro_avg_recall(self):\n",
            "        self.weighted_macro_avg_recall = np.sum(self.weights * (self.true_positives / (self.true_positives + self.false_negatives)))\n",
            "        return self.weighted_macro_avg_recall\n",
            "        \n",
            "    def __weighted_macro_avg_f1(self):\n",
            "        precisions = self.true_positives / (self.true_positives + self.false_negatives)\n",
            "        recalls = self.true_positives / (self.true_positives + self.false_positives)\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Suffix: \n",
            "         self.weighted_macro_avg_f1 = np.sum(self.weights * (2 * (precisions * recalls) / (precisions + recalls)))\n",
            "        return self.weighted_macro_avg_f1\n",
            "---------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "import json\n",
        "from transformers import AutoModelForSequenceClassification, AutoModelForTokenClassification, AutoTokenizer\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2l0j-gIbj9xb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#login huggingface\n",
        "\n",
        "# Log in using the token from the environment variable\n",
        "login(token=os.getenv(\"HF_TOKEN\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CGfgB8zj-7q",
        "outputId": "0db319c2-08a7-4d4e-d583-2b5ea765209b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sane hyper-parameters\n",
        "params = {\n",
        "    'max_new_tokens': 200,\n",
        "    'temperature': 0.2,\n",
        "    'top_k': 50,\n",
        "    'top_p': 0.1,\n",
        "    'repetition_penalty': 1.17\n",
        "}\n",
        "device = \"cuda\"\n"
      ],
      "metadata": {
        "id": "adEZYG2d1-H7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tested the model using tiny_starcoder before but found out CodeLlama is much better, thats why its commented\n",
        "\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# checkpoint = \"bigcode/tiny_starcoder_py\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "# model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
      ],
      "metadata": {
        "id": "qSB2up-Bj_yp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer\n",
        ")\n",
        "\n",
        "base_model_id = \"codellama/CodeLlama-7b-hf\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    quantization_config=None,\n",
        "    device_map=None,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        ").to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "4686168995864e759e186d7fd918e760",
            "ee7b9cecbc6f40088ea5f2367d335a45",
            "12bf162d434845e9ac4232c4574c0018",
            "af54eb0306254a2b85a253c6810e1d69",
            "9e544e16614f4d9ba0d70e98948ec925",
            "c7bcb65fc0d54533a3a48974d61338e3",
            "826d8188ff884735abd2f98764ba110d",
            "31e77e6b20c14be1907f066476a6c134",
            "726fb2007f064bf7a52762b192ceb02b",
            "47c841d17ccc4567810669e78e1dca88",
            "deb9ab1daa544a79a28dfb40d8c901f6"
          ]
        },
        "id": "0CR01PAU1fEu",
        "outputId": "629165dc-c72a-4c4b-b34d-73f04d68eb5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4686168995864e759e186d7fd918e760"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying a demo on filling first\n",
        "prompt = '''def hello_world():\n",
        "    <FILL_ME>\n",
        "'''\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    **params\n",
        ")\n",
        "\n",
        "filling = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "print(filling)"
      ],
      "metadata": {
        "id": "zeV0bqlmkAZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d832f5-0131-4983-f672-703623cb3031"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> <PRE> def hello_world():\n",
            "     <SUF>\n",
            " <MID>print(\"Hello World!\") <EOT></s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "def extract_middle(output_text):\n",
        "    # Ensure that both the <fim_middle> and <|endoftext|> tokens are in the output\n",
        "    if \"<MID>\" in output_text:\n",
        "        # Find the starting point after <fim_middle> and ending before <|endoftext|>\n",
        "        start = output_text.index(\"<MID>\") + len(\"<MID>\")\n",
        "        if \"<EOT>\" in output_text:\n",
        "          end = output_text.index(\"<EOT>\")\n",
        "        else:\n",
        "          end = len(output_text)\n",
        "        generated_middle = output_text[start:end].strip()  # Extract and strip any surrounding whitespace\n",
        "        return generated_middle\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Function to apply fill-in-the-middle using StarCoder\n",
        "def apply_fill_in_the_middle(dataset):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, (prefix, middle, suffix) in enumerate(dataset):\n",
        "        # Prepare FIM input for the model\n",
        "        fim_input = f\"{prefix}<FILL_ME>{suffix}\"\n",
        "        # Tokenize the input\n",
        "        inputs = tokenizer.encode(fim_input, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Generate the middle part\n",
        "        outputs = model.generate(inputs, pad_token_id=tokenizer.eos_token_id, **params)\n",
        "\n",
        "        # Decode the output to get the generated middle code\n",
        "        generated_middle = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "        # Save the result (original middle, generated middle)\n",
        "        results.append({\n",
        "            \"prefix\": prefix,\n",
        "            \"suffix\": suffix,\n",
        "            \"actual_middle\": middle,\n",
        "            \"generated_middle\": extract_middle(generated_middle),\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Applying fill-in-the-middle on the dataset\n",
        "results = apply_fill_in_the_middle(dataset[5:10])\n",
        "\n",
        "# Print the results\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(\"Prefix: \\n\", result['prefix'])\n",
        "    print(\"Actual Middle: \\n\", result['actual_middle'])\n",
        "    print(\"Generated Middle: \\n\", result['generated_middle'])\n",
        "    print(\"Suffix: \\n\", result['suffix'])\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "KAIfDeQ8kBDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e970b2-5d7f-462d-93b3-551fc6d11253"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "Prefix: from tensorflow.keras.models import load_model\n",
            "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
            "from keras.models import Sequential\n",
            "from keras.layers import Dense\n",
            "from keras.utils import to_categorical\n",
            "from keras import regularizers\n",
            "\n",
            "from sklearn.decomposition import PCA\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.neighbors import KNeighborsClassifier\n",
            "from sklearn.svm import SVC\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "from sklearn.metrics import accuracy_score\n",
            "from sklearn.ensemble import AdaBoostClassifier\n",
            "from sklearn.cluster import KMeans\n",
            "\n",
            "from skimage.filters import sobel, prewitt, roberts, laplace , median, gaussian, threshold_otsu, rank, threshold_local\n",
            "from skimage.feature import canny\n",
            "from skimage.restoration import denoise_nl_means, wiener\n",
            "from skimage.morphology import disk , square\n",
            "from skimage.draw import rectangle\n",
            "\n",
            "Actual Middle \n",
            " from skimage import exposure, filters\n",
            "from skimage.segmentation import felzenszwalb, slic, quickshift\n",
            "from skimage.segmentation import slic\n",
            "from skimage.segmentation import mark_boundaries\n",
            "from skimage.util import img_as_float\n",
            "from skimage.transform import resize\n",
            "from skimage.measure import regionprops\n",
            "from skimage.color import label2rgb\n",
            "from skimage.morphology import closing, disk, skeletonize\n",
            "from skimage.util import invert\n",
            "from skimage.segmentation import clear_border\n",
            "from skimage.feature import hog, local_binary_pattern\n",
            "from skimage.color import rgb2gray\n",
            "from skimage.feature import daisy\n",
            "\n",
            "from scipy.fftpack import fft\n",
            "from scipy.signal import convolve2d\n",
            "from scipy.ndimage import convolve\n",
            "from scipy import ndimage as ndi\n",
            "\n",
            "from pathlib import Path\n",
            "from PIL import Image, ImageOps\n",
            "from pyefd import elliptic_fourier_descriptors\n",
            "# from multiprocessing import Pool\n",
            "from colorama import Fore, Back, Style\n",
            "\n",
            "Generated Middle \n",
            " from skimage.transform import rotate\n",
            "Suffix: from skfuzzy.cluster import cmeans\n",
            "\n",
            "import pickle\n",
            "import time\n",
            "import cv2\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "import os\n",
            "import tqdm\n",
            "import hmmlearn.hmm as hmm\n",
            "import datetime\n",
            "import colorama\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Example 2:\n",
            "Prefix: # Required Files in the same directory:\n",
            "# 1. model.h5\n",
            "# 2. pca.pkl\n",
            "# 3. extracted_features_train_mean.npy\n",
            "# 4. extracted_features_train_std.npy\n",
            "\n",
            "from dataloader.dataloader import DataLoader\n",
            "from feature_extraction.feature_extraction import FeatureExtractor\n",
            "from feature_selection.feature_selection import FeatureSelector\n",
            "from model_selection.model_selection import ModelSelection\n",
            "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
            "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
            "from preprocessing.image_aligner import ImageAligner\n",
            "\n",
            "from imports import *\n",
            "\n",
            "data_loader = DataLoader(Path('./test'))\n",
            "illumination_processing = IlluminationPreprocessing()\n",
            "feature_extractor = FeatureExtractor()\n",
            "feature_selector = FeatureSelector()\n",
            "image_aligner = ImageAligner()\n",
            "\n",
            "model = load_model(\"model.h5\")\n",
            "pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "extracted_features_train_mean = np.load(\"extracted_features_train_mean.npy\")\n",
            "extracted_features_train_std = np.load(\"extracted_features_train_std.npy\")\n",
            "\n",
            "path = Path('./test')\n",
            "\n",
            "if os.path.exists(\"results.txt\"):\n",
            "    os.remove(\"results.txt\")\n",
            "if os.path.exists(\"time.txt\"):\n",
            "    os.remove(\"time.txt\")\n",
            "\n",
            "results_file = open(\"results.txt\", \"w\")\n",
            "time_file = open(\"time.txt\", \"w\")\n",
            "\n",
            "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
            "\n",
            "# Sort the list of files in increasing order\n",
            "files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
            "\n",
            "# Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
            "for i, filename in enumerate(files):\n",
            "    img = cv2.imread(os.path.join(path, filename))\n",
            "    img = np.array(img)\n",
            "    \n",
            "    # Get current time\n",
            "    start = time.perf_counter()\n",
            "\n",
            "Actual Middle \n",
            "     \n",
            "    # Resize the image\n",
            "    img = data_loader.custom_resize_img(img)\n",
            "    \n",
            "    # Illumination Preprocessing\n",
            "    illuminated_test, _ = illumination_processing.process_image(img)\n",
            "\n",
            "    # Image Alignment\n",
            "    aligned_test = image_aligner.align_image([illuminated_test])[0]\n",
            "\n",
            "Generated Middle \n",
            " # Align images\n",
            "    aligned_test = image_aligner.align_images([img], data_loader.get_reference())[0]\n",
            "Suffix: \n",
            "    # Feature extraction and selection\n",
            "    daisy_features_test = feature_extractor.extract_daisy_features([aligned_test])[0]\n",
            "\n",
            "    pca_daisy_features_test = feature_selector.test_pca(daisy_features_test,pca)\n",
            "    \n",
            "    pca_daisy_features_test = (pca_daisy_features_test - extracted_features_train_mean) /extracted_features_train_std\n",
            "\n",
            "    # Model loading and prediction\n",
            "    model_prediction = model.predict(pca_daisy_features_test)\n",
            "\n",
            "    # Only in case of ANN\n",
            "    model_prediction = model_prediction.argmax(axis=1)\n",
            "    \n",
            "    # stop timer\n",
            "    end = time.perf_counter()\n",
            "    \n",
            "    total_time_seconds = round(end - start, 3)\n",
            "\n",
            "    # write the prediction in results file\n",
            "    results_file.write(f\"{int(model_prediction[0])}\\n\")\n",
            "    \n",
            "    # write the time in times file\n",
            "    time_file.write(f\"{total_time_seconds}\\n\")\n",
            "\n",
            "results_file.close()\n",
            "time_file.close()\n",
            "\n",
            "\n",
            "Example 3:\n",
            "Prefix: # Required Files in the same directory:\n",
            "# 1. model.h5\n",
            "# 2. pca.pkl\n",
            "# 3. extracted_features_train_mean.npy\n",
            "# 4. extracted_features_train_std.npy\n",
            "\n",
            "from dataloader.dataloader import DataLoader\n",
            "from feature_extraction.feature_extraction import FeatureExtractor\n",
            "from feature_selection.feature_selection import FeatureSelector\n",
            "from model_selection.model_selection import ModelSelection\n",
            "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
            "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
            "from preprocessing.image_aligner import ImageAligner\n",
            "\n",
            "from imports import *\n",
            "\n",
            "data_loader = DataLoader(Path('./test'))\n",
            "illumination_processing = IlluminationPreprocessing()\n",
            "feature_extractor = FeatureExtractor()\n",
            "feature_selector = FeatureSelector()\n",
            "image_aligner = ImageAligner()\n",
            "\n",
            "model = load_model(\"model.h5\")\n",
            "pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "extracted_features_train_mean = np.load(\"extracted_features_train_mean.npy\")\n",
            "extracted_features_train_std = np.load(\"extracted_features_train_std.npy\")\n",
            "\n",
            "path = Path('./test')\n",
            "\n",
            "if os.path.exists(\"results.txt\"):\n",
            "    os.remove(\"results.txt\")\n",
            "if os.path.exists(\"time.txt\"):\n",
            "    os.remove(\"time.txt\")\n",
            "\n",
            "results_file = open(\"results.txt\", \"w\")\n",
            "time_file = open(\"time.txt\", \"w\")\n",
            "\n",
            "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
            "\n",
            "# Sort the list of files in increasing order\n",
            "files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
            "\n",
            "# Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
            "for i, filename in enumerate(files):\n",
            "    img = cv2.imread(os.path.join(path, filename))\n",
            "    img = np.array(img)\n",
            "    \n",
            "    # Get current time\n",
            "    start = time.perf_counter()\n",
            "    \n",
            "    # Resize the image\n",
            "    img = data_loader.custom_resize_img(img)\n",
            "    \n",
            "    # Illumination Preprocessing\n",
            "    illuminated_test, _ = illumination_processing.process_image(img)\n",
            "\n",
            "    # Image Alignment\n",
            "    aligned_test = image_aligner.align_image([illuminated_test])[0]\n",
            "\n",
            "    # Feature extraction and selection\n",
            "    daisy_features_test = feature_extractor.extract_daisy_features([aligned_test])[0]\n",
            "\n",
            "    pca_daisy_features_test = feature_selector.test_pca(daisy_features_test,pca)\n",
            "    \n",
            "    pca_daisy_features_test = (pca_daisy_features_test - extracted_features_train_mean) /extracted_features_train_std\n",
            "\n",
            "\n",
            "Actual Middle \n",
            "     # Model loading and prediction\n",
            "    model_prediction = model.predict(pca_daisy_features_test)\n",
            "\n",
            "    # Only in case of ANN\n",
            "    model_prediction = model_prediction.argmax(axis=1)\n",
            "    \n",
            "    # stop timer\n",
            "    end = time.perf_counter()\n",
            "    \n",
            "    total_time_seconds = round(end - start, 3)\n",
            "\n",
            "\n",
            "Generated Middle \n",
            " # Predicting the class label\n",
            "    model_prediction = model.predict(np.expand_dims(pca_daisy_features_test, axis=0))\n",
            "\n",
            "    total_time_seconds = round((time.perf_counter()-start), 6)\n",
            "Suffix:     # write the prediction in results file\n",
            "    results_file.write(f\"{int(model_prediction[0])}\\n\")\n",
            "    \n",
            "    # write the time in times file\n",
            "    time_file.write(f\"{total_time_seconds}\\n\")\n",
            "\n",
            "results_file.close()\n",
            "time_file.close()\n",
            "\n",
            "\n",
            "Example 4:\n",
            "Prefix: # Required Files in the same directory:\n",
            "# 1. model.h5\n",
            "# 2. pca.pkl\n",
            "# 3. extracted_features_train_mean.npy\n",
            "# 4. extracted_features_train_std.npy\n",
            "\n",
            "from dataloader.dataloader import DataLoader\n",
            "from feature_extraction.feature_extraction import FeatureExtractor\n",
            "from feature_selection.feature_selection import FeatureSelector\n",
            "from model_selection.model_selection import ModelSelection\n",
            "from performance_analysis.performance_analysis import PerformanceAnalysis\n",
            "from illumination_preprocessing.illumination_preprocessing import IlluminationPreprocessing\n",
            "from preprocessing.image_aligner import ImageAligner\n",
            "\n",
            "from imports import *\n",
            "\n",
            "data_loader = DataLoader(Path('./test'))\n",
            "illumination_processing = IlluminationPreprocessing()\n",
            "feature_extractor = FeatureExtractor()\n",
            "feature_selector = FeatureSelector()\n",
            "image_aligner = ImageAligner()\n",
            "\n",
            "model = load_model(\"model.h5\")\n",
            "pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "extracted_features_train_mean = np.load(\"extracted_features_train_mean.npy\")\n",
            "extracted_features_train_std = np.load(\"extracted_features_train_std.npy\")\n",
            "\n",
            "path = Path('./test')\n",
            "\n",
            "if os.path.exists(\"results.txt\"):\n",
            "    os.remove(\"results.txt\")\n",
            "if os.path.exists(\"time.txt\"):\n",
            "    os.remove(\"time.txt\")\n",
            "\n",
            "results_file = open(\"results.txt\", \"w\")\n",
            "time_file = open(\"time.txt\", \"w\")\n",
            "\n",
            "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
            "\n",
            "# Sort the list of files in increasing order\n",
            "files.sort(key=lambda x: int(os.path.splitext(x)[0]))\n",
            "\n",
            "# Loop over all the image files, read each image using cv2.imread and store it in the numpy array\n",
            "for i, filename in enumerate(files):\n",
            "    img = cv2.imread(os.path.join(path, filename))\n",
            "    img = np.array(img)\n",
            "    \n",
            "    # Get current time\n",
            "    start = time.perf_counter()\n",
            "    \n",
            "    # Resize the image\n",
            "    img = data_loader.custom_resize_img(img)\n",
            "    \n",
            "    # Illumination Preprocessing\n",
            "    illuminated_test, _ = illumination_processing.process_image(img)\n",
            "\n",
            "    # Image Alignment\n",
            "    aligned_test = image_aligner.align_image([illuminated_test])[0]\n",
            "\n",
            "    # Feature extraction and selection\n",
            "    daisy_features_test = feature_extractor.extract_daisy_features([aligned_test])[0]\n",
            "\n",
            "    pca_daisy_features_test = feature_selector.test_pca(daisy_features_test,pca)\n",
            "    \n",
            "    pca_daisy_features_test = (pca_daisy_features_test - extracted_features_train_mean) /extracted_features_train_std\n",
            "\n",
            "    # Model loading and prediction\n",
            "    model_prediction = model.predict(pca_daisy_features_test)\n",
            "\n",
            "    # Only in case of ANN\n",
            "    model_prediction = model_prediction.argmax(axis=1)\n",
            "    \n",
            "    # stop timer\n",
            "    end = time.perf_counter()\n",
            "    \n",
            "    total_time_seconds = round(end - start, 3)\n",
            "\n",
            "    # write the prediction in results file\n",
            "    results_file.write(f\"{int(model_prediction[0])}\\n\")\n",
            "    \n",
            "    # write the time in times file\n",
            "\n",
            "Actual Middle \n",
            "     time_file.write(f\"{total_time_seconds}\\n\")\n",
            "\n",
            "\n",
            "Generated Middle \n",
            " time_file.write(f\"{total_time_seconds}\\n\")\n",
            "Suffix: results_file.close()\n",
            "time_file.close()\n",
            "\n",
            "\n",
            "Example 5:\n",
            "Prefix: import sys\n",
            "sys.path.append('../')\n",
            "\n",
            "from imports import *\n",
            "\n",
            "\n",
            "class FeatureSelector:\n",
            "    def __init__(self) -> None:\n",
            "        pass\n",
            "\n",
            "    def extract_pca_features(self, images, load=False, num_pca_components=0.95):\n",
            "        \"\"\"\n",
            "        The extract_pca_features function takes as input a NumPy array of images and an optional parameter num_components that specifies the number of principal components to use as features (default is 20).\n",
            "        For each image, the function flattens the image into a 1D vector and appends it to a list of image vectors.\n",
            "        It then converts the list of image vectors to a NumPy array and performs PCA using scikit-learn's PCA function.\n",
            "        Finally, the function extracts the first num_components principal components and returns them as the PCA features.\n",
            "        \"\"\"\n",
            "        image_vectors = []\n",
            "        for image in images:\n",
            "            image_vectors.append(image.flatten())\n",
            "        image_vectors = np.array(image_vectors)\n",
            "        \n",
            "        if load:\n",
            "            pca = pickle.load(open(\"pca.pkl\", \"rb\"))\n",
            "            pca_features = pca.transform(image_vectors)\n",
            "            return pca_features\n",
            "        else:\n",
            "\n",
            "Actual Middle \n",
            "             print(\"Creating new PCA model...\")\n",
            "            pca = PCA(n_components = num_pca_components, svd_solver = 'full')\n",
            "            pca.fit(image_vectors)\n",
            "\n",
            "            pca_features = pca.transform(image_vectors)\n",
            "\n",
            "            pca_features = np.array(pca_features)\n",
            "            \n",
            "            pickle.dump(pca, open(\"pca.pkl\", \"wb\"))\n",
            "            \n",
            "            return pca_features\n",
            "        \n",
            "    def test_pca(self,img, pca):\n",
            "        image_vector = img.flatten()\n",
            "        pca_features = pca.transform(np.array([image_vector]))\n",
            "        return pca_features\n",
            "\n",
            "Generated Middle \n",
            " pca = PCA(n_components=num_pca_components)\n",
            "            pca.fit(image_vectors)\n",
            "            pickle.dump(pca, open(\"pca.pkl\", \"wb\"))\n",
            "            \n",
            "            pca_features = pca.transform(image_vectors)\n",
            "            return pca_features\n",
            "Suffix:         \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Section"
      ],
      "metadata": {
        "id": "27bnqoOrAkK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.chrf_score import sentence_chrf\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "import torch\n",
        "\n",
        "\n",
        "def exact_match(actual_middle, generated_middle):\n",
        "    return int(actual_middle.strip() == generated_middle.strip())\n",
        "\n",
        "def chrf_score(actual_middle, generated_middle):\n",
        "    return sentence_chrf(actual_middle, generated_middle)\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def bleu_score(actual_middle, generated_middle):\n",
        "    reference = [list(actual_middle)]\n",
        "    candidate = list(generated_middle)\n",
        "    return sentence_bleu(reference, candidate)\n",
        "\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "def levenshtein_ratio(actual_middle, generated_middle):\n",
        "    return SequenceMatcher(None, actual_middle, generated_middle).ratio()\n",
        "\n",
        "import ast\n",
        "\n",
        "def is_syntax_valid(generated_middle):\n",
        "    try:\n",
        "        ast.parse(generated_middle)\n",
        "        return 1  # Valid code\n",
        "    except SyntaxError:\n",
        "        return 0  # Invalid code\n",
        "\n",
        "# Load CodeBERT\n",
        "eval_tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')\n",
        "eval_model = RobertaModel.from_pretrained('microsoft/codebert-base')\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_model.to(device)\n",
        "\n",
        "def get_code_embedding(code):\n",
        "    inputs = eval_tokenizer(code, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = eval_model(**inputs)\n",
        "        # Take the mean of the token embeddings for the final representation\n",
        "        return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def code_similarity(actual_middle, generated_middle):\n",
        "    actual_embedding = get_code_embedding(actual_middle)\n",
        "    generated_embedding = get_code_embedding(generated_middle)\n",
        "    similarity = cosine_similarity([actual_embedding], [generated_embedding])\n",
        "    return similarity[0][0]  # Extract the similarity value\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "60f5cfc48c394ef08f044dad03a50227",
            "2aea51a7f6f340cb88657ca29be2ddfc",
            "4af619a83b3144dd866cda2571774b70",
            "58a4749b7a3b4f6ba113ae962bad42f3",
            "743125700e0c4050a9ea3586b52622af",
            "a54b8c92f45e488cb2831efa54e90fdf",
            "535121458b84497db8dc1d891b16298b",
            "0ad4f9868326492a996fa431ca7431ad",
            "d6a34f7457a84b0897eba81ff48212d7",
            "ac234e1b33054c42b6949c0769c34ff0",
            "fbfd7e1a8a1b4baf911431d12adc7f32",
            "0d1f23a6d53a49f38e0f95db00216eee",
            "d97fdc62c2cc4354bf41ed82619bb3fb",
            "f3f696e1e3c24362b6574c1a8f2d2159",
            "698de0988cf14796a835285818b2bab6",
            "f1f248fd9b2346f6b327e0534e6804ce",
            "11216b0f00e74a23974a08388d7480c7",
            "6fc8f2bf5d8f443eb675d067d060b78e",
            "a1b37f1e6f0541569e643ebe94ac2e5c",
            "0b490ae809c345a8824efb80d302fdc8",
            "58ecee6ee53448fb9ee883389dca4f43",
            "6a53dfe892994e1f85e2090457fb4615",
            "e37b6baede6b43e4a27478f433b7eefe",
            "5b52182bebeb4cda8cd02d2e0a93ce22",
            "5c9f141c68d744889eb1c046950a2b0f",
            "4a1c4543996041b589931683eae8fb03",
            "dd609d2371d9446b8c3fe443e82bdae2",
            "1af0b387f09c4044bcb40ad2f070110a",
            "da1a5d6c7f574b53ad15d8769738e7b6",
            "7c371e2de859427a95a1911bf62694cb",
            "3ce544ba80f34a96ab6247e8a41796ba",
            "c8c9502a796542919e1a9014e2d5e66f",
            "955090510f8d4867a9c0f4176c5f2942",
            "0658ee95e01f4bf18f1cf3ed112b573d",
            "6e4cf4dc9e72471c9811c13d455ea72e",
            "76614e1f1ca340c8961f91435a78f89a",
            "133ad04cb5be405a8e2ba91dd72a5ed3",
            "97d1e4da203e4126aa92bfc592778481",
            "4737fb9adbc7423c80457eecaa57b0e1",
            "fb663774f1904a039cc08c86a5ea7d41",
            "908f89e9bc294be6b8a4b4ca166aaba3",
            "45697a53b6954b70be2d3d025bf21f46",
            "2b20f0eb582849df939d9ebac0d6a690",
            "2c23838042ef415fb3a3be407b62ae9f",
            "f403ff6b11224fba8742b7b56bfc773d",
            "aa4c82caef34451bbf4da17f136b4b10",
            "593d7b8a6a624152be4ccf3ad6710cbc",
            "75e300073f5e4863a95adeb9b6cdb110",
            "4402d2c23e51417ea514fb3c86bda37e",
            "9f06327626aa4e489b341f22a4b68388",
            "0f8a2065422a42c994f08d6b2048b8e4",
            "d398430b9d9d4f1280698e48ffddfb6d",
            "1af3118131e642a78bb15b725a143cfa",
            "79a4e30ba608416aa8ffbf1c4caabf62",
            "e0e03b7d812a436fb91eb7bd011f8fe7",
            "906467d1c39f461280538119b483421f",
            "feb26b7a610549b0bc4bcb2f099cff8c",
            "7f98a63e8e8e47aea197c33ccaf35baa",
            "547cfd14790e4ea4a15686e9a3817a25",
            "9af383f0f322494c9a031958a7a99061",
            "b976c11a8b7549c892a5a6ad727ccdb7",
            "8c5b40b0264a4e44b508ff247a8c8401",
            "9eb7c603a03a4641a5a9cf267a8025ae",
            "f723371adadb44b48fab7c3a3edd36fa",
            "dec4c78e4fdb4b4c8657cf40bf633682",
            "495b64151656433b8fd2e9470b67e057"
          ]
        },
        "id": "-kO_PnyA8hpv",
        "outputId": "855a12f8-b3e3-4294-b81f-a340e4f4d76f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60f5cfc48c394ef08f044dad03a50227"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d1f23a6d53a49f38e0f95db00216eee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e37b6baede6b43e4a27478f433b7eefe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0658ee95e01f4bf18f1cf3ed112b573d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f403ff6b11224fba8742b7b56bfc773d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "906467d1c39f461280538119b483421f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "\n",
        "def evaluate_model(results):\n",
        "    exact_match_scores = []\n",
        "    chrf_scores = []\n",
        "    bleu_scores = []\n",
        "    levenshtein_scores = []\n",
        "    syntactic_similarity_scores = []\n",
        "\n",
        "    for result in results:\n",
        "        actual_middle = result['actual_middle']\n",
        "        generated_middle = result['generated_middle'] or \"\"\n",
        "\n",
        "        exact_match_scores.append(exact_match(actual_middle, generated_middle))\n",
        "        chrf_scores.append(chrf_score(actual_middle, generated_middle))\n",
        "        bleu_scores.append(bleu_score(actual_middle, generated_middle))\n",
        "        levenshtein_scores.append(levenshtein_ratio(actual_middle, generated_middle))\n",
        "        syntactic_similarity_scores.append(code_similarity(actual_middle, generated_middle))\n",
        "\n",
        "    return {\n",
        "        \"Exact Match\": mean(exact_match_scores),\n",
        "        \"chrF Score\": mean(chrf_scores),\n",
        "        \"BLEU Score\": mean(bleu_scores),\n",
        "        \"Levenshtein Ratio\": mean(levenshtein_scores),\n",
        "        \"Syntactic Similarity\": mean(syntactic_similarity_scores)\n",
        "    }\n",
        "\n",
        "# Run evaluation on the results\n",
        "evaluation = evaluate_model(results)\n",
        "print(evaluation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h7huo-l-1Ms",
        "outputId": "361c9b4a-45bf-4d99-bb30-2ecad1cc8b7e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Exact Match': 0, 'chrF Score': 0.32759649710376354, 'BLEU Score': 0.32761429252470736, 'Levenshtein Ratio': 0.11234714383277125, 'Syntactic Similarity': 0.8496151}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explaining Evaluation\n",
        "#1. Exact Match: 0\n",
        "\n",
        "Interpretation: An exact match score of 0 indicates that none of the generated middle segments perfectly match the actual middle segments across your dataset. This could suggest that while the model is generating relevant content, it is not producing the exact code that was intended. This is often the case in creative tasks like code generation, where multiple valid implementations may exist.\n",
        "\n",
        "#2. chrF Score: 0.3276\n",
        "\n",
        "Interpretation: A chrF score of 0.3276 indicates a moderate level of similarity between the generated and actual code snippets at the character level. This score suggests that there are some overlapping character sequences, indicating that the generated code is somewhat aligned with the intended output, but there is still room for improvement.\n",
        "\n",
        "#3. BLEU Score: 0.3276\n",
        "\n",
        "Interpretation: A BLEU score of 0.3276 suggests that there is a moderate level of overlap between the n-grams of the generated and actual code segments. Similar to the chrF score, this indicates that while the generated code has some valid segments, it does not fully capture the intended middle segments.\n",
        "\n",
        "#4. Levenshtein Ratio: 0.1123\n",
        "\n",
        "Interpretation: A Levenshtein ratio of 0.1123 indicates a low level of similarity between the actual and generated middle segments. This low score suggests that the generated outputs are relatively far from the actual outputs, requiring considerable edits to align with the intended code. This might point to substantial differences in structure or content.\n",
        "\n",
        "#5. Syntactic Similarity: 0.8496\n",
        "\n",
        "Interpretation: A syntactic similarity score of 0.8496 indicates a high degree of structural similarity between the generated and actual code. This suggests that while the exact wording may differ, the generated code retains a similar syntactic form to the expected output, which is a positive outcome in code generation tasks.\n",
        "\n",
        "\n",
        "# Overall Insights:\n",
        "The low exact match score indicates that the model struggles to generate exact matches but still produces content that is relevant or structurally similar.\n",
        "\n",
        "The chrF and BLEU scores show some level of quality and coherence in the generated outputs, but they also indicate that improvements are needed.\n",
        "\n",
        "The high syntactic similarity score suggests that the model can capture the underlying structure of the code well, which may be more valuable in programming tasks where there can be multiple valid implementations of a function."
      ],
      "metadata": {
        "id": "GEyF8Rai_s1q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "879dbE87_TUa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}